{"claim": "The paper lacks ablative experiments analyzing the impact of removing the low-pass filter on low-frequency versus high-frequency information and on accuracy and generalization.", "claim_type": "experimental", "paper_id": "Cf4FJGmHRQ", "paper_title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "1Zfm29TuCw", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We provide an analysis of the impact of low and high-frequency information on accuracy/generalization through ablation experiments in Table 21 in Appendix F.7 of revision. Compared to PAC-FNO, accuracy and generalization decrease when using low-pass filter or high-pass filter.\"", "b3_evidence": "“We argue that the low pass filter removes useful information for generalization of the model and harms the image classification accuracy. Thus, we propose a FNO block without the low pass filter, and call it 'all component' FNO (AC-FNO).”\n\n“ We perform a comprehensive evaluation of PAC-FNO with seven image recognition benchmarks under various input quality degradation. In the evaluation, PAC-FNO demonstrates superior performance over other baselines…”", "b2_justification": "The authors state they added ablation experiments specifically examining low-pass vs high-pass vs combined filters (Table 21, Appendix F.7) and report results showing how each choice affects accuracy and generalization on ImageNet-1k and ImageNet-C/P Fog.", "b3_justification": "The paper proposes removing the low-pass filter (AC-FNO) and argues about its effects (Section 3), but the provided content includes no ablation experiments that analyze the specific impact of removing the low-pass filter on low- vs high-frequency information or on accuracy vs generalization. The methods and claims are described, and broad evaluations are mentioned, but no targeted ablative study is presented in the shown sections."}
{"claim": "The method section does not provide a sufficient mechanistic explanation for why the proposed parallel architecture is effective.", "claim_type": "subjective", "paper_id": "Cf4FJGmHRQ", "paper_title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "1Zfm29TuCw", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The parallel configuration of AC-FNO blocks captures more information than a serial structured model in the first layer, which is directly related to the data. We visualize what frequency the parallel configuration and serial configuration capture in Figure 7 in Appendix F.8 of revision. Figure 7 shows that the parallel configuration captures more high frequencies than the serial configuration. In other words, the parallel structured model captured both more low-frequency and high-frequency components than the serial structured model. As a result, parallel configuration of AC-FNO blocks show a better performance than serial configuration in Figure 4 in Section 4.3.\"", "b3_evidence": "1) \"Thus, we propose a FNO block without the low pass filter, and call it 'all component' FNO (AC-FNO). We then propose to stack the AC-FNO blocks in a parallel structure to increase the capacity of encoding spatial information of images, call the whole structure as 'parallel' AC-FNO or PAC-FNO.\" (Section 3)\n\n2) \"We now propose to configure AC-FNO blocks in a parallel structure to increase the capacity to learn various types of input variations. Previous FNO models have a serial structure, and the first layer of the model, which is directly related to data, consists of only one block. It has too small a capacity to consider all components of the data. Therefore, we increase the capacity of the first layer with the parallel configuration of AC-FNO blocks, allowing it to utilize all frequencies of the image, including high-frequency and low-frequency components.\" (Section 3.2)", "b2_justification": "Authors acknowledge the concern and provide a mechanistic explanation: they argue the parallel architecture captures both low- and high-frequency components (unlike serial), cite visualization (Figure 7), and report ablations (Table 21) to justify effectiveness.", "b3_justification": "The paper gives only high-level, qualitative motivation for the parallel design (e.g., 'increase the capacity' and retain all frequencies) but does not provide a detailed mechanistic explanation or analysis for why the parallel AC-FNO configuration leads to improved effectiveness over serial FNOs. The relevant content in Section 3 and 3.2 is descriptive rather than mechanistic."}
{"claim": "The manuscript does not provide evaluations on additional LiDAR datasets such as SemanticPOSS, Waymo, or SynLiDAR.", "claim_type": "experimental", "paper_id": "63xeWav1lU", "paper_title": "Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "P8fCEoWdti", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Following your suggestions, we have added experiments on six additional LiDAR-based point cloud datasets and one out-of-distribution dataset. And our proposed OLIVINE **consistently** outperforms the superpixels-based methods on all datasets. For the full results, please refer to Tables M2 and M3 of the uploaded PDF file.", "b3_evidence": "\"Extensive experiments reveal that our pre-training approach outperforms state-of-the-art 3D selfsupervised methods on both the nuScenes and SemanticKITTI datasets.\"", "b2_justification": "The authors state they have added experiments on multiple additional LiDAR datasets and report consistent results, indicating they addressed the lack of evaluations.", "b3_justification": "The paper reports experiments only on nuScenes and SemanticKITTI and does not mention evaluations on SemanticPOSS, Waymo, or SynLiDAR anywhere in the provided content."}
{"claim": "The paper lacks empirical analyses of model performance on out-of-distribution datasets to assess robustness.", "claim_type": "experimental", "paper_id": "63xeWav1lU", "paper_title": "Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "P8fCEoWdti", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Following your suggestions, we have added experiments on six additional LiDAR-based point cloud datasets and one out-of-distribution dataset. And our proposed OLIVINE consistently outperforms the superpixels-based methods on all datasets. For the full results, please refer to Tables M2 and M3 of the uploaded PDF file.\"; \"Based on your valuable feedback, we will carefully revise the manuscript, incorporating the additional experiments and analyses into the final version.\"", "b3_evidence": "“Extensive experiments demonstrate that our approach mitigates the challenges posed by traditional methods and consistently surpasses existing image-to-LiDAR contrastive distillation methods in downstream tasks.”\n\n“Extensive experiments reveal that our pre-training approach outperforms state-of-the-art 3D selfsupervised methods on both the nuScenes and SemanticKITTI datasets.”", "b2_justification": "Authors acknowledge the concern and state they added experiments including an out-of-distribution dataset and will incorporate these analyses into the revised manuscript.", "b3_justification": "The paper only reports experiments on standard benchmarks (nuScenes and SemanticKITTI) and does not present evaluations on out-of-distribution datasets or explicit robustness analyses in the provided content."}
{"claim": "The paper does not sufficiently compare OLIVINE against closely related methods like R1, R2, and R3.", "claim_type": "baseline", "paper_id": "63xeWav1lU", "paper_title": "Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "P8fCEoWdti", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "", "b3_evidence": "Abstract: \"Extensive experiments demonstrate that our approach mitigates the challenges posed by traditional methods and consistently surpasses existing image-to-LiDAR contrastive distillation methods in downstream tasks.\" \nIntroduction: \"Extensive experiments reveal that our pre-training approach outperforms state-of-the-art 3D selfsupervised methods on both the nuScenes and SemanticKITTI datasets.\" \nRelated Work: \"PPKT [39] ... SLidR [50] ... Seal [38] ... HVDistill [73] ...\"", "b2_justification": "Error during labeling: Unterminated string starting at: line 1 column 287 (char 286)", "b3_justification": "The paper claims to outperform existing image-to-LiDAR contrastive distillation methods (Abstract, Introduction) and lists related prior works (Related Work), but the provided excerpt does not include the experimental results, tables, or explicit comparisons vs. the specific methods R1, R2, and R3. Therefore it is not possible from the given content to confirm whether comparisons against those particular methods are present or sufficient."}
{"claim": "The paper does not provide strong arguments that hybrid domain adaptation is a meaningful, distinct research task compared to existing domain adaptation and generalization fields.", "claim_type": "novelty", "paper_id": "FE2e8664Sl", "paper_title": "Few-shot Hybrid Domain Adaptation of Image Generator", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "u2SOmGevjE", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "HDA only requires collecting data for several independent target domains rather than for each possible combination as mentioned by **Reviewer 2zhA**. Under such circumstances, HDA offers greater flexibility and versatility to adapt the generator to more composite and expansive domain.", "b3_evidence": "Abstract: \"Can a pre-trained generator be adapted to the hybrid of multiple target domains and generate images with integrated attributes of them? In this work, we introduce a new task - Few-shot Hybrid Domain Adaptation (HDA). ... Compared with Domain Adaptation (DA), HDA offers greater flexibility and versatility to adapt generators to more composite and expansive domains. Simultaneously, HDA also presents more challenges than DA as we have access only to images from individual target domains and lack authentic images from the hybrid domain.\" Introduction: \"Compared with conventional DA, HDA is more challenging in two aspects: (1) Existing DA approaches typically employ the discriminator ... we only have images sampled from individual domains and lack real images of the hybrid domain, which presents challenges for designing the discriminator-based adaptation framework. (2) Since there are extremely few reference images, the discriminator could easily overfit ... leading to missing the characteristics from other target domains in the generator.\" Related Works: \"However, the approach of inference time interpolation needs to train models on multiple individual domains, which necessitates multiple times the model size and training time. In contrast, our method can acquire one model for the hybrid domain in just few minutes.\"", "b2_justification": "The authors explicitly defend HDA as a meaningful, distinct task: they provide conceptual arguments (e.g., data-collection and compositionality advantages), contrast HDA with prior methods (DoRM, style-mixing, image editing, Domain Expansion), and add empirical results to support the claim.", "b3_justification": "The paper explicitly introduces HDA as a new task and provides several arguments why it is distinct from standard DA and from inference-time interpolation approaches, citing concrete challenges (lack of hybrid-domain images, discriminator overfitting) and practical advantages (flexibility, single adapted model vs multiple per-domain models). These points are presented in the Abstract, Introduction, and Related Works."}
{"claim": "The paper does not include experiments or analysis showing applicability of the methodology to conditional image generation conditioned on one or more target styles.", "claim_type": "experimental", "paper_id": "FE2e8664Sl", "paper_title": "Few-shot Hybrid Domain Adaptation of Image Generator", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "u2SOmGevjE", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"As shown in Fig. 12 of Appendix, we conduct the experiments on conditional generation. Specifically, we collect 10-shot images with \\textit{red hair} and \\textit{sunglasses}. Then we use masks to separate these attributes and adapt the generator with masked images for \\textit{red hair} and \\textit{sunglasses} respectively. We can observe that the generated images possess the corresponding attribute for both single DA and hybrid DA. Simultaneously, these images also maintain consistency with source domain.\"", "b3_evidence": "HDA aims to acquire an adapted image generator that preserves the integrated attributes of all target domains, without overriding the original characteristics.", "b2_justification": "The authors explicitly report and describe conditional generation experiments (Fig.12) using masked attributes (red hair and sunglasses) and state that generated images exhibit the corresponding attributes for both single and hybrid domain adaptation, directly addressing the reviewer's request for experiments on conditional image generation.", "b3_justification": "The paper consistently describes HDA as producing a single adapted generator that integrates attributes from multiple target domains and compares against inference-time interpolation methods, but it does not present experiments or analysis for conditional (per-style or per-target) image generation at inference time."}
{"claim": "The paper fails to discuss how the proposed methodology generalizes to conditional generation scenarios rather than producing images spanning all target-domain attributes.", "claim_type": "methodology", "paper_id": "FE2e8664Sl", "paper_title": "Few-shot Hybrid Domain Adaptation of Image Generator", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "u2SOmGevjE", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Results of conditional generation\\n\\nAs shown in Fig. 12 of Appendix, we conduct the experiments on conditional generation. Specifically, we collect 10-shot images with \\textit{red hair} and \\textit{sunglasses}. Then we use masks to separate these attributes and adapt the generator with masked images for \\textit{red hair} and \\textit{sunglasses} respectively. We can observe that the generated images possess the corresponding attribute for both single DA and hybrid DA. Simultaneously, these images also maintain consistency with source domain.\"", "b3_evidence": "\"HDA aims to acquire an adapted generator that preserves the integrated attributes of all target domains, without overriding the source domain's characteristics.\" (Abstract)\n\"HDA aims to acquire an adapted image generator that preserves the integrated attributes of all target domains... For example, given the few-shot references from the individual sketch, baby and smile domains as shown in Fig. 1 (Right), HDA aims to adapt the generator to sketch-smile-baby domain.\" (Introduction)\n\"Hybrid domain adaptation (HDA) aims to acquire a generator G_T that models a hybrid domain T = ∪_{i=1}^N T_i and generate images ˜Y with integrated attributes.\" (Section 3.1 Problem Formulation)", "b2_justification": "Authors explicitly report experiments on conditional generation, describe the setup (masked attributes, 10-shot), and state that generated images possess the corresponding attributes while maintaining source-domain consistency, directly addressing the reviewer's concern.", "b3_justification": "The paper consistently frames HDA as learning a single adapted generator that produces images with integrated attributes from all target domains and does not discuss or analyze conditional/controllable generation (i.e., generating different attribute combinations on demand). Thus it fails to address generalization to conditional generation scenarios."}
{"claim": "The paper lacks a study of the effect of using different pre-trained image encoders on the method's performance and robustness.", "claim_type": "experimental", "paper_id": "FE2e8664Sl", "paper_title": "Few-shot Hybrid Domain Adaptation of Image Generator", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "u2SOmGevjE", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Effect of different pre-trained image encoders\"\n\n\"As shown in Fig. 13 of Appendix, we conduct experiments on pre-trained Swin and Dinov2 to explore the impact of different image encoders on generated images. Their results all achieve HDA, indicating that our method is agnostic to different pre-trained image encoders. Although they exhibit slight stylistic differences, these are due to their different approaches to extract features into separated subspaces, as depicted in Fig. 8 of Appendix. To converge to the exact realization of the target domain, our method employs the ensemble technique that exploits both Swin and Dinov2. As shown in the figure, the results closely resembles the attributes of the target domain while maintaining the best consistency with source domain.\"", "b3_evidence": "To address the issues, we propose a discriminator-free framework for HDA. Specifically, we utilize the pre-trained image encoder E , such as Swin (Liu et al., 2021) and Dinov2 (Oquab et al., 2023) in image classification task, to encode the few-shot reference images Y i from T i into features f i :", "b2_justification": "The authors explicitly report experiments using different pre-trained image encoders (Swin and Dinov2), state that results achieve HDA and that the method is agnostic to different encoders, and describe slight differences and an ensemble approach—directly addressing the reviewer's concern.", "b3_justification": "The paper states it uses pre-trained image encoders (e.g., Swin and DINOv2) as the embedding backbone but presents no experimental comparison or ablation studying the effect of different pre-trained encoders on performance or robustness in the provided content (no such study or results are described in the main text)."}
{"claim": "The contrastive loss used by the authors is the vanilla form of classical contrastive learning without apparent innovation.", "claim_type": "methodology", "paper_id": "uMAujpVi9m", "paper_title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "9ap4s1SZlZ", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we have provided a novel method to **distill knowledge from well-trained molecule models** to protein models. Though employing the same contrastive loss, our approach is different from existing contrastive learning models since it uses a fixed molecular encoder.\"; \"Firstly, we acknowledge your observation that we didn't use any fancy models compared with typical **model-centric** works. While we respect your assessment, we would like to highlight that our primary focus in this paper is a **data-centric** pretraining method... constructing large-scale synthetic data that facilitates the pretraining of models...\"", "b3_evidence": "\"Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders.\" (Abstract)\n\n\"To counteract biases from peptide fragments used as ligands, we align the pocket encoder with a pretrained small molecule encoder, whose weights are fixed. This pretrained encoder serves as a guide, transferring binding-specific and biologically relevant information from extensive molecular datasets to our pocket encoder.\" (Introduction)\n\n\"Specifically, for a protein pocket p and its corresponding pseudo-ligand l , we denote their normalized encoding vectors as s and t . Let g_T and g_S denote the ligand and protein prediction networks, respectively. Then two distinct contrastive losses are used to facilitate the training process: ... the primary purpose of the first loss is to identify the true protein pocket from a batch of samples when given a pseudo-ligand. Similarly, the second loss seeks to identify the corresponding ligand fragment for a given pocket.\" (Section 3.2)", "b2_justification": "The authors explicitly reject the claim that there is no innovation: they acknowledge the contrastive loss form is standard but argue their novelty lies in the data-centric pipeline (peptides as pseudo-ligands), the use of a fixed molecular encoder to distill molecule-model knowledge into the pocket encoder, distributional alignment, theoretical justification, and ablations showing these design choices are necessary—therefore they refute the reviewer’s assertion of ‘no apparent innovation’.", "b3_justification": "The paper does not use a plain vanilla contrastive loss; it proposes a ‘‘molecular-guided’’ contrastive scheme that (1) aligns the pocket encoder to representations from a fixed, pretrained small-molecule encoder and (2) uses two distinct contrastive losses (pocket→ligand and ligand→pocket). These design choices are described explicitly in the paper, so the reviewer claim that the loss is the vanilla form without apparent innovation is contradicted."}
{"claim": "The authors claim the bound naturally exists for representations from pretrained molecule models, yet many non-molecule-pretrained models also satisfy this prior.", "claim_type": "experimental", "paper_id": "uMAujpVi9m", "paper_title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "9ap4s1SZlZ", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"As you said, many other encoders can also satisfy this condition. This shows that our method is applicable to many different molecular encoders with or without pretraining as we proved in Table 4.\" ... \"In fact, in the process of our early exploration, we noticed that some encoders cannot achieve a low pretraining loss, indicating the entire conditions of the theorem are nontrivial.\" ... \"Therefore, our theorem is nontrivial and reveals the transfer ability of our contrastive pre-training from the pseudo-ligand domain to the real ligand domain.\"", "b3_evidence": "“we align the pocket encoder with a pretrained small molecule encoder, whose weights are fixed. This pretrained encoder serves as a guide, transferring binding-specific and biologically relevant information from extensive molecular datasets to our pocket encoder.”; “The introduction of a new molecular guided fragment-surroundings contrastive learning method for pocket representations, which naturally distillates comprehensive structural and chemical knowledge from pretrained small molecule encoders.”", "b2_justification": "The authors acknowledge that the theorem's condition can be satisfied by many encoders (including those without molecule pretraining) but argue this does not make the result trivial — additional conditions (e.g. achieving low pretraining loss) are required and some encoders fail to meet them, so the authors partially accept the reviewer's point while defending the nontriviality of their bound.", "b3_justification": "The paper clearly states that pretrained small-molecule encoders provide useful binding-related priors and that the pocket encoder is aligned to such pretrained molecular representations (supporting the first part). However, the paper does not claim — nor provide evidence — that many non-molecule-pretrained models also satisfy this prior, so the second part of the reviewer's statement is not supported by the paper."}
{"claim": "Existing public datasets contain a limited number of pocket-ligand complex structures, limiting direct pocket-ligand pretraining opportunities.", "claim_type": "quantitative", "paper_id": "uMAujpVi9m", "paper_title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "9ap4s1SZlZ", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we have designed a pipeline to generate **over 5 million** synthetic ligand-protein pairs, which greatly eases the **data scarcity** problem in the field of protein-ligand interaction learning.\"", "b3_evidence": "Abstract: \"However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand nonredundant pairs) hampers large-scale pretraining endeavors for interaction modeling.\"; Section 2.1 POCKET PRETRAINING DATA: \"The most famous database is the PDBBind ..., which consists of 19,443 protein-ligand pairs in the latest version (v2020).\" and \"Biolip2 ... includes 467,808 pocket-ligand pairs, but only 71,178 pairs are non-redundant (the weekly version of 2023-09-21).\"", "b2_justification": "The authors acknowledge the data scarcity and directly address it by creating a large synthetic dataset and a peptide-based pretraining pipeline to compensate for limited real pocket-ligand complexes.", "b3_justification": "The paper explicitly states that publicly available pocket-ligand complex datasets are small (under 100k non-redundant pairs) and gives specific counts (e.g., PDBBind ~19k, BioLip2 467,808 total but only ~71k non-redundant), supporting the reviewer's claim about limited data restricting pretraining."}
{"claim": "The contribution is weak from an algorithmic point of view.", "claim_type": "novelty", "paper_id": "FGTDe6EA0B", "paper_title": "Language Generation in the Limit", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "2eG34J1hN3", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We understand that we disagree on several of these points...\"; \"we would suggest that this indicates how getting the details of the proof right is fairly subtle, and it is easy to inadvertently set things up in a way that leads to errors.\"; \"we think it is important for these details to be present; and if you were to fill in these details, you would get back to something essentially equivalent to Section 5.\"", "b3_evidence": "Our main result is that there is an agent that is able to generate in the limit for every countable list of candidate languages.\n\n(2.1) There is an algorithm with the property that for any countable collection of languages C = {L1, L2, L3, ...}, and any enumeration of one of these languages K, the algorithm generates from K in the limit.\n\nDespite the generality of the model, producing the generation algorithm that proves our main theorem makes use of subtle structural properties of the given list of candidate languages.", "b2_justification": "The authors explicitly disagree with the reviewer's criticisms and defend the technical and algorithmic substance of their work, arguing the proofs are subtle and nontrivial and that the reviewer’s alternative proofs are incorrect.", "b3_justification": "The paper presents a concrete algorithmic result: a constructive algorithm that generates from any countable collection of languages in the limit, and it frames this as the main theorem. Thus the claim that the contribution is weak algorithmically is contradicted by the paper's stated algorithmic contribution and formal proofs."}
{"claim": "The paper's results only hold under the assumption that all languages in the list are infinite.", "claim_type": "methodology", "paper_id": "FGTDe6EA0B", "paper_title": "Language Generation in the Limit", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "2eG34J1hN3", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"On the point about the languages $L_i$ being infinite, as noted earlier, we agree that the question becomes technically more complicated when some languages can be finite, and we can indeed discuss this point in a revision. ... This is exactly the reason to assume that the candidate languages $L_i$ are infinite.\"", "b3_evidence": "We will assume that all the languages L_i are infinite; while the original Gold-Angluin framework did not require this, it becomes important in specifying the generation problem: if we require an algorithm to output unseen strings forever, then this is not possible from a finite language, where the algorithm would eventually run out of new strings to generate. (2.1) There is an algorithm with the property that for any countable collection of languages C = {L_1, L_2, L_3, ...}, and any enumeration of one of these languages K, the algorithm generates from K in the limit.", "b2_justification": "Authors acknowledge that allowing finite languages makes the question technically more complicated, confirm they assume languages are infinite, and justify retaining that assumption while offering to discuss the issue in a revision.", "b3_justification": "The paper explicitly assumes all candidate languages L_i are infinite when formalizing the model, and the main theorem (2.1) is stated within that formal model. Thus the result is presented under the assumption that every language in the list is infinite."}
{"claim": "Assuming all languages are infinite is an unnatural and unjustified restriction seemingly introduced to make the proof work.", "claim_type": "subjective", "paper_id": "FGTDe6EA0B", "paper_title": "Language Generation in the Limit", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "2eG34J1hN3", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"On the point about the languages $L_i$ being infinite, as noted earlier, we agree that the question becomes technically more complicated when some languages can be finite, and we can indeed discuss this point in a revision. ... In particular, we'd reiterate the point from our earlier response that the challenge in real language generation problems is not the concern that the training data might have exhausted all possible valid utterances; it is generally understood, both intuitively and on more technical grounds, that there will always be further valid utterances that have not yet been seen. This is exactly the reason to assume that the candidate languages $L_i$ are infinite.\"", "b3_evidence": "We will assume that all the languages L_i are infinite; while the original Gold-Angluin framework did not require this, it becomes important in specifying the generation problem: if we require an algorithm to output unseen strings forever, then this is not possible from a finite language, where the algorithm would eventually run out of new strings to generate.", "b2_justification": "The authors explicitly disagree with the reviewer's characterization and defend the infiniteness assumption as reasonable and motivated; they acknowledge extra technical complications if languages can be finite but argue those complications detract from the motivation rather than justifying rejecting the assumption.", "b3_justification": "The paper explicitly states and justifies the assumption that all candidate languages are infinite: it argues this is necessary for the generation specification because if a language were finite, an algorithm could not be required to output unseen strings forever. Thus the assumption is justified in the paper rather than an ad-hoc restriction to make the proof work."}
{"claim": "The authors' explanation in line 126 for requiring all languages to be infinite is unconvincing.", "claim_type": "subjective", "paper_id": "FGTDe6EA0B", "paper_title": "Language Generation in the Limit", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "2eG34J1hN3", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"On the point about the languages $L_i$ being infinite, as noted earlier, we agree that the question becomes technically more complicated when some languages can be finite, and we can indeed discuss this point in a revision. As we also discussed earlier, we think that these added complications arising from finiteness detract from the underlying motivation rather than adding to it. ... This is exactly the reason to assume that the candidate languages $L_i$ are infinite.\"", "b3_evidence": "We will assume that all the languages L_i are infinite; while the original Gold-Angluin framework did not require this, it becomes important in specifying the generation problem: if we require an algorithm to output unseen strings forever, then this is not possible from a finite language, where the algorithm would eventually run out of new strings to generate.", "b2_justification": "The authors reject the reviewer's characterization as unconvincing: they acknowledge added technical complications if languages can be finite but argue those complications detract from the motivation and reaffirm that assuming infinite languages is appropriate for real language generation, thus disagreeing with the claim.", "b3_justification": "The paper gives an explicit, direct reason for assuming all languages are infinite: otherwise an algorithm required to output unseen strings forever would eventually run out of new strings. This directly addresses the point made at line 126 and provides a straightforward justification rather than leaving it unconvincing."}
{"claim": "Going beyond context-free languages typically renders finiteness or emptiness decision problems undecidable.", "claim_type": "other", "paper_id": "FGTDe6EA0B", "paper_title": "Language Generation in the Limit", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "2eG34J1hN3", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"On the point about the languages $L_i$ being infinite, as noted earlier, we agree that the question becomes technically more complicated when some languages can be finite, and we can indeed discuss this point in a revision.\"", "b3_evidence": "“If the reader finds it helpful for concreteness, they can consider the results that follow in the context of a specific list of languages C, such as the set of all context-free languages or the set of all regular languages; but everything we say applies to general collections of languages.”\n\n“All we assume about the list of languages is that it is specified through a black box that can answer questions of the form 'Is w ∈ L_i ?' for any string w ∈ U and language L_i ∈ C.”\n\n“We will assume that all the languages L_i are infinite; while the original Gold-Angluin framework did not require this, it becomes important in specifying the generation problem...”", "b2_justification": "The authors do not respond to the reviewer's claim about decidability (undecidability of finiteness or emptiness when going beyond context-free languages). They discuss proof issues and the assumption that candidate languages are infinite, but they do not address decidability/undecidability or the context-free boundary explicitly.", "b3_justification": "The paper does not make claims about decidability of finiteness or emptiness when moving beyond context-free languages. It formulates a model for generation/identification from a (countable) list of candidate languages and assumes access to a black box 'Is w ∈ L_i ?', but it does not discuss decision-problem (un)decidability results for finiteness or emptiness of language classes."}
{"claim": "The paper lacks comparisons to alternative initialization methods that set Q(W)+L1L2 to closely approximate the original pretrained matrix W.", "claim_type": "baseline", "paper_id": "xw29VvOMmU", "paper_title": "LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Bm88GSraZd", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We actually did implement and compare against a baseline that uses OPTQ/GPTQ to quantize first before learning low-rank updates. In particular, we use GPTQ to first quantize the model and then learn low-rank updates. We called this 'GPTQ-LoRA' baseline 'LREC' in the paper... We find that GPTQ-LoRA underperforms both QLoRA and LQ-LoRA (Table 1).\"; \"In addition, our latest PTQ experiments included comparisons with RTN, GPTQ, AWQ, and OmniQuant. For details, please see 'Additional Post Training Quantization Experiments' in our earlier response.\"", "b3_evidence": "\"we are not aware of prior work on low-rank plus quantized matrix decomposition, except for a recent preprint which proposes to perform SVD on the residuals E = W -Quantize( W ) to correct for errors after quantization (Yao et al., 2023). This approach can be seen as performing a single step of the iterative algorithm with the initialization Q (0) = Quantize( W ) . In our experiments we did not observe significant differences in performance when we initialized Q (0) to Quantize( W ).\"", "b2_justification": "The authors state they implemented and evaluated a quantize-then-LoRA baseline (GPTQ/OPTQ → LoRA, called GPTQ-LoRA/LREC) and report additional PTQ comparisons (RTN, GPTQ, AWQ, OmniQuant), with tables showing results—directly countering the claim that such comparisons were missing. They also explain compatibility with other quantization schemes and why some specialized methods (BRECQ/FlexRound) were not included.", "b3_justification": "The paper explicitly considers and compares an alternative initialization (Q(0) = Quantize(W)) and reports that it did not significantly change performance; it also compares LQ-LoRA to quantized-LoRA baselines (QLoRA, GPTQ-LoRA). Thus it does not lack comparisons to alternative initializations of the form Q(W)+L1L2 ≈ W."}
{"claim": "LQ-LoRA appears to inherit QLoRA's inference overhead limitation because it cannot integrate the LoRA layer directly into existing linear layers.", "claim_type": "methodology", "paper_id": "xw29VvOMmU", "paper_title": "LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Bm88GSraZd", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“inference with quantized + low-rank is not necessarily slower, especially in batch = 1 setting (per the latest releases from QLoRA; kudos to them).”\n\n“Practitioners could use the 'quantized + low-rank' models without merging. Such models could be just as fast as merged dense models and more memory-efficient.”\n\n“We then further quantize the LoRA components themselves to 8-bit (NF8)... LoRA components (with NF-8 quantization) amount to about 0.1-0.2 extra bits per parameter.”\n\n“For example, we could post-training merge \\mathbf{Q}, \\mathbf{L}_1, \\mathbf{L}_2, and re-decompose them into three separate quantized matrices for inference.”", "b3_evidence": ["Here Q is the quantized component which remains fixed and L1 L2 is the low-rank component. During adaptation only L1 and L2 (which captures the high-variance subspaces of W ) are finetuned.", "Dequantization, which is needed on the fly for finetuning and inference, simply reverses this process."], "b2_justification": "The authors do not claim that LQ-LoRA can be merged into existing linear layers (they do not demonstrate integration), but they explicitly argue that the inference overhead is not necessarily an issue: quantized + low-rank models can be competitive without merging, LoRA components can be quantized (adding only ~0.1–0.2 bits), and they provide experiments and citations to support comparable inference speed. Thus they partially address the reviewer's concern by disputing the inevitability of an inference overhead, while not fully showing direct integration of LoRA into linear layers.", "b3_justification": "The paper describes that the pretrained weights are decomposed into a fixed quantized component Q and a separate low-rank component L1L2 that is updated, and it explicitly states that dequantization is required \"on the fly\" for finetuning and inference. This implies extra runtime work similar to QLoRA. However, the paper does not explicitly state that the LoRA/low-rank component cannot be merged into existing linear layers for inference or directly claim it inherits QLoRA's exact inference-overhead limitation, so the reviewer claim is not fully confirmed by the text."}
{"claim": "The paper states Diffusion-TTA relies on a biased approximation due to ELBO optimization, raising concerns about estimator consistency and validity that are not resolved.", "claim_type": "methodology", "paper_id": "c7m1HahBNf", "paper_title": "Exploring Structured Semantic Priors Underlying Diffusion Score for Test-time Adaptation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "U1a50zbUPt", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"the bias should be calculated by: \\n$$\\text{Bias}(\\epsilon_\\phi(x_t,t,c_y),\\epsilon)=\\mathbb{E}\\_{x_t|\\epsilon,t}[\\epsilon_\\phi(x_t,t,c_y)]-\\epsilon=0,$$\\nwhich means the conditional noise estimator \\epsilon_\\phi(x_t,t,c_y) is indeed an **unbiased estimator** of the true noise \\epsilon.\" and \"the denoising estimator in Eq (7) is actually **unbiased**, there is **no theoretical approximation** for Eq (7), and we argue that **no circular reasoning** exists in our DUSA.\"", "b3_evidence": "From Introduction: \"Diffusion-TTA is heavily reliant on the Monte Carlo method over as many as 180 timesteps to estimate a biased approximation of likelihood [32, 38], resulting in high computational complexity proportional to sampled timesteps.\"; From Sec. 3.1: \"The loss is averaged over hundreds of (t, ε) pairs to remedy the performance degradation caused by incorrect class prediction using a single timestep [32], at the cost of reduced efficiency.\"", "b2_justification": "Authors explicitly dispute the reviewer's claim, provide mathematical derivations showing the conditional noise estimator is unbiased, and assert there is no theoretical approximation or circular reasoning in their method.", "b3_justification": "The paper criticizes Diffusion-TTA for relying on Monte Carlo sampling over many timesteps to estimate a biased approximation of the likelihood and for being computationally inefficient, but it does not state that this bias arises from ELBO optimization nor does it raise unresolved concerns about estimator consistency or validity. The paper's critique is about Monte Carlo timestep-based likelihood estimation and efficiency, not ELBO-related estimator consistency."}
{"claim": "The paper does not report results from gpt-3.5-turbo-16k-0613 on the example without prompt engineering, few-shot learning, or chain-of-thought.", "claim_type": "experimental", "paper_id": "UkxJd64mki", "paper_title": "StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "fGEvjzIyly", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Since 'gpt-3.5-turbo-16k-0613' has been deprecated, we used an improved version, 'gpt-3.5-turbo-1106,' to generate a prediction with a temperature setting of 0.\"", "b3_evidence": "1) \"StrategyLLM expends less than $0.24 to develop a strategy-based prompt for a variety of tasks using the latest version of GPT-3.5-Turbo.\" 2) \"We conduct comprehensive evaluations of StrategyLLM on 13 datasets across 4 challenging tasks...\"", "b2_justification": "The authors acknowledge that gpt-3.5-turbo-16k-0613 was not used (it is deprecated) and instead report using gpt-3.5-turbo-1106, so they effectively confirm that results from the specified deprecated model were not provided.", "b3_justification": "The provided paper text mentions using 'the latest version of GPT-3.5-Turbo' for prompt generation and presents experimental evaluations, but it does not mention or report results from the specific model 'gpt-3.5-turbo-16k-0613' nor any explicit baseline evaluation of that model in a zero-shot / no-prompt-engineering / no-CoT setting in the given sections."}
{"claim": "Attributing CoT's inferior performance relative to StrategyML to a bug in the CoT implementation is not justified without further investigation.", "claim_type": "subjective", "paper_id": "UkxJd64mki", "paper_title": "StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "fGEvjzIyly", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We want to reassure you that there is no bug or issue in our CoT implementation.\"", "b3_evidence": "Abstract: \"StrategyLLM outperforms the competitive baseline CoT-SC that requires human-annotated solutions on 13 datasets...\"; Introduction: \"Despite their potential, current CoT approaches employing few-shot prompts with instance-specific solutions may face challenges in terms of generalizability and consistency.\"", "b2_justification": "Authors explicitly agree that poor CoT performance is not due to a bug: they reassure there is no bug, explain variability of LLM outputs, and point to test-set results showing CoT's effectiveness rather than a buggy implementation.", "b3_justification": "The paper attributes CoT's weaker performance to issues of generalizability and consistency and presents StrategyLLM as an alternative; it does not claim or investigate that a software/implementation bug causes CoT's inferior performance, so blaming a bug is not justified by the paper."}
{"claim": "The paper does not evaluate whether reinitializing the fake score function from the teacher model helps training as the student converges.", "claim_type": "experimental", "paper_id": "tQukGCDaNT", "paper_title": "Improved Distribution Matching Distillation for Fast Image Synthesis", "paper_venue": "neurips2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "K5GmPvDd81", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we have not yet observed the peak performance of our models... The suggestion to reinitialize the fake diffusion model at a later stage is intriguing, and we look forward to experimenting with this approach.\"", "b3_evidence": "“We show that the resulting instability is due to the 'fake' critic not estimating the distribution of generated samples with sufficient accuracy and propose a two time-scale update rule as a remedy.”\n\n“DMD uses a frozen pre-trained diffusion model as µ_real (the teacher), and dynamically updates µ_fake while training G, using a denoising score-matching loss on samples from the one-step generator, i.e., fake data [22, 47].”", "b2_justification": "Authors acknowledge they have not tried reinitializing the fake model and indicate they plan to experiment with this suggestion, thus agreeing the paper currently lacks that evaluation.", "b3_justification": "The paper describes addressing instability by dynamically training a 'fake' score (µ_fake) and using a two time-scale update rule, but contains no evaluation or mention of reinitializing the fake score from the teacher as the student converges."}
{"claim": "The combination of EGNN and ESM2 limits the novelty of the method.", "claim_type": "novelty", "paper_id": "Dr4qD9bzZd", "paper_title": "Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "a9hHYfEm0G", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We would like to point out that our NAEPro is not a combination of ESM2 and EGNN. Instead our key innovations are (1) interleaving layers of sequence-level attention and local neighborhood equivariant sub-layer (2) accelerating the local sub-layer with the k-nearest neighbors.\" ... \"As the results show, EGNN+ESM2 performs much worse than our NAEPro, and removing the ESM2 initialization will not influence the performance too much, demonstrating that our model is much more superior than EGNN+ESM2.\"", "b3_evidence": "“NAEPro is an interleaving network consisting of stacked neighborhood attentive equivariant layers (NAELs). Each NAEL is composed of two integral components: a global attention sub-layer and a neighborhood equivariant sub-layer.”\n\n“We adopt the Transformer layer (Vaswani et al., 2017) to compute global contextual embeddings.”", "b2_justification": "Authors explicitly reject the claim, describe architectural novelties that differentiate NAEPro from an EGNN+ESM2 combination, and provide empirical results showing EGNN+ESM2 performs worse than NAEPro.", "b3_justification": "The paper describes a novel Neighborhood Attentive Equivariant Layer (NAEL) architecture combining a Transformer-based global attention sub-layer and a neighborhood equivariant sub-layer designed by the authors. It does not state that the method is merely a combination of EGNN and ESM2, nor does it reference using ESM2; thus the reviewer's claim is contradicted by the paper."}
{"claim": "Previous works can be readily applied to the motif-conditioned setting, which calls into question this paper's significance.", "claim_type": "novelty", "paper_id": "Dr4qD9bzZd", "paper_title": "Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "a9hHYfEm0G", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Previous work which is most similar to ours is Inpainting [1]. However, [1] provides the functional sites manually while we automatically mined the functional sites ... by MSAs.\"; \"EGNN+ESM2 is a sequential process and can not cross-condition on sequence and structure.\"; \"we think antibody design models can not be directly applied to our task without any modification and vice versa.\"", "b3_evidence": "Intro: \"Wang et al. (2022) provide a solution to fill in additional sequence and structure given functional motifs. However, this approach assumes that biologists already possess knowledge of the motifs associated with the target proteins, thereby potentially restricting the model's applicability.\" Related Work: \"Wang et al. (2022) propose Inpainting to reconstruct both missing protein sequences and structures using provided motifs. However, it's essential to note that this approach necessitates the prior specification of motifs for the target proteins, which requires domain-specific expertise.\"", "b2_justification": "The authors explicitly argue that prior methods are not readily applicable to their motif-conditioned co-design task, citing architectural and task differences (automatic motif mining vs manual, inability to cross-condition sequence and structure, inefficiency of prior equivariant networks) and providing empirical comparisons to support their point.", "b3_justification": "The paper explicitly argues prior methods are not directly applicable to motif-conditioned design—citing that some require pre-specified motifs or prespecified secondary structures, and thus motivate automatic motif-guided co-design. This contradicts the reviewer's claim that previous works can be readily applied to the motif-conditioned setting."}
{"claim": "No experimental results are provided on the CATH dataset to compare with SMCDiff and FrameDiff.", "claim_type": "experimental", "paper_id": "Dr4qD9bzZd", "paper_title": "Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "a9hHYfEm0G", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We would like to clarify our task more clearly. Our task aims to co-design functional and novel protein sequence and structure. In our method, we use MSAs to automatically find motifs to guarantee the protein function, which is achieved within the same protein family. Instead, CATH is a protein dataset consisting of proteins from diverse families, making the motif extraction difficult. Besides, CATH is usually used to evaluate inverse folding task, say protein sequence design based on fixed backbone structure, which is not the goal of our paper. We hope we didn’t misunderstand the reviewer’s meaning by “the original SMCDiff and FrameDiff results” as SMCDiff and FrameDiff haven’t been evaluated on CATH dataset.", "b3_evidence": "“We evaluate our model and several strong baselines on two protein datasets, β -lactamase and myoglobin.”", "b2_justification": "The authors acknowledge they did not provide experiments on the CATH dataset and justify this by explaining CATH is a different benchmark (inverse-folding, diverse families) and that SMCDiff/FrameDiff have not been evaluated on CATH, so they did not run those comparisons.", "b3_justification": "The paper states experiments were run on only two datasets (β-lactamase and myoglobin) and does not report results on the CATH dataset or comparisons to SMCDiff or FrameDiff."}
{"claim": "The paper lacks head-to-head comparisons to ProteinMPNN, ESMIF, and PiFold on protein sequence design under the same evaluation setting.", "claim_type": "baseline", "paper_id": "Dr4qD9bzZd", "paper_title": "Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "a9hHYfEm0G", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Q2: Could you provide head-to-head comparisons to ProteinMPNN, ESMIF, and PiFold on protein sequence design? Please follow the same setting.\n\nAns: We provide protein sequence design given backbone structures on our two datasets in the following table. In this setting, we slightly modified our method to make it adaptable to the task as the reviewer asked. Specifically, we provided the whole backbone structure as the model input and designed the whole protein sequence. As the results show, even though we only provide backbone structure without any motif residues, our model can still achieves higher AAR and pLDDT on myoglobin, and higher AAR on beta-lactamase.\n\nmyoglobin\n\n|Model| AAR (%)|pLDDT |\n|:-----|:----:|:----:|\n|ProteinMPNN|81.37|81.9817|\n|ESMIF|76.49|78.0986|\n|PiFold|78.93|80.2912|\n|NAEPro|**85.56**|**82.3871**|\n\nβ-lactamase\n\n|Model| AAR (%)|pLDDT |\n|:-----|:----:|:----:|\n|ProteinMPNN|53.59|**70.6723**|\n|ESMIF|57.49|61.3928|\n|PiFold|63.38|64.9017|\n|NAEPro|**68.39**|65.8218|", "b3_evidence": "\"We evaluate our model and several strong baselines on two protein datasets, β -lactamase and myoglobin.\" (Abstract)\n\n\"followed by the utilization of existing inverse folding models (Ingraham et al., 2019; Jing et al., 2020) like ProteinMPNN (Dauparas et al., 2022) to determine sequences that can fold into the specified structure.\" (1 INTRODUCTION)\n\n\"Our model is at least 17 x faster than all the representative baselines. We will release our datasets, code and models.\" (1 INTRODUCTION, contributions)", "b2_justification": "The authors directly provided head-to-head comparison results against ProteinMPNN, ESMIF, and PiFold for protein sequence design (backbone-to-sequence setting) and reported metrics in tables, addressing the reviewer's request.", "b3_justification": "The provided paper text states it evaluates against “several strong baselines” but does not list or present any head-to-head experimental comparisons with ProteinMPNN, ESMIF, or PiFold. ProteinMPNN is only mentioned in related work/intro, not as an evaluated baseline in the shown experimental description or results excerpts."}
{"claim": "The proposed combinatorial toy model is too simplistic and fails to capture implicit biases of deep learning that drive observed merging phenomena.", "claim_type": "subjective", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We fully agree that many assumptions were made. The way we see it is that deep learning's complexity necessitates some level of simplification for tractable analysis.\"; \"This is correct. The framework as it stands does not describe the learning process, which is an extremely complicated subject itself.\"", "b3_evidence": "1) \"we propose an alternative (still simplified) model of feature learning...\"  \n2) \"Note that we do not attempt to derive how our model can arise mechanistically via optimization, but we believe that this can be considered a strength of our approach.\"  \n3) \"Despite the simplification, we show that our framework naturally captures the phenomenon of GDE... Finally, we demonstrate that the framework can make accurate predictions about the effects of merging classes and changing data distribution on GDE and calibration, leading to the construction of natural data distributions that break GDE.\"", "b2_justification": "The authors acknowledge the model's simplicity and many assumptions and concede it does not model the learning process or fully match practice, but they defend the choice as a tractable, useful abstraction and argue it can still yield insight; thus they partially endorse the reviewer's critique while disputing that this makes the work without value.", "b3_justification": "The paper explicitly describes the proposed model as simplified and acknowledges it does not model mechanistic/optimization biases (supporting the reviewer’s claim of simplicity and lack of implicit-bias modeling). However, the paper also argues that despite this simplification the framework nevertheless captures and explains merging-related phenomena (e.g., GDE and effects of merging classes), contradicting the reviewer’s assertion that it 'fails to capture' those phenomena."}
{"claim": "The proposed model does not leave an obvious path for generalizations toward more realistic models or practical deep learning setups.", "claim_type": "novelty", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"This is correct. The framework as it stands does not describe the learning process, which is an extremely complicated subject itself. However, we postulate that techniques similar to [1] could be used to study the optimization of a feature model like ours in the future.\" \n\n\"We believe our framework can accommodate distribution shifts. For instance, the simplest form of covariate shift one could introduce is to add a new set of features that are not present in the training data with some probability at test time.... One can also introduce a covariate shift on existing features but that would require imposing a non-uniform distribution over the existing features. We leave the exploration of these directions to future works.\"", "b3_evidence": "\"Based on these observations, we propose an alternative (still simplified) model of feature learning... Note that we do not attempt to derive how our model can arise mechanistically via optimization, but we believe that this can be considered a strength of our approach.\"", "b2_justification": "The authors acknowledge the gap between their abstract model and practical setups and explicitly describe limitations, but they also point to possible extensions (e.g., applying optimization techniques, extending to multi-class, and accommodating distribution shifts) and commit to exploring these directions in future work, so they partially address the reviewer's claim.", "b3_justification": "The paper explicitly acknowledges that the proposed framework is a simplified, phenomenological model and states they do not attempt to derive mechanistic or optimization-based extensions, which supports the reviewer's point that the work does not provide an explicit path to more realistic/mechanistic generalizations. However, the paper also introduces practical analysis tools (interaction tensor, PCA-based feature identification, clustering) and demonstrates empirical and theoretical implications (e.g., explaining GDE and constructing distributions that break it), which could serve as starting points for future generalizations even though the authors do not make those extensions themselves."}
{"claim": "The interaction-tensor-based model is not well motivated, and the paper does not explain how it relates to actual deep network training.", "claim_type": "subjective", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"This is correct. The framework as it stands does not describe the learning process, which is an extremely complicated subject itself.\"\n\n\"The primary goal of our work is to investigate the effect of different features being learned by different models on GDE and the calibration of deep ensembles... While our model does not directly provide insights into training, understanding these feature interactions may indirectly inform training strategies in the future.\" \n\n\"We definitely agree that our model is unconventional and more abstract than most existing works but similar assumptions have been made in prior work [6]... Despite the simplification, our model already exhibits some interesting behaviors and offers insight into empirical phenomena so we believe that it adds value to the current discussion on feature learning.\"", "b3_evidence": "“we introduce a new tool, the interaction tensor , for empirically analyzing the interaction between data and model through features.” || “Note that we do not attempt to derive how our model can arise mechanistically via optimization, but we believe that this can be considered a strength of our approach.”", "b2_justification": "The authors concede that the framework does not describe the learning/training process (agreeing with that part of the claim) but simultaneously defend the model's motivation and usefulness for explaining empirical phenomena and relate it to prior work, so they partially address the reviewer's concern rather than fully conceding or refuting it.", "b3_justification": "The paper clearly motivates and defines the interaction tensor and describes how it is constructed (so it is motivated and connected to empirical analysis of models and data), but it explicitly states that it does not attempt to derive how the proposed model arises mechanistically from optimization or training, i.e., it does not explain the relation to actual deep network training."}
{"claim": "The authors do not clearly specify how hyperparameters, such as thresholds, were set in their model or experiments.", "claim_type": "methodology", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"As detailed in Appendix F.10 (referred at the end of Section 4), our conclusions are robust across a range of parameter settings so we believe that the settings used in our paper should be appropriate for most situations.\" / \"In Appendix F.10, we conducted an ablation study and found that our qualitative conclusions are robust to variations in these hyperparameters. Therefore, we believe the values used in our paper should be appropriate for most applications.\"", "b3_evidence": "1) \"We use the top K principal components V : K and project the representations to R K , Φ_proj ≜ Φ V : K = [ V ⊤ : K φ ( x (1) ) , V ⊤ : K φ ( x (2) ) , . . . , V ⊤ : K φ ( x ( N ) )] ⊤ . For notation simplicity, we will use υ ( x ) to denote V ⊤ : K φ ( x ) ...\"\n\n2) \"In this section, we describe the procedure for constructing the interaction tensor Ω ∈ { 0 , 1 } M × N × T . ... If the n th data point contains the t th feature and the m th model has learned the T th feature, then Ω mnt would be 1 .\"", "b2_justification": "The authors point the reviewer to Appendix F.10 and state they performed an ablation study showing conclusions are robust across a range of hyperparameter settings, thereby addressing how hyperparameters (e.g., thresholds) were set and their impact.", "b3_justification": "The provided paper text mentions hyperparameter-like choices (e.g., selecting the top K principal components and binarizing an interaction tensor) but does not state how such parameters (K, clustering or binarization/threshold criteria) were chosen or tuned. Sections 3.1 and 3.2 describe the procedures but omit specific settings or threshold selection methodology."}
{"claim": "The notational choices (using generic letters like i, j, k) are confusing and the paper lacks a summary figure for symbols such as p_d and p_r.", "claim_type": "presentation", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We have streamlined the notations in Section 3 for better clarity so the footnotes are no longer needed.\" ... \"Regarding the table of notation, we fully agree that a table would be great to have. Unfortunately, so far we have not been able to find a way to squeeze it into the text. And we will definitely include it in the extended version.\"", "b3_evidence": ["we will use υ ( x ) to denote V ⊤ : K φ ( x ) and υ m,k ( x ) to denote the k th entry of of the m th model's υ ( x ) .", "For models ( f i , f j ) and their respective a th and b th features, we can define their correlation to be:", "Figure 1: Visualization of images with the least features (left) and the most features (right) for classes of CIFAR 10 under our feature definition (defined in Section 3.1)."], "b2_justification": "The authors acknowledge the notation issues and report concrete changes to streamline notation and clarify index conventions in Section 3. However, they did not add the requested summary table/figure to the main text, only noting a centralized notation list in the appendix and promising to include a table in an extended version.", "b3_justification": "The paper indeed uses generic index notation (i, j, k, m, n, t) in its technical sections, which supports the reviewer's observation about notational choices. However, the reviewer claim that these choices are 'confusing' is a subjective judgment not stated or evidenced in the paper. Regarding a summary figure for symbols such as p_d and p_r, the provided paper content contains multiple figures (e.g., Figure 1) but does not show or mention symbols named p_d or p_r in the excerpt, so there is insufficient evidence in the provided content to confirm whether such a summary figure is missing from the full paper."}
{"claim": "The authors claim to prove GDE without explicitly assuming calibration, but they do not clarify whether their model assumptions are stronger or weaker than calibration.", "claim_type": "methodology", "paper_id": "ze7DOLi394", "paper_title": "On the Joint Interaction of Models, Data, and Features", "paper_venue": "iclr2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "RUsLYJEhvF", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We want to clarify that we *do not* claim that the assumptions we make are weaker than calibration (since neither is a clear superset of the other), but we do believe that it sheds more light on the underlying reasons behind GDE. Only stating the model is calibrated does not tell us much about the model or the data, but our assumptions do. In fact, our framework tells us how one can break our assumption (and calibration) through data distribution interventions. Of course, it is an important open question why so many natural distributions seem to satisfy these assumptions.", "b3_evidence": "\"we show that GDE arises immediately as a consequence of how neural networks learn appropriately defined features. This phenomenon was previously explained by assuming calibration of the underlying ensemble, which is often a strong assumption to make.\"; \"To address this gap, this work shows that the phenomenon of GDE can arise within a feature learning context, without making explicit calibration assumptions.\"; \"Note that we do not attempt to derive how our model can arise mechanistically via optimization, but we believe that this can be considered a strength of our approach.\"", "b2_justification": "The authors explicitly clarify the relationship: they state they do not claim their assumptions are weaker than calibration and assert that neither set of assumptions is a clear superset of the other, thus directly addressing the reviewer's concern.", "b3_justification": "The paper explicitly states that GDE arises from their feature-learning framework without making explicit calibration assumptions, and it does not provide a comparison stating whether its model assumptions are stronger or weaker than the calibration assumption (no such comparison or claim appears in the cited sections)."}
{"claim": "The proposed method lacks necessary motivation and the paper fails to convincingly justify why this approach is needed.", "claim_type": "subjective", "paper_id": "QQ5eVDIMu4", "paper_title": "Distribution Shift Resilient GNN via Mixture of Aligned Experts", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "ppMpJyIYRZ", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We understand the reviewer's clarification concerns, however, we don't agree that they, based on our justificaton, are the cause of rejection. We believe nuanced heterogeneous shifts are common, important, yet being typically ignored in the research domain of distribution shifts, we made these argument clear and also promise to refine.\"", "b3_evidence": "1) \"However, previous works mostly focus on addressing specific types of distribution shifts, e.g., larger graph size or node degree, or inferring distribution shifts from data environments, which is highly limited when confronted with nuanced distribution shifts.\" 2) \"Here we introduce GraphMETRO, a novel framework based on a mixture-of-experts (MoE) architecture, enhancing GNN generalizability for both node- and graph-level tasks. The core concept of GraphMETRO includes the construction of a hierarchical architecture composed of a gating model and multiple expert models that are aligned in a common representation space.\" 3) \"Assumption 1 (An Equivalent Mixture for Distribution Shifts) ... We assume that the resulting shift in Dt can be modeled by the selective application of up to k out of K classes of stochastic transformations to each instance in the source distribution Ds (k < K).\"", "b2_justification": "The authors explicitly defend and justify the motivation, argue that heterogeneous shifts are important and previously overlooked, provide theoretical and empirical support, and state they do not agree that lack of motivation should cause rejection.", "b3_justification": "The paper explicitly motivates the problem (limitations of prior work on specific shift types and the need to handle nuanced, instance-wise distribution shifts), introduces a principled solution (GraphMETRO) with a clear conceptual framework (gating + experts) and a formal assumption (Assumption 1) that justifies the mixture decomposition approach, and reports empirical gains. Thus the claim that the paper 'lacks necessary motivation and fails to convincingly justify' the approach is contradicted by multiple sections of the paper."}
{"claim": "The novelty of the proposed method is insufficient and does not meet the standards expected for significant research contributions.", "claim_type": "novelty", "paper_id": "QQ5eVDIMu4", "paper_title": "Distribution Shift Resilient GNN via Mixture of Aligned Experts", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "ppMpJyIYRZ", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we don't agree that they, based on our justificaton, are the cause of rejection. We believe nuanced heterogeneous shifts are common, important, yet being typically ignored in the research domain of distribution shifts...\"; \"We believe our work makes good contributions to the field of graph distribution learning by proposing a novel and effective solution...\"; \"We believe our novelty comes from the formulation of an equivalent mixture for graph OOD and the construction of our training framework...\"", "b3_evidence": "Abstract: \"Here we introduce GraphMETRO, a novel framework based on a mixture-of-experts (MoE) architecture...\"; Introduction (end of first page): \"We present a novel framework, GraphMETRO, to enhance model generalizability...\"; Related Works: \"GraphMETRO is the first to design a mixture-of-expert model specifically tailored to address graph distribution shifts, coupled with a novel objective for producing invariant representations.\"; Key benefits: \"It provides a simple yet novel paradigm, which formulates graph generalization as inferring the equivalent mixture as a proxy...\"", "b2_justification": "The authors firmly disagree with the reviewer's claim and defend the paper's novelty, outlining specific original contributions (equivalent mixture formulation, referential invariant representations, training framework), adding comparisons to prior work, and promising revisions to clarify these points.", "b3_justification": "The paper repeatedly claims novelty for the proposed approach (GraphMETRO), describing it as a \"novel framework\" and the \"first\" MoE designed for graph distribution shifts, and highlights novel contributions in multiple sections. Therefore the paper does not support the reviewer's assertion that its novelty is insufficient."}
{"claim": "Despite including shift learning and data augmentation components, the paper appears to rely on standard optimization routines without explaining why.", "claim_type": "methodology", "paper_id": "QQ5eVDIMu4", "paper_title": "Distribution Shift Resilient GNN via Mixture of Aligned Experts", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "ppMpJyIYRZ", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we set apart the other loss terms from backpropagating to it to avoid interference with the training of the gating model… We optimize the objective via stochastic gradient descent\"... \"we did try to pretrain the gating model for several epochs as warm up before training the whole model in an end-to-end fashion via the objective Eq. in (3). However, we didn’t notice a statistically significant difference in their performance\"", "b3_evidence": "The standard approach is Empirical Risk Minimization (ERM) , i.e., where L denotes the loss function and y is the label of the graph G. It minimizes the average loss among all examples in the source domain.", "b2_justification": "Authors acknowledge and clarify their optimization choices: they state they use SGD, explain training pipeline details (e.g., isolating loss terms to avoid interference), point to appendix hyperparameters, and report having tried a more intricate strategy (pretraining the gating model) with no significant difference.", "b3_justification": "The paper mentions standard Empirical Risk Minimization (ERM) as the baseline training objective and otherwise describes architectural components (gating, experts, augmentation) and an informal assumption, but does not provide details or rationale for any specialized optimization routine or explain why standard optimization would be sufficient. Thus the reviewer's claim that the paper appears to rely on standard optimization routines without explaining why is supported by the paper text."}
{"claim": "The claim that graph shift heterogeneity is under-explored is contradicted by a wide spectrum of existing approaches and literature.", "claim_type": "novelty", "paper_id": "QQ5eVDIMu4", "paper_title": "Distribution Shift Resilient GNN via Mixture of Aligned Experts", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "ppMpJyIYRZ", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We believe nuanced heterogeneous shifts are common, important, yet being typically ignored in the research domain of distribution shifts, we made these argument clear and also promise to refine.\"", "b3_evidence": "Introduction: \"A line of previous research has focused on addressing specific types of distribution shifts. For example, works have looked at distribution shifts related to graph size (...) feature noise (...) and node degree or local structure (...). However, these approaches are highly limited as the distribution shift types could be multiple in the real-world datasets and may not be consistent with the presumed distribution shifts. While previous invariant learning methods on graphs (...) is able to accommodate multiple distribution shifts inferred from data environments, they focus on common patterns within each environment and do not explicitly model the variety across node or graph instances.\" Related Works: \"However, this line of research focuses on group patterns without explicitly considering nuanced (instance-wise) distribution shifts, making its applicability limited.\" Also: \"GraphMETRO is the first to design a mixture-of-expert model specifically tailored to address graph distribution shifts...\"", "b2_justification": "The authors explicitly disagree with the reviewer’s characterization and defend their original claim: they acknowledge related prior work but argue that existing methods do not address the instance-wise (nuanced) graph shift heterogeneity they target, and they revised/clarified their positioning rather than conceding the reviewer's point.", "b3_justification": "The paper explicitly argues that prior work focuses on specific shift types or group/environment-level patterns and does not model nuanced, instance-wise heterogeneity. It even states GraphMETRO is the first MoE tailored to address graph distribution shifts, so the reviewer's claim that a \"wide spectrum\" of existing approaches already contradicts the paper's claim is not supported by the paper."}
{"claim": "The paper title 'Physically Compatible 3D Object Modeling from a Single Image' is misleading because the work focuses on enhancing models from existing methods rather than full single-image reconstruction.", "claim_type": "methodology", "paper_id": "k29Iv0XrBF", "paper_title": "Physically Compatible 3D Object Modeling from a Single Image", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "RasXwPlfVF", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Based on your suggestions, we will change the title to ‘Physically Compatible 3D Object Modeling.’", "b3_evidence": "1) \"Our framework's versatility is demonstrated by its integration with five distinct single-view reconstruction methods, each employing unique geometry representations.\" 2) \"Our framework treats the rest-shape geometry as the optimization variable, assuming that the mechanical properties and external forces are predefined as inputs. Fig. 2 illustrates the overall pipeline.\"", "b2_justification": "The authors agree that the title should be changed and commit to updating it, acknowledging the reviewer's concern that the original title was misleading.", "b3_justification": "The paper describes an optimization framework that takes predefined mechanical properties and external forces and optimizes a rest-shape geometry (i.e., refines physical models), and explicitly states integration with five existing single-view reconstruction methods rather than presenting an end-to-end single-image reconstruction pipeline that infers all attributes from scratch (Abstract; Section 3)."}
{"claim": "The method may incorrectly deem inherently unstable poses (for example, a flamingo standing on one leg) as standable under gravity after optimization, which contradicts physical realism.", "claim_type": "methodology", "paper_id": "k29Iv0XrBF", "paper_title": "Physically Compatible 3D Object Modeling from a Single Image", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "RasXwPlfVF", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Thank you for your feedback. Based on your suggestions, we will change the title to ‘Physically Compatible 3D Object Modeling.’ We are also open to any other title suggestions from the reviewer and will adjust the paper title based on the meta-review if necessary.\"", "b3_evidence": "\"Fundamentally, an image is more than a visual representation of an object: It captures a physical snapshot of the object in a state of static equilibrium, under the influence of real-world forces.\"; \"In our approach, we treat the entity depicted in the input image as a solid object.\"; \"In the second scenario, the loss function is L(x_static) = || proj_z(C(x_static)) - ˆC ||, ... Minimization of this function ensures the structural stability of M_static.\"", "b2_justification": "The authors only discuss changing the paper title and offering to provide additional materials to improve the review score; they do not address the reviewer's concern about incorrectly deeming unstable poses as standable or discuss physical realism or pose stability.", "b3_justification": "The paper assumes the input depicts an object in static equilibrium and models entities as solid objects, enforcing stability via a center-of-mass constraint. It does not discuss cases where observed poses are passively unstable (e.g., animals balancing actively) or analyze failure modes where the method might incorrectly make such poses appear standable. Therefore the reviewer claim is not directly confirmed nor explicitly contradicted by the paper."}
{"claim": "Evaluating different off-the-shelf methods using connected components is an inappropriate metric and cannot demonstrate the proposed method's superiority in physical compatibility.", "claim_type": "methodology", "paper_id": "k29Iv0XrBF", "paper_title": "Physically Compatible 3D Object Modeling from a Single Image", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "RasXwPlfVF", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Based on your suggestions, we will change the title to ‘Physically Compatible 3D Object Modeling.’\"", "b3_evidence": "For evaluation, we introduce five metrics designed to comprehensively assess the physical compatibility of the modeled 3D objects under simulation. These metrics include image loss between the rendered image of the modeled physical object and the input image, stability under gravity, as well as measures from finite element analysis, such as integrity and structural robustness.", "b2_justification": "The authors' response only discusses changing the paper title and solicits further suggestions; it does not address the reviewer's critique about the evaluation metric or the use of connected components for demonstrating physical compatibility.", "b3_justification": "The paper describes five specific evaluation metrics (image loss, stability under gravity, and FEM measures like integrity and structural robustness) and reports integration with five reconstruction methods, but it does not mention using 'connected components' as an evaluation metric nor discuss the appropriateness of such a metric. Therefore the paper does not provide information to confirm or refute the reviewer's claim."}
{"claim": "The paper's claim regarding the knowledge base is insufficiently clarified and lacks explanation of how the knowledge base is constructed or used.", "claim_type": "methodology", "paper_id": "aaYBsuGRne", "paper_title": "Understanding In-context Learning with a Pelican Soup Hypothesis", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "EIVr3uVfUn", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We have revised the paper to address the main concern that Section 3 is not substantiated... We added more elaboration on the linkage between Section 3 and Section 5.1, stressing that Section 3 is to draw intuitions for the assumptions in Section 5.1 and that Section 5.1 is the formal description for the characteristics described in Section 3. (… ) The construction of Calcutec is more complicated than the toy data used in previous theoretical works such as [3] because Calcutec relies on milder assumptions and is more realistic. (… ) Could you be more specific on what details are missing and how we should improve? We will appreciate your suggestion.", "b3_evidence": "We posit that a knowledge base is indispensable for solving any NLP task as cognitive psychologists have suggested that semantics of words are based on the interrelation among concepts (Fodor, 1975; 2008; Siskind, 1996; Murphy, 2004). For example, the semantic of the verb 'move' is embodied in its implication on 'position'. A knowledge base that allows a system to utilize the semantics of the word 'move' may contain a rule: if X moved, then the position of X changed. Therefore, we follow the early formulation of AI (McCarthy, 1960; Croft, 1993) to include a 'commonsense' knowledge base KB in our formalism of NLP tasks.\n\nThat is, x belongs to class y_i if and only if based on the commonsense rules in KB and the instruction t, x entails z_i.\n\nSince people write articles based on similar KBs of commonsense, language models may be able to acquire the KB by modeling general text. Additionally, language models may learn to do reasoning with the rules in the KB, because articles generally contain statements that are logical and coherent and proceed like a proof induction process.", "b2_justification": "Authors acknowledge the reviewer’s concern, say they revised the paper to clarify Section 3 and link it to the formalism in Section 5.1, and point to Calcutec as an instantiation; however, they do not in this response give a direct, detailed explanation of how the knowledge base itself is constructed or used and request further guidance, so the claim is only partially addressed.", "b3_justification": "The paper defines a commonsense knowledge base (KB) and states its formal role in the task formalism (Section 2) and hypothesizes that language models can acquire KB by modeling general text (Section 3.1). However, it does not provide concrete details or procedures for how such a KB is constructed, instantiated, or operationalized in experiments."}
{"claim": "The paper lacks empirical analysis or validation demonstrating that the assumptions in Section 5.1 hold in realistic data or model settings.", "claim_type": "experimental", "paper_id": "aaYBsuGRne", "paper_title": "Understanding In-context Learning with a Pelican Soup Hypothesis", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "EIVr3uVfUn", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We then instantiate the abstraction/framework with Calcutec and show that LMs trained with it can do in-context learning.\"", "b3_evidence": "\"First, we synthesize a dataset called Calcutec that replicates the linguistic phenomena and show that language models trained with this dataset acquire in-context learning ability and benefit from chain-of-thought.\"; \"Second, our experiment of GPT-2 on some natural language tasks shows the linkage between one of the linguistic phenomena and in-context learning.\"; \"Finally, in §7, we study the distribution shift caused by the absence of reasoning steps with a digit addition task. We find that larger models are better at gaining an intuition that allows them to jump to a conclusion without reasoning steps.\"", "b2_justification": "The authors report empirical instantiation of their assumptions (via the Calcutec dataset and experiments replicating distribution shifts) and clarify the link between Sections 3 and 5.1, but they also acknowledge limitations (e.g., inability to explain domain bias) and do not fully demonstrate the assumptions hold broadly in realistic data/model settings.", "b3_justification": "The paper does include some empirical validation (synthetic Calcutec experiments in §5 and a GPT-2 experiment on natural language in §6, plus digit-addition experiments in §7) that touch on assumptions related to coreference and absence-of-reasoning shifts. However, it does not provide a comprehensive empirical analysis showing that all of the concrete assumptions listed in §5.1 hold across realistic data or model settings, so the reviewer's claim is only partially true."}
{"claim": "The proposed approach only captures concepts describable as image parts and may fail to capture whole-image concepts such as lighting or global illumination.", "claim_type": "methodology", "paper_id": "UqZecMwLTo", "paper_title": "A Unified Concept-Based System for Local, Global, and Misclassification Explanations", "paper_venue": "iclr2024", "paper_decision": null, "decision": "Unknown", "review_id": "Xnu3bVVbeW", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "No, the current version of the method is not able to detect abstract and complex concepts like brightness or daylight, which are challenging concepts necessitating additional pre/post-processing tasks.", "b3_evidence": "Section 2: \"Each of these images can be segmented into k segments/superpixels, i.e., for sample x_c_i, a set of segments as S^c_{x_i} = { s^c_{i,1}, s^c_{i,2}, ..., s^c_{i,k} } is obtained. Each segment is padded with zero value up to the original input size and labeled with the corresponding target class.\" | Section 3: \"This method utilizes surrogate models and auxiliary datasets to identify the most influential part(s) of the images and is developed using a set of super-pixelated images of the given target class\" | Section 3 (Local concepts): \"To extract the local concepts of an unseen image x_i with respect to the class c, the image is first segmented and all its initial concepts are collected in S_{x_i}... the p highest-scoring ones are selected as the local concepts of sample x_i.\" | Section 3 (Concept extraction / global): \"the embeddings of a set of candidate local concepts, associated with a set of unseen images, are clustered and the g top groups, indicated with their best samples, are selected as the global concepts.\"", "b2_justification": "The authors explicitly acknowledge the limitation: the current method cannot detect abstract or global image concepts like brightness or daylight and they report this as a limitation in the paper and appendix.", "b3_justification": "The paper defines concepts as superpixels/segments and builds both local and global concepts from those segments (local concepts are selected from segmented parts; global concepts are formed by clustering embeddings of local segments). There is no discussion of representing or scoring whole-image, non-local concepts such as lighting or global illumination, so the claim that the approach captures concepts describable as image parts and may miss whole-image concepts is supported."}
{"claim": "Comparative methods like LIME, SHAP, GradCAM, and LRP produce off-manifold concepts, which likely leads to lower evaluation scores than on-manifold UCBS.", "claim_type": "baseline", "paper_id": "UqZecMwLTo", "paper_title": "A Unified Concept-Based System for Local, Global, and Misclassification Explanations", "paper_venue": "iclr2024", "paper_decision": null, "decision": "Unknown", "review_id": "Xnu3bVVbeW", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "Examples of the response content without addressing the claim: \"The proposed approach is certainly not the first to explore the extraction of local and global explanations, please refer to [1, 2].\"; \"Surrogate models are indeed binary classifiers that try to fully comprehend the target of interest.\"; \"No, the current version of the method is not able to detect abstract and complex concepts like brightness or daylight, which are challenging concepts necessitating additional pre/post-processing tasks.\"", "b3_evidence": "\"a recent study has shown that external scoring tools may be vulnerable methods against the perturbed input samples Uesato et al. (2018); Brown & Kvinge (2021). Additionally, they may mistakenly overestimate the concepts' importance, which makes it potentially unfaithful and sensitive to irrelevant concepts Schrouff et al. (2021).\"", "b2_justification": "The authors' response does not address the reviewer's specific claim about comparative methods (LIME, SHAP, GradCAM, LRP) producing off-manifold concepts or how that causes lower evaluation scores compared to UCBS. Their replies cover other points (related work, surrogate training data, and limitations regarding abstract concepts) but make no mention of those comparative methods or the off-manifold issue.", "b3_justification": "The paper criticizes external scoring tools as vulnerable to perturbed inputs and potentially unfaithful (Introduction), and it proposes UCBS as an alternative that uses surrogate networks and auxiliary data to learn concepts. However, it does not explicitly state that LIME, SHAP, GradCAM, or LRP produce \"off-manifold concepts,\" nor does it directly claim that such off-manifold concepts cause those methods to obtain lower evaluation scores than UCBS."}
{"claim": "The sentence in line 50 ('That is, the prediction is a single (potentially high-dimensional) point (or maybe a small number of such points).') is hard to read.", "claim_type": "presentation", "paper_id": "JEKXTLjEIq", "paper_title": "Binary Search with Distributional Predictions", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BELGkUQqxK", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We agree that the proof of our specific claim, that one cannot black-box reduce to a single point prediction, does not directly imply that one cannot reduce to *collections* of point predictions.\"", "b3_evidence": "That is, the prediction is a single (potentially high-dimensional) point (or maybe a small number of such points).", "b2_justification": "The authors discuss the technical content around single-point vs. distributional predictions, but they do not acknowledge or promise to rephrase or clarify the specific sentence in line 50 that the reviewer called \"hard to read.\" There is no explicit response addressing sentence readability or a commit to rewrite that line.", "b3_justification": "The paper contains the quoted sentence, but whether it is \"hard to read\" is a subjective assessment not addressed in the paper itself. The document does not comment on the readability of its own sentences, so this claim cannot be verified from the paper content."}
{"claim": "The phrase 'essentially optimal' is used without clarifying algorithmic complexity, hidden constants, or precise approximation guarantees.", "claim_type": "methodology", "paper_id": "JEKXTLjEIq", "paper_title": "Binary Search with Distributional Predictions", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BELGkUQqxK", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We will certainly include the discussions of model 1 and 2, and more comparison to Lin et al., in the paper as you suggest.\" \"Setting the exponential coefficient of d to a small constant is preferable for improved empirical results, and does not change the asymptotic complexity.\" \"We note that in model 2, the time complexity is basically equivalent to the query complexity. ... And then once the BST is built, the time it takes to search in it is essentially equal (up to constants involving following pointers) to the query complexity that we analyze. So in this setting, the query complexity *is* the time complexity!\"", "b3_evidence": "Abstract: \"We complement this with a lower bound showing that this query complexity is essentially optimal (up to constants)\"; Section 1.1: \"we give an algorithm with query complexity O ( H ( p ) + log η )\"; Section 1.1 (Worst case lower bound): \"no algorithm can use fewer than Ω(log η) queries in the worst case. Since Ω( H ( p )) is a known lower bound as well ... this implies that our algorithm is asymptotically tight.\"", "b2_justification": "Authors acknowledge time vs. query complexity and promise to add discussions, and they note asymptotic invariance of a tuning constant; however they do not provide the missing hidden constants or precise approximation guarantees the reviewer requested.", "b3_justification": "The paper does claim the algorithm is \"essentially optimal (up to constants)\" and gives asymptotic bounds O(H(p) + log η) and matching lower bounds (Ω(log η) and known Ω(H(p))). However, it does not state the explicit hidden constants or a precise approximation factor for the combined bound—only asymptotic/\"up to constants\" phrasing—so the reviewer's criticism is partially correct."}
{"claim": "If separate predictions are provided per query, the proposed algorithm appears to require rebuilding a binary search tree for each query, implying O(n) time per query.", "claim_type": "methodology", "paper_id": "JEKXTLjEIq", "paper_title": "Binary Search with Distributional Predictions", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BELGkUQqxK", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We note that in model 2, the time complexity is basically equivalent to the query complexity. In this model, there is a single distribution over queries, so the time to build our BST is just preprocessing – we expect to answer far more queries than the time it takes to build the BST ... And then once the BST is built, the time it takes to search in it is essentially equal (up to constants involving following pointers) to the query complexity that we analyze. So in this setting, the query complexity *is* the time complexity!\"", "b3_evidence": "Main algorithm. We then give our main result in Section 3: an algorithm which interleaves phases of the 'median' algorithm and classical binary search to obtain a query complexity of O ( H ( p ) + log η ) , where η is the earth mover's distance (EMD, also known as the Wasserstein W 1 metric) between p and ˆ p ...\n\nDistributional Robustness of Optimal Binary Search Trees. ... So we can interpret our results as providing distributionally-robust optimal BSTs: given ˆ p , we can efficiently compute a BST where the expected lookup time under the true (but unknown) query distribution p is at most O ( H ( p ) + log η ) .", "b2_justification": "The authors explicitly dispute the need to rebuild the BST per query by explaining that in model 2 the BST construction is preprocessing amortized over many queries, and thereafter each query's time equals the analyzed query complexity rather than O(n) per query.", "b3_justification": "The paper describes an online algorithm for the per-query prediction setting that interleaves median-based and classical binary search and gives a per-query comparison bound of O(H(p) + log η) (Section 1.1). It does not state that a binary search tree must be rebuilt per query; moreover, for the single-distribution setting the paper explicitly says a BST can be computed efficiently once given ˆp. Thus the claim that the proposed algorithm requires rebuilding a BST for each query (implying O(n) time per query) is not supported and is contradicted by the paper."}
{"claim": "The paper fails to compare or highlight differences between their uncertainty formulation and Semantic-NeRF's uncertainty formulation.", "claim_type": "baseline", "paper_id": "SgjAojPKb3", "paper_title": "OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ua8o7e9n4j", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In our work, we compute the _generalized variance_ over high-dimensional OpenSeg/CLIP features projected to a single 3D point. SemanticNeRF computes the _entropy_ of the per-semantic-class probability distribution for each 2D pixel. Both metrics are used to quantify uncertainty, however what they measure is different:\" ... \"Unlike SemanticNeRF which computes the entropy only for analyses, in our work, the generalized variance guides the novel-view selection mechanism used to improve the open-set features.\"", "b3_evidence": "1) \"We identify the disagreement from multiple views as a powerful signal and propose a probabilistic approach to generate novel view points.\" 2) \"While OpenScene (Peng et al., 2023), OpenMask3D (Takmaz et al., 2023a), and LERF (Kerr et al., 2023) demonstrate impressive capability of segmenting any given concept, they still suffer from several limitations.\"", "b2_justification": "The authors directly compare their uncertainty metric to SemanticNeRF's, explain the fundamental difference (generalized variance over open-set features vs. entropy over semantic-class probabilities), and state how their measure is used to guide novel-view selection while SemanticNeRF uses entropy for analysis only.", "b3_justification": "The paper describes its own probabilistic/view-disagreement mechanism for selecting novel views (i.e., an uncertainty-like formulation) and compares to prior works like LERF and OpenScene, but it does not mention or compare against Semantic-NeRF or its uncertainty formulation anywhere in the text."}
{"claim": "The paper includes few in-the-wild examples and relies primarily on the Replica dataset for evaluation.", "claim_type": "experimental", "paper_id": "SgjAojPKb3", "paper_title": "OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ua8o7e9n4j", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We provide additional results on the ARKitScenes [Baruch et al. NeurIPS’21] dataset in the attached supplementary material.\"; \"In the __attached supplementary we show additional “in-the-wild” real-world results__ on the ARKitScenes dataset which consists of iPhone RGB-D recordings with imperfect poses in natural environments.\"", "b3_evidence": "“For 3D point cloud segmentation on the Replica dataset, OpenNeRF outperforms recent open-vocabulary methods such as LERF and OpenScene by at least +4 . 9 mIoU.”\n\n“We identify the Replica dataset as a promising candidate to evaluate open-set 3D semantic segmentation since, unlike ScanNet ... or Matterport ..., it comes with very accurate mesh reconstruction, per-point semantic labels as well as a long-tail class distribution (see Fig. 4).”\n\n“OpenNeRF significantly outperforms the current state-of-the-art for open-vocabulary 3D segmentation with an +4 . 5 mIoU gain on the Replica dataset.”\n\n“Zero-shot results on Replica (Straub et al., 2019).”", "b2_justification": "The authors explicitly acknowledge the limitation and report having added additional real-world, in-the-wild experiments on a large-scale dataset (ARKitScenes), providing supplementary results and discussion to address the reviewer's concern.", "b3_justification": "The paper repeatedly emphasizes evaluation on the Replica dataset (reports quantitative gains on Replica and shows qualitative 'zero-shot results on Replica') and discusses Replica as the chosen benchmark; it does not describe broader in-the-wild evaluations, consistent with the reviewer claim that the work relies primarily on Replica and includes few (if any) in-the-wild examples."}
{"claim": "The proposed notion of post-purification robustness assumes the purified DNN will encounter further fine-tuning, which may not hold in many deployment scenarios.", "claim_type": "methodology", "paper_id": "qZFshkbWDo", "paper_title": "Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "Ni8p8ZQbkI", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Due to the substantial computational costs associated with large-scale experiments, we initially examine and verify this crucial issue, post-purification robustness, using smaller datasets and models in this study. We will follow your question and incorporate our discussions into both a separate section and the Limitation section in the revised version.\"; \"This is very vital since more models are becoming available for users' further fine-tuning after undergoing safety tuning. Our research initially demonstrates this feasibility with small-scale datasets and models.\"", "b3_evidence": "\"We find that current safety purification methods are vulnerable to the rapid re-learning of backdoor behavior, even when further fine-tuning of purified models is performed using a very small number of poisoned samples.\" (Abstract) \n\n\"we employ the Retuning Attack (RA) where we first retune the purified models using an extremely small number of backdoored samples and tuning epochs.\" (1 Introduction) \n\n\"Since the vulnerability revealed by the Retuning Attack (RA) relies on the use of retuned models, we further propose the more practical Query-based Reactivation Attack (QRA). This attack is capable of generating sample-specific perturbations... simply by querying these purified models.\" (1 Introduction)", "b2_justification": "Authors acknowledge limitations and promise to add discussion/limitations, but also defend the relevance of the assumption by arguing many models will be further fine-tuned and present initial supporting experiments—so they neither fully accept the reviewer's concern nor fully contradict it.", "b3_justification": "The paper evaluates \"post-purification robustness\" primarily via a Retuning Attack (RA) that explicitly fine-tunes purified models with a few poisoned samples, so it does analyze the scenario where models undergo further fine-tuning. However, the authors do not strictly assume fine-tuning is the only threat: they explicitly introduce a Query-based Reactivation Attack (QRA) to show reactivation can occur via querying without further fine-tuning. Thus the reviewer claim is partially accurate (RA is a core evaluation) but incomplete because the paper also covers non-fine-tuning (query-only) reactivation."}
{"claim": "The paper does not sufficiently justify the real-world implications of its threat model, leaving uncertainty about its practical relevance.", "claim_type": "subjective", "paper_id": "qZFshkbWDo", "paper_title": "Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "Ni8p8ZQbkI", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Due to the substantial computational costs associated with large-scale experiments, we initially examine and verify this crucial issue, post-purification robustness, using smaller datasets and models in this study. We will follow your question and incorporate our discussions into both a separate section and the Limitation section in the revised version.\"", "b3_evidence": "1) \"we further propose the practical Query-based Reactivation Attack (QRA) which could effectively reactivate the backdoor by merely querying purified models.\" (Abstract)\n2) \"Note that data-poisoning attacks are more practical in real-world scenarios as they make fewer assumptions about the attacker's capabilities [5, 15, 41].\" (Related Work)\n3) \"This is particularly important because purified models are often used in various downstream scenarios, such as customized fine-tuning [37] for critical tasks [20].\" (Introduction)", "b2_justification": "The authors acknowledge the reviewer’s concern, explain the limitation (use of small datasets/models due to computational cost), claim their work provides an initial demonstration of practical relevance, and promise to add discussion and limitations in the revised paper — but they do not yet provide full real-world empirical justification on large-scale models.", "b3_justification": "The paper claims the threat model (data-poisoning backdoors) and the proposed Query-based Reactivation Attack (QRA) are practical (Intro, Related Work, Abstract) but does not provide detailed real-world case studies, deployment scenarios, or empirical evidence demonstrating feasibility in operational settings. Thus the reviewer’s claim that the paper does not sufficiently justify real-world implications is partially true: the paper asserts practicality but lacks in-depth justification of practical relevance."}
{"claim": "The paper lacks details on how the image encoder accepts increased numbers of input views.", "claim_type": "methodology", "paper_id": "2dfBpyqh0A", "paper_title": "Gaussian Graph Network: Learning Efficient and Generalizable Gaussian Representations from Multi-view Images", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "J9ZvJzmWl3", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Φ_{image} in Eq. (1) of GGN refers to multi-view feature extraction, cost volume construction and cost volume refinement.\"; \"The cost volume part does cost a lot of time and memory when the number of views increase, as you mentioned.\"; \"We further conduct efficiency experiments and correct the inference time of each part more detailedly.\"", "b3_evidence": "\"Given N input images I = { I i } ∈ R N × H × W × 3 and their corresponding camera parameters C = { c i } , we follow the instructions of pixelSplat [4] and MVSplat [6] to extract image features: ... where Φ_image is a 2D backbone. We predict the means and features of pixel-aligned Gaussians: ... where Φ_depth and Φ_feat stand for neural networks to predict depth maps and Gaussian features, and ψ_unproj is the unprojection operation.\"", "b2_justification": "The authors acknowledge the confusion, admit a prior reporting mistake, and provide explicit clarification and measured breakdowns showing how the image encoder (including cost-volume steps) scales with increasing numbers of input views.", "b3_justification": "The paper only states that it takes N input images and uses a 2D backbone (following prior works) to extract per-view features, but it does not describe concrete architectural or training details for how the image encoder handles increased numbers of input views or variable N beyond this high-level description."}
{"claim": "The paper fails to explain which coding scheme is used, what specific test is used, and how Q(t|s) is chosen for the federated setting.", "claim_type": "methodology", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we use a BCH code (length 15) for the experiments in the main body and a cyclic code (length 31) in Appendix J.\" | \"the validation dataset utilized in our instantiation of FedGT is purely due to the testing strategies that rely on the group accuracy and the group recall, respectively.\" | \"For sake of clarification, we model the noisiness of the test $Q(t_i\\lvert s_i)$ as a BSC ... Then, we treat the overall noise of the tests to kick-start the backward recursion in the forward-backward decoder $Q(\\mathbf{t}\\lvert \\mathbf{s})$ as $m$ (size of $\\mathbf{t}$) parallel BSC with crossover probability $p$.\"", "b3_evidence": "“A suitable choice for A is the parity-check matrix of a powerful error-correcting code, i.e., with good distance properties. Furthermore, d can be inferred by applying conventional decoding techniques.”; “The central server then applies a test t : u →{0,1} to the aggregate model for each test group ... We remark that the proposed framework is general and can be applied to any test on the test group aggregates.”; “In general, the (noisy) test vector t is statistically dependent on the syndrome vector s according to an (unknown) probability distribution Q(t|s).”", "b2_justification": "The authors explicitly specify the codes used, describe the testing strategy, and explain their choice for Q(t|s) (BSC model) and alternatives, so they address each part of the reviewer's claim.", "b3_justification": "Section 4 describes the design choices only at a high level and explicitly leaves them unspecified: the assignment matrix A is suggested in general to be a parity-check matrix of a code (no specific code named), the test t is described abstractly and the framework is said to be applicable to any test, and the test noise distribution Q(t|s) is stated to be (unknown). Thus the paper does not explain which specific coding scheme, which specific test, nor how Q(t|s) is chosen for the federated setting."}
{"claim": "The paper does not report how many clients are securely aggregated by the baseline [2], preventing fair apples-to-apples comparisons.", "claim_type": "baseline", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The RFA protocol securely computes the geometric median among all clients. Hence, as the reviewer points out, the RFA protocol performs secure aggregation on all of the clients. Although this provides more privacy than FedGT, we would like to emphasize that our scheme allows for identification and may be run in a single round.\"", "b3_evidence": "Abstract: \"We further show that FedGT significantly outperforms the private robust aggregation approach based on the geometric median recently proposed by Pillutla et al. on heterogeneous client data (ISIC2019) and in the presence of targeted attacks (CIFAR-10 and ISIC2019).\"\nRelated Work: \"In (Pillutla et al., 2022), a robust aggregation protocol (dubbed RFA) based on an approximate geometric median (computed exploiting secure aggregation) is proposed. However, this protocol lacks the capability to identify malicious clients and is known to be inferior to other robust aggregation techniques, especially when dealing with heterogeneous client data (Li et al., 2023).\"", "b2_justification": "The authors explicitly acknowledge that the baseline (RFA) securely aggregates all clients and explain this privacy difference as the reason an exact apples-to-apples comparison is challenging, thereby addressing the reviewer's concern.", "b3_justification": "The paper discusses and compares to the baseline of Pillutla et al. (RFA) in the Abstract and Related Work, but nowhere in the provided content does it report how many clients the baseline securely aggregates (i.e., the group size or aggregation configuration), so the claim that this information is not reported is true according to the paper."}
{"claim": "The authors do not provide experiments that vary Λ to show its effects on FA and MD rates, attacker accuracy, and model clean accuracy.", "claim_type": "experimental", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Below, we present the results as the top-1 accuracy (ACC), attack accuracy (ATT), misdetection and false-alarm probabilities versus the decoding threshold Λ for n_m=1,2,3, respectively.", "b3_evidence": "1) \"By choosing the size, number, and overlap between groups, FedGT strikes a balance between privacy and security.\" (ABSTRACT)\n2) \"Figure 1: Attack accuracy MNIST (left), CIFAR10 (mid), and ISIC2019 (right) datasets for varying number of malicious clients.\" (INTRODUCTION / Fig. 1 caption)\n3) \"The performance of FedGT, measured in terms of the utility of the model, is affected by two quantities: the misdetection probability... and the false-alarm probability...\" (Section 4)", "b2_justification": "The authors explicitly acknowledge the concern and report new experiments that vary Λ, providing tables of P_FA, P_MD, attack accuracy (ATT), and top-1 accuracy (ACC) across multiple Λ values and n_m settings.", "b3_justification": "The provided paper text describes that group size/overlap are design choices and defines misdetection/false-alarm metrics, but no experiments are shown that vary a parameter named Λ (or explicitly vary group-design parameter to report its effect) to measure FA/MD, attacker accuracy, and clean accuracy. The only experimental figure mentioned varies number of malicious clients, not Λ."}
{"claim": "The paper does not quantify the communication complexity of the chosen coding strategies in the main text, relegating details to the appendix.", "claim_type": "quantitative", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“In Appendix B, we leverage state-of-the-art protocols to estimate and the communication overhead of our proposed framework. For the experiments in the main body, we would like to emphasize that, compared to RFA, the communication overhead of FedGT is lower or similar in all rounds, including when group testing is performed.”\n\n“Regarding the scaling, the main bottleneck is the decoding operation that has a complexity of \\mathcal{O}(2^m). Hence, as the number of tests grows, i.e., the number of rows in the assignment matrix, the decoder eventually becomes a bottleneck.”", "b3_evidence": "\"...significantly outperforming the recently-proposed robust federated aggregation (RFA) protocol based on the geometric median (Pillutla et al., 2022) for the CIFAR-10 and ISIC2019 datasets, while achieving a lower communication complexity.\"", "b2_justification": "The authors acknowledge communication/runtime costs and point to Appendix B for quantified estimates; they summarize that FedGT's communication overhead is lower or similar to RFA and discuss decoding complexity O(2^m). However, they do not move full quantification into the main text and rely on the appendix, so the reviewer's concern is only partially addressed.", "b3_justification": "The main text (Abstract, Introduction, and Sections 3–4 provided) asserts that FedGT achieves lower communication complexity but does not present any quantified communication-cost expressions or detailed complexity analysis in those sections. However, the claim that such details are 'relegated to the appendix' cannot be confirmed from the provided content because the appendix is not included."}
{"claim": "The authors claim cross-silo FL supports up to 100 devices but evaluate only 15 clients and fail to scale beyond 31 with more precise encodings.", "claim_type": "experimental", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We acknowledge that the experiments consider a low number of clients compared to the maximum according to our definition. As far as the authors are aware, practical instantiations of cross-silo FL have so-far involved client constellations of size 10... Hence, we chose the number of clients to be close to the numbers observed in practice.\"; \"Regarding the scaling, the main bottleneck is the decoding operation that has a complexity of \\mathcal{O}(2^m). Hence, as the number of tests grows... the decoder eventually becomes a bottleneck. Hence, provided a reasonable number of tests, FedGT scales to an arbitrary number of clients.\"; \"For the experiments involving n=31 clients, we consider n_m= 6 malicious clients. ... The rationale of this experiment is to demonstrate that FedGT scales beyond the experiments provided in the main body that includes only 15 clients.\"", "b3_evidence": ["Our focus is specifically on the cross-silo scenario, wherein the number of clients is moderate (up to 100 ) and data-poisoning is the predominant attack vector (Shejwalkar et al., 2022).", "Fig. 1 illustrates the performance of FedGT for a scenario with 15 clients and a targeted label-flipping attack."], "b2_justification": "The authors acknowledge that their experiments use a small number of clients and explicitly admit a decoding complexity bottleneck (O(2^m)) that limits scaling; they also report an experiment with n=31 to show some scaling beyond 15. They do not, however, provide empirical results up to 100 devices nor fully refute the reviewer's concern that precise encodings/decoding hinder scaling, so the reviewer's claim is only partially addressed.", "b3_justification": "The paper explicitly states the cross-silo setting is 'moderate (up to 100)' and presents an experiment scenario with 15 clients (Fig. 1), so the first two parts of the claim are supported by the paper. However, the paper does not mention any failure to scale beyond 31 clients nor any discussion of 'more precise encodings'; that part of the reviewer claim is not supported or addressed in the paper."}
{"claim": "Figure 4 uses a logarithmic scale for attacker accuracy, which can obscure interpretation and make non-log-distributed results hard to read.", "claim_type": "presentation", "paper_id": "rDgw3yX2aO", "paper_title": "FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "LjGi6U2LkK", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "- **Unusual behavior of \"no defense\" experiments with CIFAR-10 in Figure 4**: We believe this is a manifestation of the label-flip attack, which does not significantly alter the model parameters. Hence, before convergence, the benign client updates are implicitly weakening the label-flip attack as all the clients are equally contributing to the model, according to the FedAvg protocol.", "b3_evidence": "Figure 1: Attack accuracy MNIST (left), CIFAR10 (mid), and ISIC2019 (right) datasets for varying number of malicious clients.\n\nFigure 2: Bipartite graph (left) and trellis (right) representation of the assignment matrix A in Example 1.", "b2_justification": "The authors do not respond to the reviewer’s specific concern about using a logarithmic scale in Figure 4 or about obscured interpretation; they only offer an explanation for the unusual behavior in the plot (attributing it to the label‑flip attack) but do not address the plotting scale or readability issue.", "b3_justification": "The provided paper content does not contain Figure 4 nor any statement that a logarithmic scale is used for attacker accuracy. The document only shows Figure 1 (attack accuracy) and Figure 2 (bipartite graph), so there is insufficient information to verify the reviewer’s claim about Figure 4."}
{"claim": "The paper does not specify which model is used to generate prompts within the DeNEVIL framework.", "claim_type": "methodology", "paper_id": "m3RRWWFaVe", "paper_title": "DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "3cfg9Wjv21", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Though DeNEVIL is compatible with any LLMs, **we mainly used ChatGPT to generate MoralPrompt** for subsequent experiments unless otherwise specified, because of the high quality (Table 1) and satisfactory transferability (Fig.2 and Fig.3(b)) of the prompts generated by it.\"", "b3_evidence": "Input: ¬ v , β , τ 0 , T , K , M , p θ , p ω , the initial candidate sets X 0 = { x 0 } and Y 0 = { y 0 } Output: The optimized provocative prompt x ∗\n\nFor LLMs with strong instruction following abilities, e.g., ChatGPT, we directly provide ¬ v as an instruction in the prompt. For vanilla but open-source LLMs like LLaMA (Touvron et al., 2023), we transform the sampling in Eq.(1) to inference-time controllable decoding (Yang & Klein, 2021; Krause et al., 2021), regarding ¬ v as a classifier-based condition, with p ω introduced before, then: ...", "b2_justification": "The authors explicitly state which model they used: they clarify that ChatGPT was mainly used to generate the MoralPrompt (with other models used in some experiments) and note this has been specified in the revised paper (Sec. 3.2).", "b3_justification": "The paper describes DeNEVIL in generic terms using p_θ (the target LLM) and lists p_θ as an input to the algorithm, and only gives example models (e.g., ChatGPT, LLaMA) rather than specifying a single model used to generate prompts."}
{"claim": "Figure 2's finding that ChatGPT has the lowest misalignment may be biased because the moral prompt dataset could have been generated with ChatGPT.", "claim_type": "methodology", "paper_id": "m3RRWWFaVe", "paper_title": "DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "3cfg9Wjv21", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The lowest misalignment behavior of ChatGPT is **not** caused by the data generated by it.\"; \"To verify that the lowest misalignment is not attributed to using ChatGPT itself for DeNEVIL, we also utilized the weaker Vicuna-33B and stronger GPT-4 to generate additional 500 test prompts... We can observe that **using prompts generated by other LLMs, ChatGPT still obtains the lowest value violation**.\"", "b3_evidence": "1) \"DeNEVIL dynamically probes the value vulnerabilities in each model and then creates novel and tailored prompts co-evolving with LLMs, avoiding test data leakage (address Challenge 1).\" 2) \"Then we instantiate DeNEVIL with the Moral Foundations Theory ... to construct MoralPrompt, a dataset containing 2,397 prompts ... and benchmarked 27 LLMs across diverse architectures and scales.\" 3) \"DeNEVIL framework The key challenge ... we propose the DeNEVIL framework to explore each LLM's value vulnerabilities dynamically, and hence find the most provocative scenarios (prompts) x.\"", "b2_justification": "The authors directly refute the bias concern by reporting experiments where prompts were generated by other models (GPT-4 and Vicuna-33B); ChatGPT still showed the lowest value violation, so the low misalignment is not due to using ChatGPT to create the MoralPrompt dataset.", "b3_justification": "The paper states MoralPrompt was created by instantiating DeNEVIL, which 'dynamically probes the value vulnerabilities in each model' and 'creates novel and tailored prompts co-evolving with LLMs' to avoid data leakage. Thus the dataset is presented as generated per-target-model rather than produced solely by ChatGPT, so the specific bias alleged is contradicted by the paper's described methodology."}
{"claim": "The paper lacks comparison or explanation of computational cost and parameter count, raising concerns about the method's practicality and deployability.", "claim_type": "quantitative", "paper_id": "paobkszgIA", "paper_title": "End-to-End Video Semantic Segmentation in Adverse Weather using Fusion Blocks and Temporal-Spatial Teacher-Student Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BHq8fT4eAr", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "__Point 1: Comparisons with SFC and MoDA__\n\n_Parameters_\n\nSFC: 406 MB\n\nMoDA: 185MB (Motion part) + 169MB (Segmentation part)\n\nOurs: 173MB\n\n_Inference Speed_\n\nSFC: 0.38s+0.35s (SFC requires two stages, the first for generating robust optical flows, and the second for segmentation)\n\nMoDA: 0.19s+0.17s (Similar to SFC, MoDA also requires two stages)\n\nOurs: 0.11s\n\nAll the models we experimented with were run on a single RTX 3090.", "b3_evidence": "Our method achieves a performance of 25.4% and 33.0% mIoU on the adaptation from VIPER [28] and Synthia [29] to MVSS [18], respectively, representing an improvement of 4.3% and 5.8% mIoU over the existing state-of-the-art method.", "b2_justification": "The authors directly provide parameter sizes and inference-time measurements for their method and competitors and state the hardware used, thereby addressing the reviewer's concern about computational cost and deployability.", "b3_justification": "Across the Abstract, Introduction, contributions, and Proposed Method sections provided, the paper reports accuracy (mIoU) improvements and describes the fusion block and teacher-student training, but contains no discussion, comparison, or quantitative measurements of computational cost, runtime, FLOPs, or parameter count."}
{"claim": "The paper lacks in-depth discussion and theoretical justification for the proposed method, providing insufficient explanation of its underlying principles.", "claim_type": "methodology", "paper_id": "paobkszgIA", "paper_title": "End-to-End Video Semantic Segmentation in Adverse Weather using Fusion Blocks and Temporal-Spatial Teacher-Student Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BHq8fT4eAr", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We agree with the reviewer and will follow the suggection. Essentially, we plan to include the following discussion and would greatly appreciate any further feedback. ... We will incorporate the proposed mathematical equations and other feedback into our paper to enhance clarity for our readers.", "b3_evidence": "Abstract: \"The key idea of our fusion block is to offer the model a way to merge information from consecutive frames by matching and merging relevant pixels from those frames.\"  1 Introduction: \"We have developed a temporal-spatial teacher-student learning approach to effectively train the fusion block and enhance the quality of pseudo-labels.\"  3 Proposed method: \"Subsequently, the network processes the two inputs individually, producing separate sets of feature maps for each frame. These feature maps are then fused by the fusion block, resulting in the final prediction for the current frame.\"", "b2_justification": "Authors explicitly agree with the reviewer's concern and commit to adding mathematical descriptions and clarifications (including provided equations and statements of intent) to address the lack of theoretical explanation.", "b3_justification": "The paper describes the fusion block, temporal-spatial teacher-student scheme, and temporal augmentation at a conceptual and architectural level, but contains no detailed theoretical analysis, formal derivations, or in-depth justification of why the components should work (e.g., no theoretical guarantees, proofs, or analytical discussion). The provided sections focus on design intuition and implementation rather than theoretical principles."}
{"claim": "The reported accuracies for the 2-expert Mowst and its variant are only slight improvements compared to previous methods.", "claim_type": "baseline", "paper_id": "wYvuY60SdD", "paper_title": "Mixture of Weak and Strong Experts on Graphs", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "48z2642NVy", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "While the standard for “accuracy improvement” can be subjective, we believe the accuracy gain by the 2-expert Mowst is **clearly significant, strong & consistent**, by comparing with similar papers in the field.\nComparing the best accuracy among all 11 baselines with the best accuracy among all 5 Mowst models, the average accuracy improvement is high: **1.24**.", "b3_evidence": "Abstract: \"Mowst on 4 backbone GNN architectures show significant accuracy improvement on 6 standard node classification benchmarks...\"; Contributions/Introduction: \"We show consistent accuracy improvements over state-of-the-art baselines.\"", "b2_justification": "The authors explicitly disagree with the reviewer's characterization and present counter-evidence: they report consistent, statistically summarized accuracy gains (including average improvements and per-backbone numbers) and state the improvements are \"clearly significant, strong & consistent.\"", "b3_justification": "The paper explicitly states that Mowst achieves \"significant accuracy improvement\" on benchmarks and \"consistent accuracy improvements over state-of-the-art baselines,\" which contradicts the reviewer's claim that reported accuracies are only slight improvements."}
{"claim": "The paper does not analyze whether extremely wide networks would fall into the lazy training regime or how varying width influences the reported phenomena.", "claim_type": "experimental", "paper_id": "BxHgpC6FNv", "paper_title": "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "2KLOTeJSAm", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Yes, our result holds for any width $m \\geq C n^{0.01}$ and does not require an upper bound on $m$. The same results hold even if $m$ is extremely large.\n\nWe emphasize that the setting we consider is different from the “lazy training” / “neural tangent kernel (NTK)” regime, even if the width goes to infinity. This is because we consider a smaller initialization scale than that in the NTK regime. One way to see this difference is that our weight matrix W goes far from its initialization after one step of gradient descent (since step size $\\alpha$ is much larger than the initialization scale), while in the NTK regime the weight matrix will always stay close to its initialization. Therefore, even with infinite width, the setting we consider is not in the lazy training/NTK regime.", "b3_evidence": ["Our proofs rely on analyzing the feature learning behavior of individual neurons over the gradient descent trajectory, which reveals that the network implements a non-generalizable linear classifier after one step and gradually learns generalizable features in later steps.", "We consider a two-layer neural network of width m of the form ...", "We define W = [w_1, ..., w_m] ∈ R^{p×m} and a = [a_1, ..., a_m]^⊤ ∈ R^m. We assume the second-layer weights are sampled according to a_j i.i.d. ∼ Unif{±1/√m} and are fixed during the training process."], "b2_justification": "The authors explicitly state their results hold for arbitrarily large width and argue the regime is not lazy/NTK even as width → ∞, giving a mechanism (small initialization and large step size causing weights to move far from initialization).", "b3_justification": "The paper focuses on feature learning in two-layer ReLU networks of width m and proves one-step catastrophic overfitting and later grokking via neuron alignment, but it contains no analysis of extremely wide networks, the lazy/NTK regime, or how varying the network width m affects the phenomena."}
{"claim": "The proposed algorithms rely on standard techniques like pessimism and maximum likelihood estimation, and the paper does not clearly establish technical novelty.", "claim_type": "novelty", "paper_id": "XmkuQfWZAB", "paper_title": "On Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "pg25m3wQGF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "In fact, the goal of this paper is **not** to propose new algorithms but to propose a theory that seeks to explain the superior performance of preference-based methods that people observe in practice. We theorize this is because human rating feedback is less robust to bias than preference feedback, so we propose a new model for it, which we believe is closer to what actually happens in practice than existing models. New theoretical results for these classic algorithms are derived under our new observation model.", "b3_evidence": [{"quote": "Recently, [80; 78] proved the optimal policy can be learned from preference data in the offline setting with pessimism and maximum likelihood estimation (MLE) and analyzed the suboptimality.", "section": "Introduction"}, {"quote": "In this spirit, the algorithms we study in this work also use human feedback with pessimism.", "section": "1.1 RELATED WORKS"}, {"quote": "we first consider a new model for human rating data and analyze the suboptimality guarantees of the standard LCB algorithm under it.", "section": "Introduction"}, {"quote": "Through our models, we provide the first known suboptimality analysis for reward engineering with human rating in bandit problems and shed light on how human bias and uncertainty can adversely impact policy learning.", "section": "Introduction"}, {"quote": "we also consider a new model for human preference with human bias and compare the sample complexity of pessimistic MLE under this new model with the results for human rating.", "section": "Introduction"}], "b2_justification": "The authors acknowledge they are not proposing new algorithms and that they use standard methods (pessimism, MLE), but argue the novelty lies in a new observation/bias model and new theoretical results for those classic algorithms under this model, so they partly accept the reviewer's point while disputing its implication about overall novelty.", "b3_justification": "The paper indeed builds on standard techniques (pessimism, LCB, pessimistic MLE), so the first part of the reviewer claim is supported. However, the paper explicitly asserts novel contributions (new rating and preference models and the 'first known suboptimality analysis' for rating-based reward engineering), so the claim that the paper does not clearly establish technical novelty is contradicted by the authors' stated claims of novelty."}
{"claim": "The paper concludes that less bias explains human feedback success in practical LLMs, but the theoretical results do not sufficiently support this conclusion.", "claim_type": "subjective", "paper_id": "XmkuQfWZAB", "paper_title": "On Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "pg25m3wQGF", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Thus, our assumption that human rating feedback contains more bias is grounded.\" \"Nonetheless, we admit that the current assumption could be improved. We hope the reviewer could kindly consider that this is only the first work that studies the problem...\"", "b3_evidence": "1) \"Through this, our results seek to provide a theoretical explanation for the empirical successes of preference-based methods from a modeling perspective.\" 2) \"Altogether, our theory shows the advantage of the preference-based approach can be largely attributed to its modeling with mild human bias and uncertainty, which makes it reasonable to believe the great empirical success of preference-based methods is because human preference data is subject to less bias and uncertainty in practice.\" 3) \"The comparison reveals that the preference-based approach enjoys lower suboptimality than the rating-based approach when human bias is extreme in human rating.\" ", "b2_justification": "The authors acknowledge the reviewer’s concern and provide additional justifications (literature support, a contrapositive argument, and Section 5 analysis) to defend their assumption that ratings are more biased; they also admit the assumption could be improved and offer to revise the paper, so they neither fully concede the claim nor fully refute it.", "b3_justification": "The paper explicitly concludes that the empirical success of preference-based methods can be explained by preference data having milder bias/uncertainty (supported). However, the paper also presents theoretical suboptimality comparisons and claims that these results explain when and why preference feedback helps, so the reviewer's assertion that the theoretical results do not sufficiently support the conclusion is not consistent with the paper (contradicted). Because the claim contains one true and one false component, the correct overall judgment is ‘Partially Supported.’"}
{"claim": "The paper lacks a prominent, brief explicit acknowledgement of its limitations in the main text, for example a named section or subsection.", "claim_type": "presentation", "paper_id": "3hcn0UxP72", "paper_title": "Topological obstruction to the training of shallow ReLU neural networks", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "TCqYuDFZZx", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We will add this observation in the limitations section.\" \"We agree that the limitation section, expanded with the observations prompted by the reviews, needs to be included in the main paper and, if accepted, we will do so in the final version.\"", "b3_evidence": "\"The case with biases is discussed in Appendix E.\"", "b2_justification": "Authors explicitly agree with the suggestion and commit to include and expand a limitations section in the main paper.", "b3_justification": "The main text states assumptions and defers discussion of extensions (e.g. biases) to an appendix, but does not contain a dedicated, prominent 'Limitations' section or subsection acknowledging limitations in brief in the main body."}
{"claim": "Because the authors added additional figures, including appendix material into a 10-page submission may create a space shortage.", "claim_type": "presentation", "paper_id": "3hcn0UxP72", "paper_title": "Topological obstruction to the training of shallow ReLU neural networks", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "TCqYuDFZZx", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We agree that the limitation section, expanded with the observations prompted by the reviews, needs to be included in the main paper and, if accepted, we will do so in the final version.\"", "b3_evidence": [{"quote": "Details of the proof are provided in Appendix A.", "section": "3.1 One-hidden layer neural network"}, {"quote": "The case with biases is discussed in Appendix E.", "section": "3.1 One-hidden layer neural network"}, {"quote": "Figure 1: a. Depiction of the two group actions acting on the space of the network's parameters: the neuron rescaling of Equation (2) (top) and the neuron permutation of Equation (4) (bottom). b. Depiction of the geometry of the parameter space induced by the rescaling invariance of ReLU networks.", "section": "3.2 Symmetries and observationally equivalent networks"}], "b2_justification": "The authors do not address the reviewer's specific concern about space shortage or page limits resulting from adding figures/appendix material. Their response discusses technical points and agrees to move/expand the limitations section into the main paper, but never mentions space constraints or how they will fit additional figures into a 10-page submission.", "b3_justification": "The paper does refer to figures and multiple appendices (e.g., Appendix A and E, and Figure 1), but it does not discuss submission page limits, a 10-page submission, or any space/formatting constraints. Therefore the paper does not provide information to confirm or refute the reviewer's claim about creating a space shortage."}
{"claim": "Batch normalization may be unnecessary because addition of features and neighborhood features already introduces spatial characteristics.", "claim_type": "methodology", "paper_id": "ehfCxpDsrw", "paper_title": "LinNet: Linear Network for Efficient Point Cloud Representation Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "V28l1766Ei", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "1) \"Ignoring the removal of redundant calculations in the neighborhood and Batch Normalization (BN), the DSA module is depicted as:\" 2) \"Excluding the Batch Normalization and focusing only on neighbor feature computations for simplicity, ...\" 3) \"\\mathbf{f}_i' = \\text{BN} {\\mathcal{R} _{j:(i, j)\\in \\mathcal{N}} \\{\\overline{\\mathbf{f}}_j + \\text{PWConv}^{3 \\mapsto c}((\\mathbf{p}_j-\\mathbf{p}_i))} }\\.\"", "b3_evidence": "\"PWConv ... is an MLP that consists of pointwise convolution, batch normalization layer, and ReLU activation function.\"", "b2_justification": "The authors do not accept or reject the reviewer's claim that Batch Normalization is unnecessary. They explicitly state they 'ignore' or 'exclude' BN for analytic simplicity in parts of their explanation but retain BN in the DSA formulation, and they focus on weight initialization differences rather than addressing whether BN can be removed.", "b3_justification": "The paper does not state that batch normalization is unnecessary. It explicitly includes a batch normalization layer as part of PWConv in its feature extractor and does not discuss removing batch normalization or claim that adding features and neighborhood features makes batch normalization redundant."}
{"claim": "The paper does not provide a detailed empirical or theoretical comparison with the 'Exploitability minimization' algorithm.", "claim_type": "baseline", "paper_id": "TlyiaPXaVN", "paper_title": "Generative Adversarial Equilibrium Solvers", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "rCNKi8T07D", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"While Goktas and Greenwald observe that the exploitability minimization problem for *only one* pseudo-game can be expressed as a min-max optimization, it is not obviously true that one can minimize the expected exploitability via a min-max optimization problem. The novelty in our method lies in noticing that we can compute the expected exploitability after computing the expected cumulative regret, by optimizing over the space of best-response functions from pseudo-games to actions, rather than the space of actions individually for every pseudo-game.\"", "b3_evidence": "“Earlier approaches Duan et al. (2021a); Marris et al. (2022) do not extend even to continuous (non pseudo-)games, since evaluating the expected exploitability and its gradient over a distribution of pseudo-games requires solving as many convex programs as examples in the data set. Additionally, in pseudogames, the exploitability is not Lipschitzcontinuous, and thus its gradient is unbounded (Appendix D), hindering the use of standard ...”\n\n“Finally, we provide empirical evidence that GAES outperforms state of the art baselines in Arrow-Debreu competitive economies, and show that GAES can replicate existing qualitative analyses for pseudo-games...”", "b2_justification": "The authors provide a theoretical comparison and contrast to exploitability minimization (citing differences and novel aspects), but they do not present a detailed empirical comparison against that specific algorithm in their response.", "b3_justification": "The paper does discuss and theoretically critique prior 'exploitability minimization' approaches (citing Duan et al. (2021a) and Marris et al. (2022)) and explains why those methods fail to extend to pseudo-games (non-Lipschitz exploitability, unbounded gradients). However, the provided content does not show a detailed empirical comparison specifically against an 'Exploitability minimization' algorithm—only a general statement that GAES \"outperforms state of the art baselines\" without naming or detailing that specific baseline—so the claim is only partially accurate."}
{"claim": "The relevance of Daskalakis et al. (2009) to the min-max optimization discussion in Footnote 4 is unclear and unexplained.", "claim_type": "presentation", "paper_id": "TlyiaPXaVN", "paper_title": "Generative Adversarial Equilibrium Solvers", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "rCNKi8T07D", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Thank you for pointing this citation out. It seems that we accidentally cited the wrong paper from Daskalakis et al., while we sought to cite [2].", "b3_evidence": "\"Although the computation of GNE is intractable in the worst-case (Chen & Deng, 2006; Daskalakis et al., 2009; Chen & Teng, 2009; Vazirani & Yannakakis, 2011; Garg et al., 2017), in practice, applications may only require a solver that gives solutions with high accuracy in expectation over a realistic distribution of problem instances.\" \n\n\"By delegating the task of computing a best-response to a discriminator, our method circumvents the issue of solving a convex program, yielding a training problem given by a min-max optimization problem whose objective is Lipschitz-continuous, for which gradients can be guaranteed to be bounded under standard assumptions on the discriminator and the payoffs of players.\"", "b2_justification": "The authors acknowledge the citation error and agree the referenced Daskalakis et al. paper was incorrect; they state they will fix the citation, thereby accepting the reviewer’s point that the original reference and its relevance were unclear.", "b3_justification": "In the Introduction the paper cites Daskalakis et al. (2009) only as part of a list of worst-case hardness results for computing GNE/CE, while the min–max/GAN training discussion appears separately and there is no explanation or footnote connecting Daskalakis et al. (2009) to the min–max optimization point. Thus the reviewer’s observation that the relevance is unclear and unexplained is accurate."}
{"claim": "The paper lacks visualizations of M and N; if they are learnable feature maps, the authors should provide visual examples or supplemental figures.", "claim_type": "methodology", "paper_id": "yURca4wi2L", "paper_title": "Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Gu6qnKVtKj", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"M and N are learnable parameters with shapes [H,W,Q1] and [T_res,Q1], respectively. ... Regarding the visualization of M (spatial feature map) and N (temporal feature map), we will include visualizations of the deformation grid (delta x and delta y) and M in the revised version. ... This visualization will help clarify the product of M and N for specific x, y, and t coordinates\"", "b3_evidence": "“S field queries the Canonical Spatial Feature Map ( C ) at the modified location ( x +∆ x, y +∆ y ) to retrieve the corresponding feature from a trainable feature map.”\n\n“Regularization is applied by constraining the dimensions of the Temporal Feature Map. Similarly, reducing the size of the deformation MLP serves as additional regularization to promote temporal consistency.”", "b2_justification": "The authors explicitly acknowledge that M and N are learnable feature maps and state they will add visualizations (deformation grid and M) in the revised paper to clarify these maps and their product.", "b3_justification": "The paper explicitly describes learnable feature maps (a 'Canonical Spatial Feature Map (C)' and a 'Temporal Feature Map') in Section 3.1 but the provided content contains no visualizations or figures showing these maps or their learned contents. Thus the reviewer's claim that visualizations of these feature maps are lacking is true according to the paper."}
{"claim": "Without a latency breakdown, readers cannot estimate the expected overhead of adding the authors' module to a base ATM method.", "claim_type": "experimental", "paper_id": "yURca4wi2L", "paper_title": "Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Gu6qnKVtKj", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In the revised version, we will include a detailed runtime discussion, breaking down the time for DATUM (0.5 mins) and our method (9.5 mins). ... However, we agree that discussing the runtime of each method, particularly with the breakdown for DATUM, is crucial.\"", "b3_evidence": "1) \"To address this temporal inconsistency issue, in addition to better simulators, enlarging the dataset and model capacity are necessary, which substantially increases the computational costs of training.\" 2) \"Regularization is applied by constraining the dimensions of the Temporal Feature Map. Similarly, reducing the size of the deformation MLP serves as additional regularization to promote temporal consistency.\"", "b2_justification": "The authors explicitly acknowledge the need for a runtime breakdown and commit to including a detailed runtime discussion with specific timing figures in the revised paper, directly addressing the reviewer's concern about overhead estimation.", "b3_justification": "The paper does not provide any latency or runtime breakdown, only qualitative statements about computational cost and architectural choices. Because no timing, FLOPs, or runtime-overhead numbers are given for adding the proposed module to a base ATM method, readers cannot estimate the expected overhead from the paper text."}
{"claim": "The paper does not compare HydraLoRA with LoRA at higher ranks (r=16 or r=32), which would be a fairer baseline.", "claim_type": "baseline", "paper_id": "qEpi8uWX3N", "paper_title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning", "paper_venue": "neurips2024", "paper_decision": "Accept (oral)", "decision": "Oral", "review_id": "hA9JXs1a2I", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "From Table 2, we can observe that:\n\n- Compared to LoRA with Rank=16, HydraLoRA with the **same** parameters improves performance by **up to 2.61% and 2.05% on average**. \n- Compared to LoRA with Rank=32, HydraLoRA uses only **half** the parameters, while improving performance by **up to 1.60% and 1.29% on average**.", "b3_evidence": "Table 1: Performance on instruction tuning with Dolly-15K [8] and evaluated with MMLU [16] with different ranks. ... | LoRA | 16 × 1 | 45.45 | 0.124 |  | LoRA | 32 × 1 | 46.59 | 0.248 |  | LoRA (Split) | 16 × 2 | 46.82 | 0.248 | ...", "b2_justification": "The authors explicitly state that Table 2 compares HydraLoRA to LoRA at rank=16 and rank=32 and report quantitative improvements, directly addressing the reviewer's concern.", "b3_justification": "Table 1 (in Section 2.3) shows LoRA results at r=16 and r=32 but does not include any HydraLoRA rows or a direct comparison of HydraLoRA vs LoRA at those higher ranks in the provided content, so the claim that such a comparison is missing is accurate based on the shown material."}
{"claim": "The paper lacks an ablation experiment training the LLaMA-based model solely on GPT-4 data to isolate the effect of low-quality data.", "claim_type": "experimental", "paper_id": "AOJyfhWYHf", "paper_title": "OpenChat: Advancing Open-source Language Models with Mixed-Quality Data", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "B8hxyc42tI", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "", "b3_evidence": "Abstract: \"Finally, we design a series of ablation studies and analyses to validate the contribution of different components, and performance consistency...\"; Sec. 3: \"Taking the most popular SFT dataset ShareGPT used in Vicuna ... the distinct data sources from GPT-4 and GPT-3.5 can be regarded as D_exp and D_sub, as the overall quality of GPT-3.5 conversations generally falls short when compared to that of GPT-4 conversations...\"", "b2_justification": "Error during labeling: Unterminated string starting at: line 1 column 290 (char 289)", "b3_justification": "The provided paper excerpt states that ablation studies were conducted (Abstract) and describes using GPT-4 as expert data and GPT-3.5 as suboptimal data (Sec. 3). However, the excerpt does not include experimental details or results that explicitly show an ablation where the LLaMA-based model is trained solely on GPT-4 data to isolate the effect of low-quality data, so this specific claim cannot be verified from the provided content."}
{"claim": "The paper does not investigate the impact of small m and large variations in label proportions across sets on generalizability with respect to m and n_i.", "claim_type": "experimental", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": ["\"Thank you for your valuable suggestion. We have conducted experiments specifically designed for the case of small values of $m$. The experimental results are reported in Table 3.\"", "\"We also conducted additional experiments on the MNIST, Kuzushiji, and Fashion datasets with imbalanced classes. ... The experimental results are reported in Table 4.\"", "\"We conducted experiments on variants $m$ and $n_i$ and showed the experimental results in Appendix E.\""], "b3_evidence": "\"These differences make our studied MCMU more applicable than LLP. For example, MCMU can learn from an extremely small number of unlabeled sets\"; \"we assume that these class priors form a full column rank matrix θ : ' p θ_{ij} q P [0,1]^{m×k} ...\"; \"Experimental results on multiple benchmark datasets across various settings demonstrate the superiority of our proposed methods.\"", "b2_justification": "The authors explicitly state they conducted experiments for small m and for imbalanced/variable class priors (large variation in label proportions), and refer to multiple tables and appendices showing results for varied m and n_i, thereby addressing the reviewer's concern.", "b3_justification": "The paper mentions that MCMU can learn from an extremely small number of unlabeled sets and assumes class priors (θ) are given and form a full-column-rank matrix, but it provides no analysis or experiments that explicitly study how small m or large variations in label proportions across sets (or varying n_i) affect generalization. Theoretical assumptions constrain m (via rank of θ) but do not constitute an investigation of impact on generalizability."}
{"claim": "The paper does not clarify the difference between its Lemma 3.1 and Theorem 1 of Lu et al., ICML 2021.", "claim_type": "methodology", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Lemma 3.1 can be considered as a multi-class extension of Theorem 1 (only for binary classification) in Lu et al., ICML 2021. As we indicated in our paper, CCM is a multi-class extension of Lu et al., ICML 2021.\"", "b3_evidence": "“CCM can be viewed as a multi-class extension of Lu et al. (2021), following which we also consider the MCMU problem as a surrogate set classification problem... Then we theoretically showed that we can transform the posterior probabilities of ordinary labels to the posterior probabilities of surrogate sets, via a probability transition function.”\n\n“We propose a classifier-consistent method (CCM) based on a probability transition function, which can be considered as a multi-class extension of Lu et al. (2021).”", "b2_justification": "Authors directly explain that Lemma 3.1 is a multi-class extension of Theorem 1 in Lu et al. (which is for binary classification) and state that CCM is a multi-class extension of that prior work, thus explicitly addressing the requested clarification.", "b3_justification": "Throughout the provided paper text the authors only state that CCM is a multi-class extension of Lu et al. (2021) and describe their probability-transition approach, but there is no explicit discussion distinguishing their Lemma 3.1 from Theorem 1 of Lu et al. (ICML 2021). The manuscript does not clarify the difference between the two results in the shown sections."}
{"claim": "The paper fails to outline constraints on m and n required for practical significance, given that small label proportion differences may necessitate a large m.", "claim_type": "methodology", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Please refer to our response to Weakness 2, where we have conducted experiments on various values of $m$ and $n$.\"; \"We conducted experiments on variants $m$ and $n_i$ and showed the experimental results in Appendix E. Here we provide a detailed description of the additional experimental results.\"; \"The experimental results are reported in Table 1, Table 2, and Table 3. Our proposed RCM and CCM demonstrate stable performance with the increase in the number of sets and still outperform the baseline methods.\"", "b3_evidence": "\"We assume that these class priors form a full column rank matrix θ ...\"; \"Throughout the paper, we assume that the class priors of each unlabeled set are given, which means θ is accessible.\"; \"For example, MCMU can learn from an extremely small number of unlabeled sets, while most previous LLP methods that treat each set as a training unit cannot work well in this case.\"", "b2_justification": "The authors address the reviewer's concern by adding empirical experiments across various values of m and n (including small m and m<k) and reporting results, but they do not provide explicit theoretical constraints or clear guidelines on required m and n for practical significance when label-proportion differences are small.", "b3_justification": "The paper does impose a theoretical constraint on the number of unlabeled sets via the assumption that the class-prior matrix θ is full column rank (which implies a relation between m and k), but it does not provide practical guidance or explicit constraints on m or the per-set sample sizes n (e.g., sample complexity or how large m must be when class-prior differences are small). Thus the reviewer’s statement is partly correct: a theoretical requirement exists, but practical requirements on m and n are not outlined."}
{"claim": "The paper does not clearly state how test accuracies were computed.", "claim_type": "methodology", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We computed the test accuracies on the test set of widely used benchmark datasets, including MNIST, Fashion, Kuzushiji, CIFAR-10, and SVHN. We simply used the given test set and did not make modifications to the class size of the provided test set.\"", "b3_evidence": "Abstract: \"Experimental results on multiple benchmark datasets across various settings demonstrate the superiority of our proposed methods.\"; Main contributions: \"We conduct extensive experiments on benchmark datasets with various settings. Experimental results demonstrate that CCM works well but RCM consistently outperforms CCM.\"", "b2_justification": "The authors directly clarify how test accuracies were computed (they used the provided test sets without modifying class sizes) and provide additional details on imbalanced experiments, acknowledging and addressing the reviewer's concern.", "b3_justification": "The provided paper content mentions experimental results but contains no description of evaluation metrics or a procedure for computing test accuracies (no experimental setup, metrics, or evaluation protocol is given in the supplied sections). Therefore the claim that the paper does not clearly state how test accuracies were computed is supported by the content."}
{"claim": "The paper does not state whether test data were balanced across classes when reporting accuracies.", "claim_type": "experimental", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We computed the test accuracies on the test set of widely used benchmark datasets, including MNIST, Fashion, Kuzushiji, CIFAR-10, and SVHN. We simply used the given test set and did not make modifications to the class size of the provided test set.\" \"We also conducted additional experiments on the MNIST, Kuzushiji, and Fashion datasets with imbalanced classes.\"", "b3_evidence": "Experimental results on multiple benchmark datasets across various settings demonstrate the superiority of our proposed methods.", "b2_justification": "The authors directly state that test accuracies were computed on the datasets' provided test sets without modifying class sizes, and they additionally report experiments with explicitly imbalanced class settings, thus addressing the reviewer's concern.", "b3_justification": "The provided paper content (including the Abstract and Introduction) mentions experimental results but provides no information about whether test sets were balanced across classes when reporting accuracies. There is no statement describing test-data class balance or distribution in the included sections."}
{"claim": "The paper does not analyze whether class size variations in datasets influenced the reported performance differences.", "claim_type": "experimental", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We simply used the given test set and did not make modifications to the class size of the provided test set.\n\nWe also conducted additional experiments on the MNIST, Kuzushiji, and Fashion datasets with imbalanced classes. We constructed the class-imbalanced prior matrix by following a similar procedure to [1]. ... The experimental results are reported in Table 4. As can be seen from Table 4, our proposed methods RCM and CCM can still achieve satisfactory performance even under extreme class imbalance conditions.", "b3_evidence": "\"Throughout the paper, we assume that the class priors of each unlabeled set are given, which means θ is accessible.\"; \"Experimental results on multiple benchmark datasets across various settings demonstrate the superiority of our proposed methods.\"", "b2_justification": "The authors directly acknowledge the issue and report additional experiments that test class-imbalanced settings, describing the construction of imbalanced priors and presenting results (Table 4) showing method robustness under class-size variation.", "b3_justification": "The paper discusses class priors and reports experimental superiority but the provided content contains no analysis or ablation examining how variations in class sizes (class imbalance) across datasets affected the reported performance differences."}
{"claim": "Label proportions and class priors are practically equivalent in this context, so there is no clear dependence-based difference between MCMU and LLP.", "claim_type": "methodology", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "In the MCMU problem, the unlabeled set is sampled according to class priors. In our humble opinion, we think that using class priors is more appropriate for MCMU. Although class priors and label proportions seem to be practically equivalent concepts, they actually describe two different sampling processes. In LLP, the notion of \"label proportions\" means that we calculate the proportion of instances belonging to each class after generating the data according to the underlying data distribution $p(x,y)$.", "b3_evidence": "From the dependence perspective : In MCMU, given the class priors, the data points in the same set are independent on each other, while in LLP, given the label proportions, the data points in the same set are dependent from each other.", "b2_justification": "The authors explicitly state that 'label proportions' and 'class priors' are different notions and describe distinct sampling processes (LLP computes proportions after sampling (x,y), while MCMU sets class priors then samples labels and instances), thereby rejecting the reviewer's claim of practical equivalence from a dependence perspective.", "b3_justification": "The paper explicitly distinguishes MCMU from LLP and states a dependence-based difference: in MCMU data points in the same set are independent given class priors, whereas in LLP they are dependent given label proportions. Thus the claim that there is no clear dependence-based difference is contradicted by the paper."}
{"claim": "The paper should use the term 'label proportions' instead of 'class priors' within each set to avoid terminological confusion.", "claim_type": "presentation", "paper_id": "fW7DOHDQvF", "paper_title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "VC9qQQQ5cR", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In the MCMU problem, the unlabeled set is sampled according to class priors. In our humble opinion, we think that using class priors is more appropriate for MCMU. Although class priors and label proportions seem to be practically equivalent concepts, they actually describe two different sampling processes. In LLP, the notion of \\\"label proportions\\\" means that we calculate the proportion of instances belonging to each class after generating the data according to the underlying data distribution p(x,y).\"", "b3_evidence": "Abstract: \"...multiple sets of unlabeled data and their class priors (i.e., the proportion of each class) are provided...\"; Section 2.2: \"This supervision provides similar information compared with class priors.\"; Section 2.2: \"the supervision is the proportion of instances from each class.\"", "b2_justification": "The authors explicitly disagree with replacing 'class priors' by 'label proportions' for MCMU, arguing that the two terms describe different sampling processes and that 'class priors' is more appropriate for their setting.", "b3_justification": "The paper already uses and explicitly equates 'class priors' with the proportion of each class and also discusses 'label proportions' in the LLP context, so the suggested terminology change is unnecessary and the paper does not exhibit terminological confusion."}
{"claim": "The process by which test cases are described as 'randomly generated' and inserted into context files is not explained in the main paper or appendices L and Y.", "claim_type": "methodology", "paper_id": "JbOsMrwjZ3", "paper_title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "zqRMRjR9Zo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Our test cases can be thought of as typical unit tests with randomly generated parameters, hence why we are “inserting” randomly generated test cases into the code (more details given later).\" ... \"In terms of variable generation, we replace the <|var_type;parameter|> syntax with random values each iteration, for an unlimited number of iterations. These parameters are modifiable, and we implemented this system to be flexible, so that we can target specific scopes for fuzz testing. We check correctness by substituting the exact same variables in the original code, and checking if the outputs of the two functions match.\"", "b3_evidence": ["BIOCODER incorporates a fuzz-testing framework for evaluation.", "We offer a fuzzer testing tool capable of scaling to handle substantial datasets.", "Figure 2: A diagram of the BIOCODER construction process involving custom GitHub repository cleaning, parsing, and function selection, as well as context and test case creation and a massively dockerized testing framework."], "b2_justification": "The authors acknowledge the omission and directly explain their fuzz-testing approach, including that test cases are unit-test-like with randomly generated parameters and that the <|var_type;parameter|> syntax is replaced with random values each iteration and inserted into the context files; they state they will expand these details in the appendix/main text.", "b3_justification": "The paper only mentions a fuzz-testing framework and test-case creation at a high level (Abstract, Introduction, Figure 2) but provides no detailed description of the process for 'randomly generated' test cases or how they are inserted into context files in the main paper. The provided content also does not include or reference appendices L or Y with such details."}
{"claim": "For Rosalind functions, the authors do not explain why or how generated code outputs are compared with cached golden outputs, leaving the comparison procedure unclear.", "claim_type": "methodology", "paper_id": "JbOsMrwjZ3", "paper_title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "zqRMRjR9Zo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We admit that this is not clear. The “cached golden code output” refers to an optimization specific to Rosalind. We utilize the fact that we are given the same input for all test cases, and only run the golden code once, instead of running it 20 times in all 20 pairs of generated-golden code pairs. For Rosalind functions, the process is simpler and more efficient as the functions are less complex. During testing, the tester executes the generated code and golden code within the corresponding context with the same input, and the output of the pair of executions is considered correct if and only if they are identical.", "b3_evidence": "1) \"...we included an additional 253 questions from the Rosalind project.\" (Abstract / 1 INTRODUCTION)\n2) \"BIOCODER incorporates a fuzz-testing framework for evaluation.\" (Abstract)\n3) \"execution-based evaluation approaches... execute tests on the generated code to verify its functional correctness, ensuring unbiased evaluations irrespective of implementation method or style variations.\" (2.2 CODE GENERATION DATASETS AND BENCHMARKS)\n", "b2_justification": "Authors acknowledge the omission and explicitly explain the Rosalind evaluation: they describe the caching optimization, that the same input is used for both golden and generated code, and that outputs are compared for exact equality.", "b3_justification": "The paper states that it includes 253 Rosalind examples and describes a fuzz-testing / execution-based evaluation framework, but it does not describe any procedure for comparing generated outputs to cached golden outputs or explain why such cached outputs would be used. There is no text in the provided sections that details how Rosalind function outputs are compared to reference outputs."}
{"claim": "The implemented correction mechanisms for rectifying minor syntax and style errors are not defined, so it is unclear which errors are considered 'minor' and harmless to functionality.", "claim_type": "methodology", "paper_id": "JbOsMrwjZ3", "paper_title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "zqRMRjR9Zo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We admit that we did not describe the implementation details of this correction mechanism clearly.\n\nWe define “minor syntax errors” as errors that we are able to correct automatically with our heuristics. For example, StarCoder often “over-generates” code, so during one generation (even with dynamic generation limits), it could generate 3-4 functions at once, while we would only need the first one. In other words, the model doesn’t know when to stop generating.\n\nIn this case, we perform dynamic code analysis to potentially determine any relationships between functions, and retain the functions that are utilized in the target function, and remove all extraneous data. In other cases, we automatically correct mismatched brackets, missing semicolons, incorrect indentations, etc. so when inserted back into the context, it adapts accordingly.", "b3_evidence": "“BIOCODER incorporates a fuzz-testing framework for evaluation.”; “We provide a fuzzer testing tool capable of scaling to handle substantial datasets.”; “Early work on code generation benchmarks used lexical exact match, data flow, and abstract syntax tree (AST) methods. However, these measures proved to be unreliable ... In response, execution-based evaluation approaches have become more prevalent ... These approaches execute tests on the generated code to verify its functional correctness, ensuring unbiased evaluations irrespective of implementation method or style variations.”", "b2_justification": "The authors acknowledge the omission and explicitly define ‘minor syntax errors’ and the heuristic corrections they apply (e.g., removing extraneous over-generated functions, fixing mismatched brackets, missing semicolons, indentations) and describe using dynamic code analysis to retain relevant functions — directly addressing the reviewer’s concern.", "b3_justification": "The paper describes a fuzz-testing / execution-based evaluation setup (Abstract, Sec. 1, Sec. 2.2) but does not specify any correction or normalization mechanisms for handling minor syntax or style errors or define which errors are considered 'minor' and harmless. There is no text in the provided excerpts that defines error-correction rules or tolerances for non-functional deviations."}
{"claim": "The discussion of prompt effects is shallow and focuses on prompt length rather than analyzing prompt structure and content differences that may influence performance.", "claim_type": "methodology", "paper_id": "JbOsMrwjZ3", "paper_title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "zqRMRjR9Zo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Thank you for your suggestion. In response, we have added a new appendix AA to the manuscript discussing more analysis on the performance with the perspective of prompt structures and contents. We have also updated the 'Analysis and Discussion' section in the manuscript.\"; \"For more analysis regarding this and prompt structure in general, please refer to Appendix aa.\"; \"We created the prompt formats based on experimental experience. ... Uncommented/Summary at top/Summary at bottom - target performance on deciding which context to use, as there is intentionally some extraneous context not required for function. Summary Only - gather metrics on the level of dependency on context. Necessary Only - isolate purely the logical reasoning abilities of models, as we assume that all context is utilized.\"", "b3_evidence": "Abstract: \"Successful models accommodate a long prompt (> 2600 tokens) with full context, for functional dependencies.\"  Introduction: \"BIOCODER assures the inclusion of all potential external packages and code that could be utilized by the generated program... hence, we included all potentially required class declarations in the input.\"  Section 2.2: \"In addition, the context supplied greatly influences the performance of existing LLMs (Wang et al., 2022a).\"", "b2_justification": "The authors acknowledge the reviewer’s point and state they have added substantial analysis and explanations about prompt structures and contents (new appendix, updated Analysis/Discussion, and prompt-design guidelines), indicating they addressed the concern.", "b3_justification": "The paper's main explicit claim about prompt effects emphasizes prompt length and having the full context (e.g., >2600 tokens). While it notes that context influences performance and that BIOCODER includes contextual elements (imports, class declarations, globals), the provided sections do not present an analysis of prompt structure or content differences that might affect performance—only general statements and pointers to ablation appendices without detailed discussion in the main text."}
{"claim": "The paper does not state whether the five prompt styles were derived from prior literature, lectures, or experimental experience, leaving their provenance unspecified.", "claim_type": "methodology", "paper_id": "JbOsMrwjZ3", "paper_title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "zqRMRjR9Zo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“We created the prompt formats based on experimental experience. We set out to create prompt structures to test the specific performance characteristics of each model. We first decided on a set of characters to target, as shown in the following prompt types: Uncommented/Summary at top/Summary at bottom - target performance on deciding which context to use... For each of the goals, we experimented with slight modifications of each prompt structure until we found one that achieved the highest performance, best representing the performance of that specific characteristic.”", "b3_evidence": "\"(1) Successful models accommodate a long prompt (> 2600 tokens) with full context, for functional dependencies.\"", "b2_justification": "The authors explicitly state the provenance of the five prompt styles, saying they were created from experimental experience and describing the iterative testing and motivations behind each prompt type, thereby addressing the reviewer's concern.", "b3_justification": "The paper discusses prompt length and context (e.g., long prompts >2600 tokens) but does not describe any ‘five prompt styles’ or state whether prompt styles were derived from prior literature, lectures, or experimental experience. There is no provenance information for multiple prompt styles in the provided text."}
{"claim": "The paper does not justify why model editing is necessary given widespread use of APIs and their capabilities.", "claim_type": "subjective", "paper_id": "m0DS4OOmSY", "paper_title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Ys6GEBpHKH", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We believe that in the era of large models and APIs, model editing has become increasingly necessary, especially when resources are limited or when there are few errors that don’t justify full fine-tuning but still need correction.\"", "b3_evidence": "While directly fine-tuning an LLM on calibrated knowledge can help mitigate this problem, which is prohibitive due to hardware constraints and resource budget [9; 10; 11]. To this end, model editing [12; 13; 14] has been proposed to efficiently update knowledge within LLM.", "b2_justification": "The authors explicitly justify why model editing remains necessary despite APIs, listing concrete scenarios (limited resources, minor errors, rapid updates, regulated domains) where editing is preferable to fine-tuning or API use.", "b3_justification": "The paper motivates model editing primarily by arguing that fine-tuning is prohibitively expensive and that editing is an efficient alternative (Introduction), but it does not discuss or justify why editing is necessary in light of widely used API-based services or their capabilities — no discussion of APIs as an alternative is provided."}
{"claim": "The reviewer expects the method's computational cost to scale quadratically with the input dimension.", "claim_type": "quantitative", "paper_id": "jrNlWfor7q", "paper_title": "Kronecker-Factored Approximate Curvature for Physics-Informed Neural Networks", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "fjswa13z9o", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Therefore we empirically observe linear scaling in this regime, i.e. 'approximately' no dependency of the MLP w.r.t. $d_\\Omega$ and linear scaling from the number of forward passes for the Laplacian.\"; \"You are completely right though that if we let $d_\\Omega \\to \\infty$, e.g. for score matching with $d_\\Omega \\sim 10^6$, the empirical behavior would eventually become quadratic on this model.\"; \"However, for the PDE applications we target in this paper, we think that practically relevant values are $d_\\Omega \\sim 10^2$ (at most $10^3$). Therefore, we believe the empirical linear scaling we measured in this regime is representative for our method's scaling on PINN problems.\"", "b3_evidence": "\"Our goal is to evaluate first-and second-order partial derivatives of the form ∂ x_i u, ∂^2_{x_i,x_j} u for i, j = 1 , . . . , d .\" and \"For differential operators of special structure, we can fuse the Taylor-mode forward propagation of individual directional derivatives in Equations (5) and (6) and obtain a more efficient computation. E.g., to comp...\"", "b2_justification": "Authors argue that in the practically relevant input-dimension regime (d_Ω ≈ 10^2–10^3) they observe empirical linear scaling, but they also acknowledge that asymptotically (d_Ω → ∞) the cost would become quadratic, so they partially agree with the reviewer's expectation while disputing its practical relevance.", "b3_justification": "The paper explains that Taylor-mode must propagate first- and second-order directional derivatives ∂_{x_i}u and ∂^2_{x_i,x_j}u for i,j=1..d, which implies work over O(d^2) second-order directions in the general case. However, the authors also state that for differential operators with special structure (e.g. the Laplacian) this can be fused to a more efficient computation, reducing the cost, so quadratic scaling in input dimension is not always incurred."}
{"claim": "The paper omits critical details of the phylogenetic inference setup, specifically not specifying what the actions are.", "claim_type": "methodology", "paper_id": "VJDFhkwQg6", "paper_title": "Federated contrastive GFlowNets", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "Om8tHTwSEN", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In the phylogeny experiments, a state is represented as a forest. Initially, each leaf belongs to a different singleton tree. An action consists of picking two trees and joining their roots to a newly added node. The generative process is finished when all nodes are connected in a single tree. We understand that this description was missing in the document, and we included it in Appendix C.1, along with an illustrative picture.\"", "b3_evidence": "Abstract: \"We empirically attest the performance of FC-GFlowNets in four settings, including grid-world, sequence, multiset generation, and Bayesian phylogenetic inference.\"", "b2_justification": "The authors directly acknowledge the missing description and provide the missing details about states and actions for the phylogeny experiments, and state they added this information to the appendix.", "b3_justification": "The paper mentions Bayesian phylogenetic inference as one of the experimental tasks (Abstract, Introduction) but the provided content contains no description of the phylogenetic inference setup and does not specify the action space or what the actions are. There is no methods or experiment subsection in the supplied text that defines actions for the phylogenetic task."}
{"claim": "The paper fails to mention the alternative approach of training a single GFlowNet with a stochastic reward as used in prior work.", "claim_type": "other", "paper_id": "VJDFhkwQg6", "paper_title": "Federated contrastive GFlowNets", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "Om8tHTwSEN", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "1) \"updated the related works section to acknowledge the use of stochastic rewards as an alternative to dealing with expensive-to-evaluate reward functions in GFlowNet training (Appendix D)\"\n2) \"We were unaware that these works on GFlowNets for causal discovery used stochastic rewards. Thanks for pointing this out! They’re now cited in related works (pg. 21).\"\n3) \"The downside is that this requires many communication steps between clients and server. This is precisely the bottleneck we are trying to avoid with FC-GFlowNets, imposing one *single communication step* between the clients and the server. We wrote a short version of this discussion in related works (Appendix D).\"", "b3_evidence": "Introduction: \"This paper extends the theory of GFlowNets to develop a simple divide-and-conquer algorithm for federated learning of GFlowNets, in which clients learn locally GFlowNets to sample from their individual rewards and send their policies to a server for aggregation. Importantly, this procedure requires a single round of communication between the client and server sides.\" \n\nSection 3.1: \"To circumvent the restrictions imposed by the problem statement, we propose a simple divide-and-conquer strategy. First, each user n trains independently a GFlowNet with forward/backward policies p^(n)_F and p^(n)_B to sample from R_n. Then, the users send their policies to a server for a single aggregation step, in which the server combines the local GFlowNets into a new one...\" \n\nProblem statement: \"For related works, see Appendix D.\"", "b2_justification": "The authors acknowledge the alternative approach, state they have updated the related work to cite and discuss stochastic-reward training, and explain its relation and limitations (e.g., increased communication) relative to their method.", "b3_justification": "The paper consistently describes and advocates a divide-and-conquer federation scheme where each client trains a local GFlowNet and sends policies to a server for a single aggregation step; the main text does not describe or mention the alternative of training a single GFlowNet with a stochastic reward. Related work is deferred to an appendix, so the main paper does not present that alternative approach."}
{"claim": "The paper does not compare client training objectives, such as using TB versus CB, as experimental baselines.", "claim_type": "baseline", "paper_id": "VJDFhkwQg6", "paper_title": "Federated contrastive GFlowNets", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "Om8tHTwSEN", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "We have now included Table 2 (below) in Appendix C, comparing the performance of FC-GFlowNets when clients are trained with TB vs. CB. The metrics are all very similar.", "b3_evidence": "1) Abstract: \"Experiments also suggest that, in some cases, enforcing the contrastive balance can accelerate the training of conventional GFlowNets.\" 2) Contributions: \"iii) show that, in some cases, using the contrastive balance as a training criterion leads to faster convergence rates compared to using trajectory and detailed balances;\"", "b2_justification": "The authors report that they added experiments comparing client training objectives (TB vs CB) and included Table 2 showing the results, thereby providing evidence that the previously missing comparison has been performed.", "b3_justification": "The paper explicitly states that it compares the contrastive balance (CB) training criterion to trajectory balance (TB) and detailed balance (DB), reporting faster convergence in some cases; therefore the reviewer's claim that it does not compare these training objectives is false."}
{"claim": "Prior works (Malkin et al. ICLR 2023, Zhang et al. ICLR 2023, Richter et al. NeurIPS 2020) already described similar variance-reduction losses or VarGrad methods.", "claim_type": "novelty", "paper_id": "VJDFhkwQg6", "paper_title": "Federated contrastive GFlowNets", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "Om8tHTwSEN", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We once again thank you for noticing the relationship between the contrastive loss (CL) and the log-partition variance loss (VL) of Zhang et al. (ICLR 2023) — which we did not notice. In fact, CL equals twice VL *in expectation*. Nonetheless, as you pointed out, CL and VL use different estimators for the variance up to some positive multiplicative constant. Additionally, our balance condition (CB) is novel per se and essential to deriving the federated loss (Corollary 1), which is the basis of our method. We have updated the introduction, section 3.2 (which introduces the CB), and related works (Appendix D) to acknowledge this work.\"", "b3_evidence": "1) \"Enforcing the CB induces a loss that, in expectation, is equivalent to the variance of an estimator of the log-partition, whose minimization was first proposed by Zhang et al. (2023a).\"  (Abstract)\n\n2) \"Minimizing Equation 2 enforces the TB condition: ... This is the most widely used training scheme for GFlowNets. In practice, some works set p_B as a uniform distribution to avoid learning ϕ_B, as suggested by Malkin et al. (2022).\" (Section 2 PRELIMINARIES)", "b2_justification": "The authors acknowledge the relationship between their contrastive loss and prior work (Zhang et al.), conceding equivalence in expectation, and they updated related work. However, they argue differences in estimators and emphasize novel contributions (the balance condition and the federated loss), so the reviewer’s claim is only partially accepted.", "b3_justification": "The paper explicitly credits Zhang et al. (2023a) with proposing minimization of the variance of an estimator of the log-partition, but it does not attribute similar variance-reduction or VarGrad methods to Malkin et al. or Richter et al. Malkin et al. are cited regarding the trajectory-balance/backward policy but not as proposing variance-reduction losses; Richter et al. is not mentioned in the provided text."}
{"claim": "The paper does not derive similar error bounds for divergences that are less sensitive to mode-dropping than the Jeffrey divergence.", "claim_type": "methodology", "paper_id": "VJDFhkwQg6", "paper_title": "Federated contrastive GFlowNets", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "Om8tHTwSEN", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“The bound in Theorem 2 is nice but may not be very useful in practice. … Theorem 2 only aims to illustrate that the global distribution may diverge considerably from the target distribution when a client's policies are inadequately trained. … This effect, similarly observed in e.g. De Souza et al. (AISTATS 2022), is accurately represented by our upper bound on the Jeffrey's divergence. We agree that developing good diagnostics for federated GFlownets is an important topic that we would like to pursue in future works. However, the design of tight divergence bounds and effective diagnostic methods is currently an unaddressed issue in the GFlowNets literature, even for centralized settings.”", "b3_evidence": "\"we provide a theory that guarantees its correctness, and also analyze its robustness to errors in the estimation of local GFlowNets;\" (Contributions) \n\n\"Additionally, our theoretical analysis builds on the idea of contrastive balance , that imposes necessary and sufficient conditions for the correctness of general (nonfederated) GFlowNets.\" (Abstract)\n\nNo occurrences of \"Jeffrey\" or derivations of error bounds for other divergences appear in the provided content.", "b2_justification": "The authors acknowledge that their theoretical result (Theorem 2) is stated in terms of the Jeffrey's divergence and state that designing tighter bounds or bounds in other divergences is an open problem and future work. Thus they agree the paper does not provide such alternative divergence bounds.", "b3_justification": "The paper's provided content discusses theoretical guarantees (federated balance, contrastive balance) and robustness to estimation errors but contains no derivation or mention of error bounds for divergences (nor any reference to the Jeffrey divergence or alternative divergences). Thus the reviewer's claim that such bounds are not derived is supported by the paper text."}
{"claim": "The developed theoretical results do not produce a model that outperforms existing approaches, indicating limited practical improvement from the analysis.", "claim_type": "baseline", "paper_id": "h05eQniJsQ", "paper_title": "Understanding Certified Training with Interval Bound Propagation", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "zdpzuBcupz", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "We confirm our original results and show that the wider architecture suggested by our theoretical insights yields strict improvements in certified and standard accuracy in 9 of the 11 considered settings, with improvements in one of the two metrics in the remaining two settings.", "b3_evidence": "Abstract: \"...conducting an extensive empirical study, (i) confirming this transferability and yielding state-of-the-art certified accuracy...\"; Introduction: \"...we confirm the predictiveness of our theoretical results for deep ReLU networks and observe that: (i) increasing network width but not depth improves state-of-the-art certified accuracy...\"", "b2_justification": "The authors provide new experiments and extended results showing that architectures informed by their theory yield improved certified and standard accuracy in the majority of tested settings, directly refuting the reviewer's claim of no practical improvement.", "b3_justification": "The paper reports that its empirical study yields state-of-the-art certified accuracy and that increasing width improves certified accuracy, contradicting the reviewer's claim that the results do not produce a model outperforming existing approaches."}
{"claim": "The paper does not test whether observed gains are consistent across multiple architectures, training methods, and datasets like CIFAR and TinyImageNet.", "claim_type": "experimental", "paper_id": "h05eQniJsQ", "paper_title": "Understanding Certified Training with Interval Bound Propagation", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "zdpzuBcupz", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we have extended Table 1 to all settings commonly considered in certified adversarial robustness, including 5 different perturbation magnitudes across 3 different datasets (MNIST, CIFAR-10, and TinyImageNet) for 3 different training methods. We confirm our original results...\"; \"Architectures: We consider a range of convolutional architectures derived from CNN7... ResNets are not typically studied in the field... We have confirmed these results for fully connected networks, ... in Table 3, but believe the results around CNN7 to be of greater significance.\"", "b3_evidence": "“Finally, we show how these results on DLNs transfer to ReLU networks, before conducting an extensive empirical study, (i) confirming this transferability and yielding state-of-the-art certified accuracy, (ii) finding that while all IBP-based training methods lead to high tightness, this increase is dominated by the size of the propagated input regions rather than the robustness specification, and finally (iii) observing that non-IBP-based methods do not increase tightness.”\n\n“Setting We focus our theoretical analysis on deep linear networks (DLNs), i.e., f(x)=ΠLi=1 W(i) x. After proving key results on DLNs, we will show how they transfer to ReLU networks.”", "b2_justification": "The authors report that they expanded experiments to include CIFAR-10 and TinyImageNet and multiple training methods and confirm their results, but they also note limitations (focus on CNN7-derived and FC architectures and primarily IBP-based methods), so the reviewer’s concern is addressed but not exhaustively resolved.", "b3_justification": "The paper does evaluate multiple architectures and training methods: it analyzes deep linear networks (DLNs) and shows transfer to ReLU networks, and it discusses and empirically compares various IBP-based and non-IBP-based training methods. However, the provided paper content does not mention experiments on specific datasets such as CIFAR or TinyImageNet, so the dataset aspect of the claim is not supported by the paper excerpt."}
{"claim": "The authors' claim that training-free studies reduce to a hyperparameter study within their framework is unsupported because the framework's search space may omit important hyperparameters used in prior works.", "claim_type": "methodology", "paper_id": "N8YbGX98vc", "paper_title": "TFG: Unified Training-Free Guidance for Diffusion Models", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "6i2pz4NB9X", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Theoretically speaking, TFG aims to provide a general framework that unifies different sub-hyperparameter spaces, and the practical implementation tricks are omitted (as this trick only appears in FreeDoM code, not its original paper). That said, our framework can naturally represent this nuanced setting. For example, if we want the gradient to be $\\frac{\\nabla g}{\\| \\nabla g\\|}$ for a given target function $g$, we could simply set the $f$ in our algorithm as $\\exp\\{\\int \\frac{\\mathrm dg}{\\| \\nabla g\\|}\\}$, in which case the gradient of $f$ becomes exactly what we want.\" \n\n\"For all methods discussed in our paper, we employed an identical beam search strategy with three beam search trials and a maximum of 7 steps... This beam search program is method-agnostic and compatible with all methods, ensuring fair and objective comparisons. To promote transparency and facilitate future research, we will open-source our code, all beam search runs, the best parameters for each algorithm, and their corresponding performance results.\"", "b3_evidence": "“We show that existing approaches are special cases of the TFG as they correspond to particular hyper-parameter subspace in our unified space. In other words, TFG naturally simplifies and reduces the study of training-free guidance, as well as the comparisons between existing methods, into the analysis of hyper-parameter choices in our unified design space.”", "b2_justification": "The authors directly dispute the reviewer’s assertion by arguing the framework can represent the omitted hyperparameter tricks and by explaining how to express normalization within their hyperparameter formulation; they also describe a uniform beam-search procedure and promise to release code and search results to demonstrate coverage.", "b3_justification": "The paper explicitly claims that existing training-free methods are encompassed by the TFG design space and that the study reduces to analysis of hyper-parameter choices. Thus the reviewer's statement that this claim is unsupported (due to possible omitted hyperparameters) contradicts the paper's stated claim and intent to include prior methods as special cases."}
{"claim": "Lemma 4.1 appears to restate an established MMSE variance formula widely used in prior diffusion literature, leaving unclear its novel contribution to the framework.", "claim_type": "novelty", "paper_id": "N8YbGX98vc", "paper_title": "TFG: Unified Training-Free Guidance for Diffusion Models", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "6i2pz4NB9X", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "We would like to clarify that the major contribution of the unification algorithm does not lie in the novelty or difficulty of the proof of theorem 3.2, but rather in recognizing and quantifying the importance of unifying different methods in the same hyper-parameter space for training-free guidance.", "b3_evidence": "\"Within our framework, we analyze the underlying theoretical motivation of each hyper-parameter and conduct comprehensive experiments to identify their influence.\" \n\n\"This sections introduces our unified framework for training-free guidance (TFG, Algorithm 1) and formally defines its design space in Definition 3.1.\"", "b2_justification": "The authors' replies do not mention Lemma 4.1, the MMSE variance formula, or whether Lemma 4.1 restates prior results; they discuss other points (Theorem 3.2, OU process, hyperparameters) but do not address the reviewer's specific claim about Lemma 4.1's novelty.", "b3_justification": "The provided paper excerpt does not include Lemma 4.1 or its statement, so there is insufficient information to judge whether that lemma merely restates an established MMSE variance formula or provides a novel contribution."}
{"claim": "When the forward model is known, generating many samples to train a conditional diffusion model is computationally cheap, making training-based approaches potentially superior to training-free approaches.", "claim_type": "experimental", "paper_id": "N8YbGX98vc", "paper_title": "TFG: Unified Training-Free Guidance for Diffusion Models", "paper_venue": "neurips2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "6i2pz4NB9X", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"the training efficiency of their method ... is highly determined by the structure of the guidance function, and the situation of using CLIP for guidance might be completely different from that of using a general classifier.\"", "b3_evidence": "\"Conditional generation methods like classifier-based guidance [66, 7] and classifier-free guidance [23] typically require training a specialized model for each conditioning signal (e.g., a noise-conditional classifier or a text-conditional denoiser). This resource-intensive and time-consuming process greatly limits their applicability.\"", "b2_justification": "The authors directly challenge the generality of the reviewer's claim by arguing that training efficiency depends on the structure of the guidance function; while CLIP-like cases may be efficient, for general classifiers training can require extremely large amounts of unconditional generation and thus is not necessarily computationally cheap.", "b3_justification": "The paper states that training-based guidance requires training specialized models and describes this as resource-intensive and time-consuming, contradicting the reviewer's claim that generating many samples to train a conditional model is computationally cheap when the forward model is known."}
{"claim": "The surrogate model appears contrived and its assumptions lack clear motivation or connection to realistic quantization processes.", "claim_type": "subjective", "paper_id": "CXjz7p4qha", "paper_title": "Rotation Invariant Quantization for Model Compression", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "fhz0No7vIA", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "Note that \\hat w_\\ell, and hence, its norm and  \\theta_\\ell are specified by the quantization. The \\tilde w_\\ell models the quantized vector \\hat w_\\ell. In particular, the surrogate model considers all the vectors that are \\theta_\\ell away by using a random rotation matrix U(\\theta_\\ell) (see Figure 3 for illustration). That is, \\tilde w_\\ell is a realization of this random rotation. Note that the norm of \\tilde w_\\ell is the same as \\hat w_\\ell (and hence, bounded). Thus, any realization of  \\tilde w_\\ell is uniformly distributed on the cone's ring. In the revised version we clarify this point after introducing the surrogate model.", "b3_evidence": "\"To analyze the optimality of the RIQ algorithm, we introduce a universal surrogate model that depicts quantization in terms of rotation of the model weights. Its analysis reveals that the rate-distortion minimizing distribution for NN models is a spherical (rotation invariant) distribution constructed by the product of layers' spherical distribution.\"; \"This distortion reflects the rotation angle that is required to align ˆf(x) with f(x). Noticeably, eq. (1) is a rotation-invariant measure... Thus, characterizing the connection between the deviation to the distortion in each layer is a key to optimizing the model quantization... Since these distortions are invariant to rotations, the rate-distortion theory tells that the optimal quantization must be rotation invariant as well, as we show in the sequel. This motivates a searching paradigm over rotation-invariant solutions, where the layers' rate are jointly adjusted.\"", "b2_justification": "The authors directly rebut the claim by explaining the surrogate model's construction and its connection to quantization: they state that \\hat w_ell and \\theta_ell are specified by quantization, that \\tilde w_ell models the quantized vector via a random rotation U(θ_ell) which preserves the (bounded) norm, and that they clarified this in the revised manuscript.", "b3_justification": "The paper explicitly introduces and motivates the surrogate model via rotation-invariance arguments: it frames distortion with a rotation-invariant cosine measure, argues that rate-distortion optimality implies rotation-invariant solutions, and states the surrogate models quantization as rotations to analyze optimality. Thus the paper does provide clear motivation and connection for the surrogate model."}
{"claim": "The derivation procedure for the surrogate quantized weight \\tilde{w}_{\\ell} is not clearly specified in the manuscript.", "claim_type": "methodology", "paper_id": "CXjz7p4qha", "paper_title": "Rotation Invariant Quantization for Model Compression", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "fhz0No7vIA", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Note that \\hat w_\\ell, and hence, its norm and  \\theta_\\ell are specified by the quantization. The \\tilde w_\\ell models the quantized vector \\hat w_\\ell. In particular, the surrogate model considers all the vectors that are \\theta_\\ell away by using a random rotation matrix U(\\theta_\\ell) (see Figure 3 for illustration). That is, \\tilde w_\\ell is a realization of this random rotation. Note that the norm of \\tilde w_\\ell is the same as \\hat w_\\ell (and hence, bounded). Thus, any realization of  \\tilde w_\\ell is uniformly distributed on the cone's ring. In the revised version we clarify this point after introducing the surrogate model.\"", "b3_evidence": "To analyze the optimality of the RIQ algorithm, we introduce a universal surrogate model that depicts quantization in terms of rotation of the model weights. Its analysis reveals that the rate-distortion minimizing distribution for NN models is a spherical (rotation invariant) distribution constructed by the product of layers' spherical distribution.", "b2_justification": "The authors acknowledge and clarify how the surrogate ̃w_ell is constructed: they state that ̂w_ell and its angle theta_ell are specified by quantization, that ̃w_ell is generated via a random rotation matrix U(theta_ell) (a realization on the cone's ring) with preserved norm, and they say this clarification was added in the revision.", "b3_justification": "The manuscript refers to a 'universal surrogate model' used to analyze quantization but does not present the derivation steps or an explicit procedure/formula for the surrogate quantized weight \\tilde{w}_{\\ell} in the provided sections (Introduction and Preliminaries). There is mention of the surrogate model conceptually, but no clear derivation or specification of \\tilde{w}_{\\ell} is given."}
{"claim": "The relationship between weight distortion measures and output deviation is not clearly established or justified in the paper.", "claim_type": "methodology", "paper_id": "CXjz7p4qha", "paper_title": "Rotation Invariant Quantization for Model Compression", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "fhz0No7vIA", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“We emphasize the link between the layer-wise errors and the final deviation given in Corollary 1 and Proposition 1.”; “The link between the distortion and the deviation is given in Proposition 1 proof. Specifically, we prove that both the distortion and the deviation scale with the quantization rate as $O(1/k^2)$. To clarify this link, Proposition 1 now explicitly states this connection in the revised version.”", "b3_evidence": "“The resulting deviation in eq. (1) relates to the distortions gathered through the layers. In particular, each quantized layer produces a rotation distortion in its output, and this distortion keeps propagating and accumulating through the layers until reaching the model's output. Thus, characterizing the connection between the deviation to the distortion in each layer is a key to optimizing the model quantization. Though finding the exact link is intricate in general, intuitively, as the layers' quantization rate jointly decrease, the deviation increases monotonically with the layers' distortion.”", "b2_justification": "The authors acknowledge the concern and state they have clarified and explicitly connected weight-layer distortion to output deviation in the revision, pointing to Corollary 1 and Proposition 1 and claiming a proven scaling relationship.", "b3_justification": "In Section 3.1 the paper itself admits that deriving an exact link between per-layer weight distortions and the final output deviation is intricate and provides only an intuitive explanation rather than a clear, formal establishment in the quoted content."}
{"claim": "Both the critic and the generator are implemented as LLMs, which may amplify and propagate inherent LLM errors and biases throughout Prospector's decision-making pipeline.", "claim_type": "methodology", "paper_id": "YKK1jXEWja", "paper_title": "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2SqlrxhfRb", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"the in-context learning based critic fails to perform well in complex environments and a fine-tuned critic model performs better in this scenario.\"; \"A few-shot LLM Critic ... may provide low prediction accuracy\"; \"this self-asking step checks if a target object is found. This self-asking step significantly reduces missing a target object in a place (due to hallucination).\"; \"We believe that Prospector can benefit from the general and accurate reward models like Prometheus.\"", "b3_evidence": "1) \"Prospector is a reflective LLM agent that consists of two complementary LLMs such as LLM Actor and LLM Critic for solving complex interactive decisionmaking tasks.\" 2) \"Few-shot LLM Critics. Motivated by recent methods of using LLMs as an evaluator..., we attempt to use LLMs as reward estimators for interactive decision-making tasks.\"", "b2_justification": "The authors acknowledge limitations of LLM-based critics/actors (e.g., hallucination and low prediction accuracy of few-shot critics) and propose mitigations (fine-tuned critics, AskAct self-asking, and use of improved reward models), but they do not directly address the broader concern that using both components as LLMs can amplify and propagate inherent LLM errors and biases across the entire pipeline.", "b3_justification": "The paper explicitly states that both the actor (generator) and the critic are implemented as LLMs (supported). However, the paper does not claim or analyze that this design \"may amplify and propagate inherent LLM errors and biases throughout Prospector's decision-making pipeline\"; that consequence is not discussed, so the second part of the reviewer claim is not supported by the paper."}
{"claim": "The paper provides limited discussion of the limitations and failure modes of the reward prediction models used for Trajectory Ranking.", "claim_type": "subjective", "paper_id": "YKK1jXEWja", "paper_title": "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2SqlrxhfRb", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"A few-shot LLM Critic has some advantages of generality, since it does not need to be trained on a specific environment. But, it may provide low prediction accuracy, as shown in the case of the WebShop environment.\"; \"This is due to the **limited context length** of text-davinci-002 (i.e., 4096). In both ALFWorld and WebShop, 3-shot examples often exceed the context length, and the last example is truncated.\"; \"the in-context learning based critic fails to perform well in complex environments and a fine-tuned critic model performs better in this scenario.\"", "b3_evidence": "\"In some complex environments such as WebShop (Yao et al., 2022a), one of the most powerful LLMs such as GPT-3 have difficulty in reward prediction in a few-shot manner (see Table 6).\" \n\n\"We investigate the impact of the reward model used in trajectory ranking, and demonstrate that Prospector robustly generates strategic actions in both cases when using LLM-based reward model is additionally fine-tuned or not. (see Table 4 and 7).\"", "b2_justification": "The authors explicitly acknowledge and describe limitations of the reward prediction models (few-shot critics have low prediction accuracy, context-length truncation issues, and in-context learning fails in complex environments) and note that fine-tuned critics perform better and that more general/accurate reward models would help.", "b3_justification": "The paper only briefly acknowledges limits of the reward predictors (noting GPT-3 struggles in few-shot reward prediction and that fine-tuning can help) but does not present an extended analysis of failure modes or limitations of those models beyond these short remarks and pointer to tables."}
{"claim": "The manuscript does not clearly specify which reward prediction models are used for Trajectory Ranking or detail their architectures and training procedures.", "claim_type": "methodology", "paper_id": "YKK1jXEWja", "paper_title": "Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2SqlrxhfRb", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We use a LLM as a reward model (named LLM Critic) that predicts the expected reward of a trajectory generated by the LLM Actor. In this paper, we consider two types of LLM Critics: (1) few-shot LLM Critic and (2) fine-tuned LLM Critic. ... A fine-tuned LLM Critic is fine-tuned on a dataset of (trajectory, reward), and generate response as the reward for a given input trajectory. (Tables/showing) ReAct + TR (Prospector) | Llama-2-70B | FLAN-T5-3B (SFT) ... AskAct + TR (Prospector) | Llama-2-70B | FLAN-T5-3B (SFT)", "b3_evidence": "“Therefore, we investigate two methods to estimate the trajectory reward from a given dataset: (1) Few-shot LLM critics, and (2) Fine-tuned LLM critics.”\n\n“Few-shot LLM Critics. Motivated by recent methods of using LLMs as an evaluator (Li et al., 2023; Ye et al., 2023), we attempt to use LLMs as reward estimators for interactive decision-making tasks. To evaluate the trajectories without additional training of the reward model, we use few-shot in-context learning with reward-labeled trajectories.”\n\n“Fine-tuned LLM Critics. In some complex environments such as WebShop (Yao et al., 2022a), one of the most powerful LLMs such as GPT-3 have difficulty in reward prediction in a few-shot manner (see Table 6). In this case, open-sourced LLMs fine-tuned on trajectory data can help to increase the performance of Prospector agents. The details can be found in Table 5 and Table 7 in the Experiment section.”", "b2_justification": "The authors clarify that the reward model is an LLM Critic and specify two types (few-shot and fine-tuned), and they name specific models used in experiments (e.g., FLAN-T5-3B SFT, text-davinci-002, Llama-2-70B). However, they do not provide detailed architecture descriptions, dataset sizes, fine-tuning hyperparameters, or full training procedures, so the reviewer's concern is only partially addressed.", "b3_justification": "The paper describes two kinds of reward predictors (few-shot LLM critics and fine-tuned LLM critics) and provides a critic prompt template, but the main text does not list specific model names/architectures or training procedures — it only refers to details in tables (experiments/appendix). Thus the claim is partially correct: the paper gives high-level descriptions but lacks clear, explicit architecture/training details in the main text provided."}
{"claim": "The paper fails to justify the 'true value' of the method adequately, leaving unclear whether the proposed approach provides benefits beyond replicating the larger model's alignment.", "claim_type": "experimental", "paper_id": "IRXyPm9IPW", "paper_title": "Multimodal Large Language Models Make Text-to-Image Generative Models Align Better", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "juBZrLsCxq", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "Therefore, they are not the same kind of models as large and small models, and this differs from distillation, which simply transfers the capabilities of a large model to a smaller model for the same task. Our research is the first to address this concern and demonstrate this point (which is the core motivation of our study, see line 39). We have demonstrated that, for current-scale T2I models, the preference labels provided by MLLMs are effective (sections 4) and align with those provided by humans.", "b3_evidence": "“The preference prediction accuracy of VP-Score is validated to be comparable to that of human annotators.”; “Experimental results demonstrate that VP-Score exhibits a competitive correlation with human preferences compared to existing human preference reward models.”; “extensive experimental results demonstrate that VisionPrefer significantly improves text-image alignment in compositional image generation across diverse aspects ... and generalizes better than previous human-preference metrics across various image distributions.”", "b2_justification": "The authors explicitly disagree with the reviewer's characterization and argue the work is not merely replicating a larger model's alignment. They state the models differ from distillation, claim they empirically demonstrate MLLMs can provide reliable preference labels, and emphasize this is a main contribution of the paper.", "b3_justification": "The paper presents multiple validations showing the method's value beyond merely replicating the MLLM annotator: they train VP-Score on VisionPrefer and report that its preference prediction accuracy is comparable to human annotators, that VP-Score exhibits competitive correlation with human preferences versus existing reward models, and that tuning with VisionPrefer improves alignment and generalizes better than prior human-preference metrics. These statements indicate the authors did provide empirical justification rather than leaving the benefit unclear."}
{"claim": "Several parts of the paper are unclear enough that the reviewer could misread them, indicating the manuscript needs clarification in key sections.", "claim_type": "presentation", "paper_id": "IRXyPm9IPW", "paper_title": "Multimodal Large Language Models Make Text-to-Image Generative Models Align Better", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "juBZrLsCxq", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we believe there are some misunderstandings that we need to clarify:\" ... \"To avoid any remaining misunderstandings, we will make sure to revise the paper to highlight our motivation more clearly in the modified version.\"", "b3_evidence": "1) Section 3 (Step-1): \"a significant portion of the prompts in the DiffusionDB is biased towards certain\n\n> > > > > = Figure 2: VisionPrefer construction pipeline.\" 2) Table 1 header and columns: \"Feedback Format   | Feedback Format   | Feedback Format   |\\n| Dataset ... | Ranking          | Text          | Scalar          |\" 3) Section 4.1 truncated sentence: \"Specifically, we employ the average scores of each sample in VisionP\"", "b2_justification": "The authors acknowledge misunderstandings and explicitly state they will revise the manuscript to clarify key motivations and distinctions; they also provide substantive clarifications in their response.", "b3_justification": "The manuscript contains multiple truncated/garbled passages and formatting inconsistencies that make parts unclear and prone to misreading (e.g., broken sentences in Section 3, a truncated sentence in Section 4.1, and a duplicated/misaligned table header in Table 1). These issues indicate the paper needs clarification in key sections."}
{"claim": "The paper does not clarify whether the proposed algorithm can find all Pareto optimal solutions or only a desired subset.", "claim_type": "methodology", "paper_id": "BmG3NgH5xu", "paper_title": "FERERO: A Flexible Framework for Preference-Guided Multi-Objective Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "A5lBLaSAao", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"No, our a-priori method returns one solution given the absolute preference, not all Pareto optimal solutions.\" \"As there may be infinitely many Pareto optimal solutions, our method guarantees finding one solution that satisfies the absolute constraint and is Pareto optimal. We do not provide guarantees on finding all the Pareto optimal solutions.\"", "b3_evidence": "\"Finding specific preference-guided Pareto solutions that represent different tradeoffs among multiple objectives is critical yet challenging in multi-objective problems.\" (Abstract)\n\n\"The C_A-optimal set, denoted as P_A, contains all the C_A-optimal models. When A = I_M, P_A is the Pareto optimal set P.\" (Section 2.1)\n\n\"Our goal is to design an algorithm that converges to a KKT solution based on (2.1).\" (end of Section 2.2)", "b2_justification": "The authors explicitly state their method is a-priori and returns a single Pareto-optimal solution per specified absolute preference, and they acknowledge they do not guarantee finding all Pareto optimal solutions.", "b3_justification": "The paper consistently frames the goal as finding preference-guided solutions and provides convergence to KKT/stationary solutions for the constrained (preference) problem, but it does not state that the algorithm will enumerate or be able to find every Pareto-optimal point (the full Pareto front). The paper defines the CA-optimal set P_A and discusses finding preference-guided optimal models and convergence to KKT solutions, but it does not clarify whether the method can recover all Pareto-optimal solutions vs. only those consistent with a chosen preference specification."}
{"claim": "The paper provides no guarantees or evaluation for coverage of all Pareto optimal solutions or the diversity of returned solutions.", "claim_type": "experimental", "paper_id": "BmG3NgH5xu", "paper_title": "FERERO: A Flexible Framework for Preference-Guided Multi-Objective Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "A5lBLaSAao", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"No, our a-priori method returns one solution given the absolute preference, not all Pareto optimal solutions.\" \"We do not provide guarantees on finding all the Pareto optimal solutions. By running our algorithm multiple times, each time with a different absolute preference, we can obtain multiple different solutions, one solution at a time.\"", "b3_evidence": "\"C3) Under the FERERO framework, we develop a practical single-loop algorithm with nonasymptotic convergence guarantees. To our best knowledge, this is the first single-loop primal algorithm in constrained vector optimization with convergence guarantees.\" and \"C4) We apply the proposed algorithms to various synthetic and real-world image and speech datasets to demonstrate its ability to find flexible preference-guided optimal models.\"", "b2_justification": "The authors explicitly acknowledge that their a-priori method returns a single Pareto-optimal solution per specified preference and state they do not provide guarantees for finding all Pareto optimal solutions, agreeing with the reviewer's claim.", "b3_justification": "The paper provides convergence guarantees to KKT/preference-guided solutions (single-solution convergence) and reports experiments demonstrating finding preference-guided models, but it does not state any theoretical guarantees about covering the entire Pareto front or explicitly evaluate diversity/coverage of returned solutions in the provided content."}
{"claim": "The paper lacks discussion on whether the mu>0 assumption is necessary or simply used for theoretical convenience.", "claim_type": "methodology", "paper_id": "TTrzgEZt9s", "paper_title": "Distributionally Robust Optimization with Bias and Variance Reduction", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "x0lC1jsG0I", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“It is true that μ>0 is important theoretically to achieve linear convergence, as this makes the objective R_σ strongly convex. ... From a practical point of view, however, the algorithm generally works on settings that violate these assumptions. For example, the regression experiments use squared loss, which is not Lipschitz continuous, so by setting μ=0, we observe the results below on the `yacht` and `energy` datasets... Extending theoretically to the non-strongly convex case is an interesting avenue for future work.”", "b3_evidence": "\"Theoretically, Prospect converges linearly for any positive shift cost on regularized convex losses.\" \n\n\"Our goal is to achieve unconditional linear convergence for smooth, strongly convex (regularized) losses with a single hyperparameter.\"", "b2_justification": "The authors explicitly discuss the role of μ>0, stating it is needed for theoretical linear convergence (strong convexity of the objective), and they also provide empirical results for μ=0 showing the algorithm still works in practice, along with a note that theoretical extension to the non-strongly convex case is future work.", "b3_justification": "The paper repeatedly states linear convergence results under a strong-convexity/regularization assumption (µ>0) but does not discuss whether this assumption is necessary versus being a theoretical convenience. The Introduction/Contributions and Section 2 assert results for ‘regularized’ or ‘strongly convex’ losses without analyzing necessity of the assumption."}
{"claim": "The paper lacks controlled experiments that equalize crop augmentation settings between MG and baseline methods.", "claim_type": "experimental", "paper_id": "P50qJuu4IY", "paper_title": "Self-Supervised Learning with the Matching Gap", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "W9ybmgKZdT", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Running apples-to-apples experiments for these baselines (as opposed to reporting values from their original papers) would likely result in a huge compute budget that we do not want to spend... We have used our computational budget on MG experiments. We realize this presents a slight limitation in comparison to other methods, however, as we indicate in Table 1, we are aware that performance is reported over diverse configurations, using original publications, and values are mainly brought to show that within the naive implementation provided for MG it is comparable to published performance.", "b3_evidence": "\"we show that we can learn competitive features, even without extensive data augmentations: Using only cropping and flipping, we achieve 74.2% top-1 accuracy with a ViT-B/16 on ImageNet-1k, to be compared to 72.9% for I-JEPA (Assran et al., 2023).\"", "b2_justification": "The authors acknowledge they did not perform apples-to-apples experiments equalizing crop/augmentation settings for baselines, citing compute budget constraints, and explain they relied on reported baseline values while allocating compute to MG experiments (with plans to run more experiments later).", "b3_justification": "The paper reports results with reduced augmentations (e.g., 'only cropping and flipping') and compares to baselines, but the provided text does not describe experiments that control or equalize crop-augmentation settings between the matching-gap method and baseline methods."}
{"claim": "The evaluation reports only classification accuracy and omits uncertainty measures such as calibration and likelihood-based metrics across datasets.", "claim_type": "experimental", "paper_id": "wJaCsnT9UE", "paper_title": "Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "haBGktuqCH", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The additional experiment results using ECE and NLL metrics on the in-distribution (existing) test data are provided in the following tables. Results show that SharpBalance outperforms the two other baselines in both metrics on the existing test data. We will include the new results and clarification in the updated draft.\"", "b3_evidence": "“In our experiments, diversity is measured using variance defined above, as well as two other widely used metrics in ensemble learning, namely Disagreement Error Ratio (DER) ... and KL divergence ...”\n\n“We characterize the effectiveness of ensembling by the metric called ensemble improvement rate (EIR) [Theisen et al., 2023], which is defined as the ensembling improvement over the average performance of single models.”\n\n“Empirically, we measure the sharpness of the NN via the adaptive worst-case sharpness [Kwon et al., 2021, Andriushchenko et al., 2023].”\n\n“Here ℓ(·) is a loss function, which, for instance, can be the cross entropy loss or ℓ2 loss.”", "b2_justification": "Authors added uncertainty metrics (ECE and NLL) and provided results for CIFAR100, and promise to include them in the revised manuscript; however, these results are limited to in-distribution test data and do not cover multiple/different datasets as the reviewer requested.", "b3_justification": "The reviewer is correct that the paper does not mention uncertainty metrics such as calibration (e.g., ECE) or likelihood-based evaluation (e.g., NLL) in the provided content. However, the claim that the evaluation reports \"only classification accuracy\" is incorrect: the paper explicitly reports and evaluates other metrics (sharpness, diversity measures including variance/DER/KL, and an ensemble improvement rate) beyond raw accuracy."}
{"claim": "The variational free energy equals the cross-entropy of the generative joint under the proposal distribution minus the recognition model's entropy.", "claim_type": "methodology", "paper_id": "dxwIaCVkWU", "paper_title": "Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "x5hzHkvqAb", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"A second, minor, change that we have applied to the manuscript, is to write the free energy in terms of a product of complete conditionals as the recognition model Q and then consider estimating it by Monte Carlo with the whole Langevin to nested SMC procedure, as suggested by reviewer DHBv. We agree that this would further improve the clarity of our work.\"; \"From the point of view of how you're putting it, yes, we could write the free energy in terms of a product of complete conditionals as the recognition model Q and then consider *estimating* it by Monte Carlo with the whole Langevin to nested SMC procedure... We agree with the reviewer ... and will adopt that into the manuscript.\"", "b3_evidence": "Neal and Hinton [1998] reduced empirical Bayes to minimization of the variational free energy :\n\nAny proposal meeting these conditions (see Proposition 1 in Appendix B and Naesseth et al. [2015], Stites et al. [2021]) defines a free energy functional, analogous to Equation 2 in upper-bounding the model surprisal:", "b2_justification": "The authors explicitly agree with the reviewer's suggested formulation and state they will rewrite the free energy in terms of a recognition model (product of conditionals) and estimate it by Monte Carlo, adopting this change in the manuscript.", "b3_justification": "In Section 2 the paper defines the variational free energy as the objective minimized in empirical Bayes and frames it as a free-energy functional comparing the proposal q and the (unnormalized) joint γ_θ. This corresponds to F(q) = E_q[log q(z) - log p_θ(x,z)], which is equivalent to the cross-entropy term (−E_q[log p_θ(x,z)]) minus the recognition-model entropy (−E_q[log q(z)])."}
{"claim": "It is unclear whether any obstacle prevents rewriting the free energy without reference to importance weights, indicating an unaddressed technical justification.", "claim_type": "methodology", "paper_id": "dxwIaCVkWU", "paper_title": "Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "x5hzHkvqAb", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "A second, minor, change that we have applied to the manuscript, is to write the free energy in terms of a product of complete conditionals as the recognition model Q and then consider estimating it by Monte Carlo with the whole Langevin to nested SMC procedure, as suggested by reviewer DHBv. We agree that this would further improve the clarity of our work.\n\nFrom the point of view of how you're putting it, yes, we could write the free energy in terms of a product of complete conditionals as the recognition model Q and then consider *estimating* it by Monte Carlo with the whole Langevin to nested SMC procedure. ... will adopt that into the manuscript.", "b3_evidence": "\"Since the proposal from which we can sample by predictive coding is not the optimal coordinate update, we importance weight for the true complete conditional distribution that is optimal\"; \"The ratio of densities in Equation 2 is an example of a weight used to approximate a distribution known only up to its normalizing constant.\"", "b2_justification": "Authors explicitly agree that the free energy can be written in terms of a product of complete conditionals and state they will adopt this formulation in the manuscript, addressing the reviewer's concern.", "b3_justification": "The paper explicitly uses importance weights and resampling to correct proposals (Section 3) and does not provide a derivation or discussion showing how the variational free energy could be rewritten to avoid reference to importance weights. Thus it is correct that it remains unclear and technically unaddressed whether such a rewriting is possible."}
{"claim": "The paper lacks a performance comparison with DiGress, which is meaningful because the authors adapted components from DiGress.", "claim_type": "baseline", "paper_id": "lmYGRGyL4i", "paper_title": "Uncovering the Spectrum of Graph Generative Models: From One-Shot to Sequential", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2VjET9ABua", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We expanded the experimental assessment by adding DiGress as a molecular baseline.\" \"We thank you for recommending adding DiGress as a baseline, and we did so in the revised manuscript.\"", "b3_evidence": "Abstract: \"As a case study, we adapt DiGress, a diffusion-based one-shot model, to the whole spectrum of sequentiality, reaching new state of the art results, and motivating a renewed interest in developing autoregressive graph generative models.\" \nIntroduction: \"We show empirically that adapting Digress (Vignac et al., 2022), a state-of-the-art graph generative model, to 1-node sequential, leads to surpassing all autoregressive baselines, and is competitive with other state-of-the-art one-shot baselines such as CDGS (Huang et al., 2023).\"", "b2_justification": "The authors explicitly state they added DiGress as a baseline and described adapting it, addressing the reviewer's request for a performance comparison.", "b3_justification": "The paper states that the authors adapted DiGress as a case study and reports comparisons against autoregressive baselines and other one-shot baselines (e.g., CDGS), but the provided content does not show any direct performance comparison to the original DiGress model. Thus the claim that the paper lacks a performance comparison with DiGress is supported by the paper text shown."}
{"claim": "The paper does not provide an explanation for why the model performs well on molecular graphs but poorly on non-attributed generic graphs.", "claim_type": "experimental", "paper_id": "lmYGRGyL4i", "paper_title": "Uncovering the Spectrum of Graph Generative Models: From One-Shot to Sequential", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2VjET9ABua", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "However, as you said, we also noticed a drop in performance for non-attributed generic graphs, and we think that would be a promising direction to explore. Particularly for 1-node sequential models applied to big-sized graphs, we noticed that the halting signal's sparsity hinders the halting model's training process. We address this limitation in the Discussion section (numbered 6 in the revised version).", "b3_evidence": "1) \"we conduct the first analysis of the sample quality-time trade-off across a range of molecular and generic graphs datasets.\"  (Abstract)\n2) \"Looking into the literature, this is not always the case, as one-shot models have entered the stateof-the-art on challenging datasets like ZINC250k (Irwin et al., 2012), Ego (Sen et al., 2008), and many more.\"  (Introduction)\n3) \"We show empirically that adapting Digress (Vignac et al., 2022), a state-of-the-art graph generative model, to 1-node sequential, leads to surpassing all autoregressive baselines, and is competitive with other state-of-the-art one-shot baselines such as CDGS (Huang et al., 2023).\"  (Introduction)", "b2_justification": "The authors acknowledge the poorer performance on non-attributed generic graphs, state they added a Discussion section addressing limitations, and propose a concrete explanatory mechanism (sparsity of the halting signal and block-size effects) as reasons for the drop.", "b3_justification": "The paper mentions empirical analysis across molecular and generic graph datasets (Abstract, Introduction) and reports empirical results, but nowhere in the provided content does it offer a theoretical or empirical explanation for why the model would perform well on molecular (attributed) graphs yet poorly on non-attributed generic graphs. There is no dedicated discussion or rationale addressing differences in performance between these dataset types."}
{"claim": "The paper lacks detailed explanation or visualizations showing how the transition time distribution is determined.", "claim_type": "methodology", "paper_id": "KkYZmepjHn", "paper_title": "Fast Sampling via Discrete Non-Markov Diffusion Models with Predetermined Transition Time", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "rZg9TvKtrg", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we've provided comprehensive pseudo-algorithms in the paper and detailed explanations of the transition time distribution in Appendix C and Figure 3.\"; \"P(τ = t) = α_{t-1} - α_t\"", "b3_evidence": ["In this section, we introduce a non-Markov process such that the joint distribution of (x_0, x_t) remains the same as the one defined with Markov process in Section 2.", "Definition 3.2. Transition time τ is the time that the token x_t transition from x_0 to noise, i.e., τ := min_t { t | b_t = 0 }.", "where b_t is independently drawn from the Bernoulli distribution Bernoulli(β_t) and w is drawn from the noise distribution q_noise.", "Remark 3.4. (7) and (8) suggest that even though there are T distinct time steps, not every time in the range 1:T is crucial for capturing the process. Therefore, our primary focus should be on the most significant time step, i.e., the transition time τ , enabling faster reverse sampling."], "b2_justification": "The authors explicitly state they have added detailed explanations and visual material about the transition time distribution (pointing to Appendix C and Figure 3), and they also present the distribution formula and related derivations (e.g., P(τ=t)=α_{t-1}-α_t) and pseudo-algorithms, which directly address the reviewer's concern.", "b3_justification": "The paper defines transition time τ and notes b_t ~ Bernoulli(β_t) (Section 2 and 3.1) and discusses qualitative properties of τ (Remark 3.4), but in the provided content there is no detailed derivation, analytic expression, or visualization of the transition-time distribution itself."}
{"claim": "Equation 1 is insufficient because the paper fails to specify the underlying structural functions before presenting the causal graph.", "claim_type": "methodology", "paper_id": "lWXedJyLuL", "paper_title": "A Unified Causal View of Instruction Tuning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "f6n4G0QZIH", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We agree with you that it is more rigorous to model SCM from the structural equations, and when the structural equations are given, the causal graph will be determined accordingly. The reason we introduced causal graph firstly is that we want to give the reader an intuitive understanding of the data generating process of NLP tasks. An illustrative example corresponding to Fig. 1 has been provided in the above driven example.\"", "b3_evidence": "1) \"The causal graph induced by the meta-SCM is depicted on the left in Figure 1.\" 2) \"Structural causal models characterize causal relationships between variables through a set of structural functions, which we denote as generating processes in the remainder of the paper. And these structural functions induce a corresponding causal graph. Based on the above causal relations, we formalize the generating process for each variable. ... Now we formalise the generating process for a given task as follow:\" 3) \"In Equation 1, Pa ( · ) denotes the set of parent nodes in the causal graph...\"", "b2_justification": "Authors explicitly agree that it is more rigorous to model the SCM from structural equations, acknowledge the issue, and state they provided an illustrative example and revisions to address clarity.", "b3_justification": "The paper presents the causal graph (Figure 1) in the Introduction before it formalizes the structural (generating) functions; Equation 1 and the discussion of structural functions only appear later in Section 3.1, so the paper does not specify the underlying structural functions prior to showing the causal graph."}
{"claim": "Figure 1 lacks a concrete example mapping L_i, X, Y, and T to a specific task to clarify what each variable represents in practice.", "claim_type": "presentation", "paper_id": "lWXedJyLuL", "paper_title": "A Unified Causal View of Instruction Tuning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "f6n4G0QZIH", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Let's consider the sentence \\\"Pizza is delicious.\\\" This is an instance of the random variable $X_t$ in our paper. ... Specifically, $ L_1$ represents food information and $L_2$ represents sentiment. ... We use $Y_t$ to represent the target labels of different tasks, which require different latent factors, such as $L_1$ for topic classification and $L_2$ for sentiment classification.\" \"An illustrative example corresponding to Fig. 1 has been provided in the above driven example.\"", "b3_evidence": "Figure 1 caption: \"Left : The causal graph induced by the meta Structural Causal Model (meta-SCM) for integrating different NLP tasks. White nodes denote observed variables and grey nodes denote unobserved variables. Dashed lines denote edges that may be absent, while solid lines denote invariant processes. See Section 3.1 for a detailed description.\"; Section 3.1: \"X_t, Y_t represent the source context and target label respectively for NLP tasks, where subscript t denotes a specific task, such as documents and summaries, or sentences and sentiment polarity.\"; Section 1 (examples): \"For example, the connotative semantics in a document are the causal factors for sentiment analysis, while the core denotative semantics are the causal factors for topic classification.\"", "b2_justification": "The authors provided a concrete driven example that maps X_t to a sentence, assigns L1 and L2 to food and sentiment, and explains Y_t as task labels (topic vs. sentiment); they also state this example corresponds to Figure 1.", "b3_justification": "Figure 1 (its caption) presents a generic causal graph and explicitly refers the reader to Section 3.1 for details; the paper provides concrete mappings (e.g., X_t/Y_t and examples of L_i) in Section 3.1 rather than in the figure itself, so the claim that Figure 1 lacks a concrete example mapping is accurate."}
{"claim": "The authors do not provide a specific concrete example (for instance, a simple text classification) showing how non-causal factors become correlated with Y_t.", "claim_type": "methodology", "paper_id": "lWXedJyLuL", "paper_title": "A Unified Causal View of Instruction Tuning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "f6n4G0QZIH", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Let's consider the sentence \"Pizza is delicious.\" ... This sentence contains information about food, \"pizza\", and sentiment, \"delicious.\" ... For Y_t of sentiment classification, there is a backdoor path between Y_t and L_1, i.e., L_1 <- D -> L_2 -> Y_t , producing spurious correlation between food information L_1 and positive sentiment labels Y_t.", "b3_evidence": "1) \"As later analyzed, inherent dataset properties cause traditional methods to learn spurious correlations.\" 2) \"For example, the connotative semantics in a document are the causal factors for sentiment analysis, while the core denotative semantics are the causal factors for topic classification.\" 3) \"L → X_t, Y_t indicates that the source context X_t and target label Y_t are generated from the latent factors L. Considering that source context X_t carries all the information of L, X_t is pointed by all of L. Differently, not all latent factors are used to generate target label Y_t for a certain task.\"", "b2_justification": "The authors explicitly supply a concrete 'driven example' (the sentence 'Pizza is delicious.') that shows a non-causal factor (food information L1) becoming spuriously correlated with Y_t (sentiment) via dataset property D and a backdoor path.", "b3_justification": "The paper discusses spurious correlations and gives high-level, conceptual examples (e.g., connotative vs. denotative semantics) but does not present a specific concrete example or a simple text-classification demonstration that shows how non-causal factors become correlated with Y_t."}
{"claim": "Identifiability is typically defined for specific causal quantities between variables rather than for an entire SCM, but the paper treats identifiability at the SCM level without justification.", "claim_type": "methodology", "paper_id": "lWXedJyLuL", "paper_title": "A Unified Causal View of Instruction Tuning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "f6n4G0QZIH", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In causal inference, identifiability refers to ' A causal quantity can be computed from a purely statistical quantity.' [2]. However, in causal representation learning, identifiability has a different meaning - it indicates that 'Representations for each latent factor can be learned without mixing information with others, while ensuring that the difference between the learned representations and the true representations remains within acceptable bounds of uncertainty' [3, 4, 5]. The goal of the UIC is to guarantee latent variable identifiability under this definition from causal representation learning.\" \n\n\"selecting causal factors relies on the premise that the factors L_i are identifiable. Thus, we introduce a UIC Loss as a regularization term to ensure L_i identifiability.\"", "b3_evidence": "On the theoretical side, we present the Uniform Identifiability Condition (UIC), a sufficient and necessary condition to ensure identifiability of latent factors in the meta-SCM. The UIC guarantees these factors can be separated without mixing information from other factors by fitting the observed data.", "b2_justification": "The authors reject the reviewer's characterization and clarify that they use a different, representation-learning notion of identifiability (for latent factors) rather than the traditional causal-quantity notion; they further state they introduce a UIC loss to guarantee latent-variable identifiability and correct earlier unclear writing.", "b3_justification": "The paper explicitly provides a theoretical justification: it introduces a Uniform Identifiability Condition (UIC) and claims it is a sufficient and necessary condition guaranteeing identifiability of latent factors in the meta-SCM, with proofs and discussion of topology-based guarantees, so it does not treat identifiability at the SCM level without justification."}
{"claim": "The paper does not justify why identifiable latent factors would necessarily correspond to the true causal factors of Y_t.", "claim_type": "methodology", "paper_id": "lWXedJyLuL", "paper_title": "A Unified Causal View of Instruction Tuning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "f6n4G0QZIH", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"To clarify, we do not posit that \\\"if $L_i$ is identifiable, then it is a causal factor of $Y_t$.\\\" ... Notably, selecting causal factors relies on the premise that the factors $L_i$ are identifiable. Thus, we introduce a UIC Loss as a regularization term to ensure $L_i$ identifiability.\"", "b3_evidence": "1) \"Theoretically, we prove the causal factor can be identified without mixing information from others.\" (Abstract)\n2) \"In this section, ... we propose a uniform identifiability condition (UIC) based on the topological structure of SCM, which guarantees that latent factors in the SCM can be identified without mixing information from others by fitting the observed data.\" (Section 3)", "b2_justification": "The authors explicitly deny the assumption that identifiability implies causality, explaining that they do not claim \"if L_i is identifiable, then it is a causal factor of Y_t\" and that causal parents are selected via a learned binary matrix, with UIC used only to ensure identifiability as a prerequisite for selection.", "b3_justification": "The paper explicitly states a theoretical identifiability result (the Uniform Identifiability Condition) and claims to prove that causal factors can be identified without mixing information from other latent factors, thereby justifying the correspondence between identifiable latent factors and task-required causal factors for Y_t."}
{"claim": "The paper reports needing more than 1000 labeled images to match supervised accuracy, which deviates from established benchmarks requiring around 300–500 images.", "claim_type": "experimental", "paper_id": "yZBpnKpBCw", "paper_title": "Time- and Label-efficient Active Learning by Diversity and Uncertainty of Probabilities", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "AhzqNtmeeP", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "“We disagree that the experimental section is limited, we use a broad range of 10 different datasets from different categories (grey scale image, colored image, tabular) which is more than many other works in the literature: e.g., BADGE evaluates on 7 datasets. Moreover, we evaluate medical image data which is a very complex task and highly relevant for a real-world use case of active learning. However, we will include CIFAR10 in the final version of the paper.”", "b3_evidence": "Label Efficiency: Across varying datasets, active learning settings and model architectures FALCUN is always one of the most label-efficient methods.", "b2_justification": "The authors do not directly address the reviewer's specific point about requiring >1000 labeled images versus established benchmarks of ~300–500; their response discusses dataset variety, hyperparameters, and adding CIFAR10 but gives no explanation or counter-evidence about the labeled-sample counts or the discrepancy.", "b3_justification": "The provided paper excerpt does not report any experimental result stating that more than 1000 labeled images are needed to match supervised accuracy, nor does it provide the comparative benchmark numbers (300–500) cited by the reviewer. The paper only makes general claims about label efficiency (that FALCUN is label-efficient) but gives no numerical labeled-image thresholds in the supplied sections."}
{"claim": "The margin-based measure considers two class boundaries and may not generalize to multiclass settings without further justification.", "claim_type": "methodology", "paper_id": "yZBpnKpBCw", "paper_title": "Time- and Label-efficient Active Learning by Diversity and Uncertainty of Probabilities", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "AhzqNtmeeP", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In contrast, the margin uncertainty is maximal when a point is on the decision boundary. (e.g. [0.5,0.5,0,0] and [0,0,0.5,0.5] have the same margin score but lie on the decision boundary of two distinct class pairs, indicating that they are probably quite dissimilar).\" \n\n\"Using margin as initialization for diversity is advantageous because margin uncertainty has its maximal values along all decision boundaries between all classes. Thus, the set of chosen instances out of those with maximal margin uncertainty can be diverse.\"", "b3_evidence": "“Our task is multi-class classification on an input space X and a set of labels Y = {1, . . . , C} for C classes.”\n\n“For uncertainty, we use the margin uncertainty, i.e., the difference between the probabilities of its two most probable classes: … where 0 ≤ u(x) ≤ 1. Margin is a common choice for uncertainty (Roth & Small, 2006; Bahri et al., 2022; Jiang & Gupta, 2021) and naturally captures the class boundaries between each class pairs. In contrast to other simple uncertainty scores like entropy or least confidence, the margin uncertainty has an extremal function that contains a diverse set of samples: its optima lie on the class boundaries in the probability space.”\n\n“In Appendix A.2, we show the relation of margin uncertainty and the distances of objects to the one-hot encodings of their two most probable classes in the probability space.”", "b2_justification": "The authors explicitly disagree and argue margin uncertainty applies across multiclass boundaries—stating it attains maximal values along all decision boundaries and thus supports diverse selection in multiclass settings.", "b3_justification": "The paper explicitly defines and justifies margin uncertainty in the multiclass setting: it defines margin as the difference between the top two class probabilities for C classes, states that margin 'naturally captures the class boundaries between each class pairs', and refers to Appendix A.2 for a formal relation to one-hot class encodings. Thus the paper provides justification for using margin in multiclass settings, contradicting the reviewer's claim."}
{"claim": "The paper lacks results on real-world X-ray/CT datasets such as DGKr and w7Ci, which are necessary to demonstrate real-world applicability.", "claim_type": "experimental", "paper_id": "fMWrTAe5Iy", "paper_title": "R$^2$-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Vdom4sRbOm", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We will also thoroughly address the points you raised, especially clarifying the isotropic simplification and the benefits of our proposed voxelizer.\"", "b3_evidence": "\"Experiments on synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art approaches in accuracy and efficiency.\"", "b2_justification": "The authors' replies are generic acknowledgements and promise to incorporate clarifications, but they do not mention adding experiments or results on real-world X-ray/CT datasets like DGKr or w7Ci, so the claim is not addressed.", "b3_justification": "The paper explicitly states it evaluates on \"real-world datasets,\" but the provided content does not list dataset names (such as DGKr or w7Ci). From the given excerpts we cannot confirm whether those specific datasets were included or omitted."}
{"claim": "The authors do not explicitly state that their alpha-blending and per-Gaussian integration claims rely on the isotropic approximation of X-ray physics.", "claim_type": "methodology", "paper_id": "fMWrTAe5Iy", "paper_title": "R$^2$-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Vdom4sRbOm", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We will also thoroughly address the points you raised, especially clarifying the isotropic simplification and the benefits of our proposed voxelizer.", "b3_evidence": "Sec. 3.1: \"σ ( x ) is the isotropic density (or attenuation coefficient in physics) at position x ∈ R 3 . Note that real-world projections contain minor anisotropic physical effects such as Compton scattering. Following previous works [13, 2, 55, 67], we do not explicitly model them but treat them as noise during the reconstruction.\";\nSec. 3.2: \"The projected 2D Gaussian retains the same opacity and color as its 3D counterpart but omits the third row and column of position and covariance. An RGB image is then rendered by compositing these 2D Gaussians using alpha-blending [45]: I rgb = C ( G 2 ) .\"", "b2_justification": "Authors acknowledge the issue and state they will clarify the isotropic simplification in the final paper, thus agreeing the claim and committing to address it.", "b3_justification": "The paper explicitly assumes an isotropic density model for X-ray imaging (Sec. 3.1) and separately describes using alpha-blending and per-Gaussian projection in the 3DGS rasterizer (Sec. 3.2), but it does not explicitly state that the alpha-blending or per-Gaussian integration claims depend on that isotropic approximation; the reliance is only implicit."}
{"claim": "The manuscript omits discussed references such as the cited TV reference [c], which should be included for completeness and proper attribution.", "claim_type": "subjective", "paper_id": "fMWrTAe5Iy", "paper_title": "R$^2$-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Vdom4sRbOm", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We will incorporate the reviewers' remarks into the final version. We will also thoroughly address the points you raised, especially clarifying the isotropic simplification and the benefits of our proposed voxelizer.\"", "b3_evidence": "Some concurrent works have extended 3DGS to X-ray imaging. X-Gaussian [7] modify 3DGS to synthesize novel-view X-ray projections. Gao et al. [14] improve X-Gaussian by considering complex noise-inducing physical effects.", "b2_justification": "The authors promise to incorporate clarifications and address specific technical points but do not explicitly acknowledge or commit to adding the omitted citation(s) (e.g., TV reference [c]). Thus the specific claim about omitted references is not addressed.", "b3_justification": "The provided paper text does not mention a missing 'TV reference [c]' or discuss omitting that specific citation. The manuscript includes many citations in the Introduction and Related Work (e.g., [7,14], [13,2,55], [23]), but there is no evidence in the excerpt that a referenced item labeled '[c]' was discussed and omitted. Therefore there is insufficient information to confirm the reviewer's claim."}
{"claim": "The proposed model is not sufficiently novel because combining local and global perspectives in graph models is already a common idea.", "claim_type": "novelty", "paper_id": "auguNUCto5", "paper_title": "Boosting Temporal Graph Learning From Global and Local Perspectives", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "PXhDGnz45s", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"To the best of our knowledge, we are the first in the field of temporal graph learning to propose a method that simultaneously models the graph structure from an entire global perspective and a local subgraph perspective, and fuses all node embeddings across views.\"", "b3_evidence": "1) \"These methods produce node embeddings from a global or local perspective and ignore the complementarity between them, thus facing limitations... To address the challenges, we propose the Global and Local Embedding Network (GLEN) for effective and efficient temporal graph representation learning. Specifically, GLEN dynamically generates embeddings for graph nodes by considering both global and local perspectives.\" 2) \"- New Finding. We innovatively present that modeling from both global and local perspectives is indispensable for temporal graph representation learning. To the best of our knowledge, we are the first in the subfield of temporal graph learning to propose a method that simultaneously models the graph structure from an entire global perspective and a local subgraph perspective, and fuses all node embeddings across views.\"", "b2_justification": "The authors explicitly disagree with the reviewer, arguing their work is novel within the temporal graph learning subfield, distinguishing it from prior spatio-temporal or point-process works and claiming specific module-level contributions and first-to-combine choices.", "b3_justification": "The paper explicitly states that prior temporal graph methods focus on either a global or a local perspective and claims novelty in jointly modeling and fusing both perspectives; thus the reviewer's claim that combining local and global perspectives is already common contradicts the paper's stated contribution."}
{"claim": "The paper lacks a detailed discussion of temporal point process approaches and their relevance to the proposed temporal graph method.", "claim_type": "subjective", "paper_id": "auguNUCto5", "paper_title": "Boosting Temporal Graph Learning From Global and Local Perspectives", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "PXhDGnz45s", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We provide relevant discussions about the two methods using temporal point processes as follows. We will add relevant discussions of these methods in the future versions of our paper.\"", "b3_evidence": "1) \"Temporal graph methods. GNN-RNN-based temporal graph methods such as EvolveGCN (Pareja et al., 2020), CTGCN (Liu et al., 2020), and GCRN (Seo et al., 2018) ... Message-passing temporal graph networks (MP-TGNs) such as JODIE (Kumar et al., 2019), TGAT (Xu et al., 2020), TGN (Rossi et al., 2020), APAN (Wang et al., 2021b), and TPGNN (Wang et al., 2022) ... Walk-aggregating temporal graph networks (WA-TGNs) such as evolve2vec (Bastas et al., 2019a), STWalk (Pandhre et al., 2018), and EVONRL (Heidari & Papagelis, 2020)...\" 2) \"Interaction events occur temporally between nodes, which is represented as an event stream E = { e_uv(t) } ordered by time.\"", "b2_justification": "The authors acknowledge the reviewer's concern, provide explicit discussions comparing temporal point process methods (Lu et al., TREND) to their approach, present empirical comparisons versus TREND, and state they will add these discussions in the paper.", "b3_justification": "The paper's related work and preliminaries describe event streams, GNN-RNN, MP-TGN and WA-TGN approaches and time-encoding/memory mechanisms but contain no discussion of temporal point process (TPP) methods or their relevance to GLEN. Thus the claim that the paper lacks a detailed discussion of TPP approaches is supported."}
{"claim": "The paper should include additional experimental comparisons with temporal point process methods to validate claimed advantages of GLEN over global modeling approaches.", "claim_type": "baseline", "paper_id": "auguNUCto5", "paper_title": "Boosting Temporal Graph Learning From Global and Local Perspectives", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "PXhDGnz45s", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"To indicate the difference between our method and methods using temporal point processes, we show here the inductive link prediction performance ... comparison between our approach GLEN and TREND, as TREND is the SOTA method that uses the temporal point processes:\" and \"The experimental results above somewhat demonstrate the advantages of our approach over methods that use temporal point processes. In addition, the training efficiency of our model is much higher than TREND.\"", "b3_evidence": "\"GNN-RNN-based temporal graph methods such as EvolveGCN (Pareja et al., 2020), CTGCN (Liu et al., 2020), and GCRN (Seo et al., 2018) ... Message-passing temporal graph networks (MP-TGNs) such as JODIE (Kumar et al., 2019), TGAT (Xu et al., 2020), TGN (Rossi et al., 2020), APAN (Wang et al., 2021b), and TPGNN (Wang et al., 2022) ... Walk-aggregating temporal graph networks (WA-TGNs) such as evolve2vec (Bastas et al., 2019a), STWalk (Pandhre et al., 2018), and EVONRL (Heidari & Papagelis, 2020) ...\"", "b2_justification": "The authors directly address the request by discussing temporal point-process methods, explaining differences, and providing empirical comparisons (including a table comparing GLEN to TREND) showing GLEN's superior performance and higher training efficiency.", "b3_justification": "The paper's Related Works and method descriptions enumerate GNN-RNN, message-passing TGNs, and walk-aggregating TGNs as the compared/considered families but do not mention temporal point process (TPP) methods nor report experiments comparing against TPP-based approaches. Therefore the reviewer's recommendation that additional experimental comparisons with temporal point process methods are needed is consistent with what the paper omits."}
{"claim": "It is unclear whether the main claim is that Bayesian ToM-teachers better capture human internal state changes.", "claim_type": "experimental", "paper_id": "WcSofkUVge", "paper_title": "Utility-based Adaptive Teaching Strategies using Bayesian Theory of Mind", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "RYHtZ3asnL", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"One of the main focuses of our work was to explore the utility of teachers utilizing a Theory of Mind (ToM) model compared to learner-agnostic baselines... since our work is confined to simulated environments and virtual agents, further investigation, particularly involving human users, would be necessary to extrapolate our findings and draw conclusions about humans. Yet, we consider such research beyond the scope of this paper.\"", "b3_evidence": "Abstract: \"Our ToM-equipped teachers construct models of learners' internal states from observations and leverage them to select demonstrations that maximise the learners' rewards while minimising teaching costs. Our experiments in simulated environments demonstrate that learners taught this way are more efficient than those taught in a learner-agnostic way.\"", "b2_justification": "The authors clarify the paper's primary goal is comparing ToM-based teachers to learner-agnostic baselines in simulated (machine-to-machine) settings, and they explicitly state they do not claim results about humans — human-subject validation is beyond the paper's scope.", "b3_justification": "The paper clearly states its main claim: Bayesian ToM-equipped teachers model learners' internal states to select demonstrations that improve teaching efficiency (learners taught this way are more efficient than learner-agnostic ones). It does not frame the main claim as being about 'better capture[ing] human internal state changes' or leave that unclear."}
{"claim": "The paper claims to estimate learner transition and observation parameters but does not clearly explain how the learner's internal goal is estimated.", "claim_type": "methodology", "paper_id": "WcSofkUVge", "paper_title": "Utility-based Adaptive Teaching Strategies using Bayesian Theory of Mind", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "RYHtZ3asnL", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "The teacher only observes the learner’s internal state through a trajectory of this learner in the observation environment. The teacher also knows the initial belief of the learner in every environment, which is a uniform distribution in our setup. ... From a past trajectory τ^obs = {(s_k, a^{obs}_k )}^{K−1}_{k=0} of an unknown learner L on the first environment Mobs [...]", "b3_evidence": "1) \"ToM-teachers able to 1. update a belief about the internal state (i.e. goal, intention, belief, sensory capacity) of an unknown learner through Bayesian inference based on observations of its behaviour in a simple environment, see Figure 1(A), and\" (Introduction).\n\n2) \"the teacher ignores the goal of the learner and its sensory capacity, but can infer them from a past trajectory of the learner in a simpler environment.\" (Introduction).\n\n3) \"To simulate a trajectory τ_i of learner L_i on M_j, one only needs to know the tuple (π_j, g_i, v_i, b_{i,j}^0).\" (Methods, 3.2 LEARNER).\n\n4) \"<!-- formula-not-decoded -->\" (appears in Methods where update/inference formulas would be expected), indicating missing/undecoded explicit equations.", "b2_justification": "The authors clarify that the teacher infers the learner's internal state (including goals) from observed trajectories and the learner's initial belief, and they state they formalized the teacher's task and clarified the teacher's observation model. However, they do not provide a clear, explicit algorithmic description of how the learner's internal goal is estimated (e.g., the exact inference procedure or likelihood computation), so the reviewer's concern is only partially addressed.", "b3_justification": "The paper explicitly states that the teacher infers the learner's internal state (including goal and sensory capacity) via Bayesian inference from past behaviour (Introduction and ToM description). However, the provided Methods section does not present a clear, explicit procedure or decoded equations showing how the learner's goal posterior is computed (key formula blocks are missing/undecoded), so the mechanics of goal estimation are not clearly explained in the available text."}
{"claim": "The proposed method may be applicable only to a limited set of task types, but the paper does not clarify these limitations.", "claim_type": "presentation", "paper_id": "wnPlJNiqfA", "paper_title": "KFNN: K-Free Nearest Neighbor For Crowdsourcing", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "RmGxXHTEuK", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Our current version of KFNN can be used for both single choice tasks and labeling tasks. We will clarify the application scope of KFNN in the final version of the paper.\"", "b3_evidence": "\"In KFNN, the neighborhood size of each instance is automatically determined based on its attributes and noisy labels.\" (Abstract)\n\n\"KFNN initially estimates a Mahalanobis distance distribution from the attribute space to model the relationship between each instance and all classes.\" (Abstract)\n\n\"Let D = { ( x_i , L_i ) } denote a crowdsourced dataset... x_i can be represented as { x_im }_{m=1}^M. Here, M is the dimension of attributes... L_i denotes multiple noisy labels of x_i...\" (3.1 Preliminary)\n\n\"KFNN automatically determines the optimal neighborhood size for each instance based on its attributes and noisy labels...\" (Related work / Introduction)", "b2_justification": "The authors acknowledge the limitation and specify which task types KFNN currently supports (single-choice and labeling) and commit to clarifying the application scope in the final paper, but they do not fully resolve or generalize the method's applicability to other task types.", "b3_justification": "The paper consistently frames KFNN as operating on instances with attribute vectors and multiple noisy labels and explicitly uses Mahalanobis distances in the attribute space, which implies the method requires attribute-based tasks and may not apply where such attributes are absent. However, the paper does not explicitly state or discuss these applicability limitations anywhere, so the reviewer’s concern about lack of clarification is correct while the claim that it 'may be applicable only to a limited set of task types' is an inference rather than an explicitly stated limitation."}
{"claim": "The paper lacks reported time costs for meta-learning training and for model inference, preventing assessment of computational efficiency.", "claim_type": "quantitative", "paper_id": "5RielfrDkP", "paper_title": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "stCa35d4sd", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "For the OGBN-Arxiv dataset in which we use full-batch for training, training one epoch takes 2.86 seconds with meta-learning on average, and the inference takes 2.65 seconds.", "b3_evidence": "Abstract: \"Extensive experiments demonstrate that our MM-FGCN achieves SOTA performance on various graph learning tasks. The code is available on GitHub 1 .\"; Contributions: \"Extensive experiments show that our model achieves state-of-the-art performance compared to other baseline methods.\"", "b2_justification": "The authors added explicit training and inference time measurements (tables and numeric values) and a complexity discussion, directly addressing the request for reported time costs.", "b3_justification": "The provided paper content describes experimental evaluation and claims state-of-the-art performance but contains no reported training or inference time costs, nor any metrics of computational efficiency or runtime. Thus the reviewer's claim that time costs for meta-learning training and model inference are not reported is supported by the paper text provided."}
{"claim": "The reported performance is not close to state-of-the-art; more recent studies (e.g., cited [1], [2]) show better performance.", "claim_type": "baseline", "paper_id": "5RielfrDkP", "paper_title": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "stCa35d4sd", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"As shown in Table 3, our performance remains to be the SOTA method.\" \"We conduct comprehensive experiments to compare our method with Dir-GCN [18] and FSGNN [19] under the same experimental settings.\" \"The experiment results show that our method achieves the highest performance among various state-of-the-art baselines on both datasets.\"", "b3_evidence": "\"Extensive experiments demonstrate that our MM-FGCN achieves SOTA performance on various graph learning tasks.\"; \"Extensive experiments show that our model achieves state-of-the-art performance compared to other baseline methods.\"", "b2_justification": "The authors directly rebut the claim by adding comparisons to recent SOTA methods (e.g., Dir-GCN, FSGNN, GraphGPS/Graph transformer, GIN) and report new experimental results showing MM-FGCN outperforms those baselines, claiming SOTA performance.", "b3_justification": "The paper explicitly claims that its method achieves state-of-the-art performance. The reviewer claim that reported performance is not close to SOTA contradicts the paper's stated results; the provided content includes explicit SOTA claims (though numerical results are not shown in the excerpt)."}
{"claim": "The paper lacks a detailed introduction to meta-learning, hindering readers' understanding of the experimental setup and method rationale.", "claim_type": "presentation", "paper_id": "5RielfrDkP", "paper_title": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "stCa35d4sd", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We have added the missing necessary details to the manuscript. In Appendix A.2, we have added the subsections of 'Design of the neural network $M_{\\xi}$', and 'Split of $S_{meta}$ and $S_{main}'. In Appendix B.8 'Ablation studies of meta-learning', we have added the extra experiments on the ablation study of meta-learning and discussed why the meta-learning can enhance our model's performance.\" and \"How meta-learning works? Following [16], in this paper, Meta-learning is understood as ‘learning-to-learn’... We aim to design a meta-objective that refers to ‘finding a good $\\omega$ such that the $\\omega$-base-objective can be achieved well'... By combining the base- and meta-objectives, we establish the meta-learning training paradigm of MM-FGCN as a bi-level optimization problem.\"", "b3_evidence": "Introduction: \"This motivates us to establish a meta-learner to generate the customized feature transform and multiresolution analysis strategy for each individual graph instance.\"  Preliminary (topics covered): \"Graph Representation Learning... Spectral Graph Signal Processing... Spectral Graph Multiresolution Analysis.\"", "b2_justification": "The authors report adding a dedicated explanation of meta-learning to the appendix, provide a conceptual description of how meta-learning works in their method, and include ablation experiments and discussion showing why meta-learning improves performance—directly addressing the reviewer's request for a detailed introduction.", "b3_justification": "The paper only briefly mentions a \"meta-learner\" in the Introduction to motivate the method but provides no dedicated background or detailed introduction to meta-learning in Related Work or Preliminary sections, indicating a lack of detailed meta-learning exposition."}
{"claim": "The SparklesDialogueVG subset was generated using GPT-4, introducing dependency on the same model being evaluated.", "claim_type": "methodology", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"SparklesChat underperforms compared to GPT-4, despite using richer image representations, because GPT-4 operates based on detailed image annotations and the evaluation set was generated by GPT-4. This gives GPT-4 an inherent advantage in image understanding tasks, as it does not face the same challenges in interpreting images.\"", "b3_evidence": "\"We use OpenAI's GPT-4 (Openai, 2023) to simulate user-assistant conversations with visual capabilities by leveraging detailed image descriptions.\" \n\n\"SparklesDialogueVG is of high quality as the VG image descriptions generated by GPT-4 benefit from human-annotated captions, objects,\" \n\n\"SparklesChat scored 8.56 out of 10 on SparklesEval, substantially exceeding MiniGPT-4's score of 3.91 and nearing GPT-4's score of 9.26.\"", "b2_justification": "The authors explicitly acknowledge that the evaluation set was generated by GPT-4 and state this gives GPT-4 an inherent advantage, and they also acknowledge similarity concerns and plan to diversify the data—i.e., they agree the dataset creates dependency.", "b3_justification": "The paper explicitly states that GPT-4 was used to generate the SparklesDialogue data (including VG descriptions) and also reports GPT-4's performance on SparklesEval, meaning the same model was used for data generation and evaluation, supporting the reviewer's claim."}
{"claim": "The paper compares model performance to GPT-4 despite GPT-4 being used to generate part of the training dataset.", "claim_type": "baseline", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"SparklesChat underperforms compared to GPT-4, despite using richer image representations, because GPT-4 operates based on detailed image annotations and the evaluation set was generated by GPT-4. This gives GPT-4 an inherent advantage in image understanding tasks, as it does not face the same challenges in interpreting images.\"", "b3_evidence": "1) \"To support the training of SparklesChat, we introduce SparklesDialogue, the first machine-generated dialogue dataset designed for word-level interleaved multi-image and text interactions. We use OpenAI's GPT-4 (Openai, 2023) to simulate user-assistant conversations with visual capabilities by leveraging detailed image descriptions.\"; 2) \"In our SparklesEval benchmark, SparklesChat scores 8.56 out of 10, significantly exceeds MiniGPT-4's score of 3.91, and closely approaches GPT-4's score of 9.26.\"", "b2_justification": "Authors explicitly acknowledge that GPT-4 was used to generate the evaluation data and that this gives GPT-4 an inherent advantage, thereby agreeing with the reviewer's concern.", "b3_justification": "The paper explicitly states that GPT-4 was used to generate the SparklesDialogue training data (Section 4.1 / Introduction) and also reports GPT-4's score as a comparison in the SparklesEval evaluation, so it does compare to GPT-4 despite GPT-4 contributing to the training dataset."}
{"claim": "The dataset contains only two dialogue turns per sample, which limits modeling of longer conversational sessions.", "claim_type": "quantitative", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We initially created two-turn dialogues to validate our ideas in unlocking chats across multiple images and turns, which is adaptable to more turns, as shown in Figure 8. Additionally, we acknowledge the practicality of longer sessions and plan to expand the dataset accordingly.\"; \"To analyze SparklesChat's ability to generalize in scenarios involving a larger number of images... In the case of Figure 10, where three questions involving five images are concatenated into one query, the model tends to ignore the final question... We believe this limitation arises from the absence of similar patterns in the training data. A potential solution could involve incorporating multiple turns into each training dialogue to enhance the model's ability to handle such complex scenarios.\"", "b3_evidence": "We instruct GPT-4 to simulate realistic and diverse dialogues between a user and an assistant with advanced image understanding and reasoning capabilities following a structured two-turn pattern. In the first turn, the user initiates a reasonable and creative message regarding some images. In response, the assistant generates detailed answers that include comprehensive reasoning regarding the visual content. In the second turn, the user introduces a new image for further discussion, referencing both the new and previous images.", "b2_justification": "The authors acknowledge the two-turn design as a limitation, state the setup was for validation, claim the approach is adaptable to more turns, provide examples of multi-image dialogues in the appendix, and say they plan to expand the dataset — but they do not provide immediate extended data or full empirical evidence that longer-session modeling is solved.", "b3_justification": "The paper explicitly states that SparklesDialogue is generated using a \"structured two-turn pattern\", so each dialogue sample contains two turns. However, the paper does not state that this design \"limits modeling of longer conversational sessions\"—that limitation is a reviewer inference not asserted by the paper."}
{"claim": "Limiting samples to only two turns sacrifices longer-session practicality in favor of more images per turn.", "claim_type": "methodology", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We initially created two-turn dialogues to validate our ideas in unlocking chats across multiple images and turns, which is adaptable to more turns, as shown in Figure 8. Additionally, we acknowledge the practicality of longer sessions and plan to expand the dataset accordingly.\"", "b3_evidence": "We instruct GPT-4 to simulate realistic and diverse dialogues between a user and an assistant with advanced image understanding and reasoning capabilities following a structured two-turn pattern. In the first turn, the user initiates a reasonable and creative message regarding some images. ... In the second turn, the user introduces a new image for further discussion, referencing both the new and previous images.", "b2_justification": "The authors acknowledge they initially used two-turn dialogues, state the setup is adaptable to more turns, provide examples of multi-image/turn capabilities in appendices, and commit to expanding the dataset—thus recognizing the concern but not fully conceding it as a fixed limitation.", "b3_justification": "The paper explicitly states that GPT-4 was instructed to generate dialogues following a \"structured two-turn pattern,\" so the factual claim that samples are limited to two turns is supported (Section 4.1). However, the paper does not state or argue that this choice \"sacrifices longer-session practicality in favor of more images per turn\" or discuss such a trade-off, so that interpretive consequence is not supported by the text."}
{"claim": "The dataset is machine-generated rather than human-created, weakening its value as the paper's principal contribution.", "claim_type": "novelty", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Our dataset and evaluation process has involved initial human review, including manual initiation and selection of dialogue demonstrations and rigorous quality checks, as detailed in Section 4.1 of our paper.\"; \"We instruct GPT-4 to simulate realistic user-assistant interactions ... and not to directly describe images ... Thus, the generated dialogues are not mere concatenations of descriptions but are contextually rich and coherent conversations.\"", "b3_evidence": "1) \"To support the training, we introduce SparklesDialogue , the first machine-generated dialogue dataset tailored for word-level interleaved multi-image and text interactions.\" \n2) \"To achieve this, we use GPT-4 as the primary tool in our dialogue data generation, given its capabilities to follow complex instructions and extensive world knowledge.\" \n3) \"We instruct GPT-4 to simulate realistic and diverse dialogues between a user and an assistant with advanced image understanding and reasoning capabilities following a structured two-turn pattern.\" \n4) \"Our experiments validate the effectiveness of SparklesChat in understanding and reasoning across multiple images and dialogue turns.\"", "b2_justification": "Authors do not deny using machine generation (GPT-4) but argue the dataset was curated with human oversight, instructions to avoid naive descriptions, and quality checks; they thus partially rebut the claim that being machine-generated wholly weakens its value.", "b3_justification": "The paper clearly states the dataset (SparklesDialogue) is machine-generated using GPT-4, so the factual part of the claim is supported. However, the reviewer's assertion that this 'weakens its value as the paper's principal contribution' is an opinion not asserted by the paper; the paper presents the machine-generated dataset as a core contribution and provides experimental results and usage to argue its usefulness."}
{"claim": "Results are reported only for MiniGPT-4 extensions, lacking experiments that evaluate applicability to other approaches like LLaVA.", "claim_type": "baseline", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we extended our approach to more advanced models such as LLaVA-v1.5\"; \"LLaVA-v1.5*  | **+SparklesDialogue**| 65.3% | 56.7% | 7.93\"; \"updated in the revised manuscript in Section 5.1 and Table 2.\"", "b3_evidence": "\"Specifically, SparklesChat outperformed MiniGPT-4 on established vision-language benchmarks, including the BISON binary image selection task and the NLVR2 visual reasoning task. Moreover, SparklesChat scored 8.56 out of 10 on SparklesEval, substantially exceeding MiniGPT-4's score of 3.91 and nearing GPT-4's score of 9.26.\"", "b2_justification": "The authors explicitly state they extended experiments to LLaVA-v1.5, provide quantitative results for LLaVA-v1.5 and a fine-tuned LLaVA-v1.5*, and note updates to the manuscript/Table 2.", "b3_justification": "The paper's quantitative results and comparisons report SparklesChat against MiniGPT-4 (and GPT-4) on BISON, NLVR2, and SparklesEval; it does not present experimental evaluations or comparisons involving other multimodal approaches such as LLaVA."}
{"claim": "The overall contributions of the paper are weak, relying primarily on dataset creation rather than substantial technical advances.", "claim_type": "novelty", "paper_id": "oq5EF8parZ", "paper_title": "Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "WbH03mw5Tg", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Thank you for pointing out that the dataset is our main contribution. Our contribution to the model is the open-source SparklesChat to support chats across multiple images and dialogue turns.\"", "b3_evidence": "Abstract: \"To support the training, we introduce SparklesDialogue , the first machine-generated dialogue dataset tailored for word-level interleaved multi-image and text interactions. Furthermore, we construct SparklesEval , a GPT-assisted benchmark for quantitatively assessing a model's conversational competence across multiple images and dialogue turns.\"; Introduction: \"SparklesChat, as shown in Figure 1, integrates multiple images at the word level (e.g., \\\"Can you link the celebration occurring in IMAGE#2331159 and the dirt bike race in IMAGE#2330601 ?\\\"). This innovation enables fine-grained integration of images and text, mimicking natural human communication more closely.\"; Section 3 (Architecture): \"Only the projection layer is trainable in the model while other vision and language components are frozen.\"", "b2_justification": "The authors acknowledge the reviewer’s point that the dataset is the main contribution but contest that this is the only contribution: they claim a model contribution (SparklesChat) enabling multi-image multi-turn chats and present experimental evidence (including extending to LLaVA-v1.5) to support technical progress beyond dataset creation.", "b3_justification": "The paper indeed emphasizes dataset and benchmark contributions (SparklesDialogue and SparklesEval) as central to the work, which supports the reviewer's point about dataset reliance. However, the paper also claims a technical contribution—integrating multiple images at the word level within the model architecture (SparklesChat) and demonstrating empirical gains—so the claim that contributions are primarily dataset-only is only partially true."}
{"claim": "The authors assert that performance saturates quickly with dataset size but provide no experimental evidence or analyses to support this claim.", "claim_type": "experimental", "paper_id": "Y4mBaZu4vy", "paper_title": "The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Zh7uivbHf7", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "We have added an experiment demonstrating the scalability of EGAP in the attached pdf (Figure 1). ... From the figure, we see that EGAP scales well when data size and number of parameters increases.", "b3_evidence": "We contend that these increasingly complex domain constraints inhibit the scaling ability of NNIPs, and such strategies are likely to cause model performance to plateau in the long run.", "b2_justification": "The authors state they added scalability experiments and report that EGAP \"scales well when data size and number of parameters increases,\" providing empirical results (OC20 splits, Figure 1) that counter the claim of rapid performance saturation.", "b3_justification": "The paper does not assert that performance saturates quickly with dataset size. Instead, it argues that imposing complex domain constraints may cause performance to plateau and presents ablation studies and evidence about scaling with model parameters and compute. Thus the reviewer's statement that the authors claim dataset-size saturation (and provide no supporting evidence) is not an accurate description of the paper."}
{"claim": "Because training trades off energy and force predictions, prioritizing one metric can explain observed differences, so metric differences do not demonstrate overall superiority.", "claim_type": "methodology", "paper_id": "Y4mBaZu4vy", "paper_title": "The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "Zh7uivbHf7", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "Examples from the response: \"Energy MAE (mEV/atom) = Energy MAE (kcal/mol) / (mEV to kcal/mol) / (Number of Atoms) = 0.0654 / 0.02306052 / 42 = 0.06752418667\"; \"During training, we used the same train/val/test dataset splits as MACE ... There is also a unit conversion between the two papers, which we accounted for in our row in the table in the PDF.\"; \"We have updated the results of EGAP on OC20 2M and All+MD split, with comparisons of relevant baselines. Our model is now state-of-the-art on both OC20 All+MD and OC20 2M...\"", "b3_evidence": "\"These models are usually trained to predict the system energy and per-atom force based on system properties, including atomic numbers and positions.\"; \"Energy (eV) and force (eV/Å) mean absolute error (MAE) are reported, along with the model's parameter counts.\"; \"Results with Energy MAE can be found in the Appendix Fig. 7.\"", "b2_justification": "The authors focus on unit conversions, dataset splits, and recalculated/updated experimental results but do not acknowledge, discuss, or rebut the reviewer's conceptual point that training may trade off energy vs. force predictions or that prioritizing one metric could explain observed differences.", "b3_justification": "The paper reports both energy and force MAE and compares models (see Figure 2 and Fig.1 captions), but it does not state or analyze that training involves an explicit trade-off between optimizing energy versus forces or that prioritizing one metric explains observed differences. There is no discussion in the provided text attributing metric differences to such a trade-off."}
{"claim": "DCPS defines the likelihood g^l_m(x_m) as the conditional expectation E[g_{k_l}(x_{k_l}) | x_m], rather than the rough approximation to E[g_0(x_0) | x_m] used in SDA.", "claim_type": "methodology", "paper_id": "BOrut7M2X7", "paper_title": "Divide-and-Conquer Posterior Sampling for Denoising Diffusion priors", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "IgYyLGCtuC", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"...our work differs significantly from [SDA]: First, regarding the number of elements of this sequence (the number $L$), second and more importantly, regarding how these distributions are defined and the way we sample from them.\"; \"For your second point: 'My intuition is that potentials $g_m(x)$ defined as in Eq. (3.9), (3.10) or (3.11) but with $m$ instead of $k_\\ell$ would work nearly as well.' We have already experimented with the setting you suggest and found that it doesn’t compare favorably with DCPS.\"", "b3_evidence": "“define the potentials g⋆_k(x_k) := ∫ g_0(x_0) p_{0|k}(x_0 | x_k) d x_0. Note that these potentials satisfy the recursion g⋆_{k+1}(x_{k+1}) = ∫ g⋆_k(x_k) p_{k|k+1}(x_k | x_{k+1}) d x_k.”\n\n“For the Diffusion Posterior Sampling (DPS) algorithm [10], the point mass approximation δ_{ˆx_{0|k}(x_k)} of p_{0|k}(·|x_k) results in the estimate ∇_{x_k} log g_0(ˆx_{0|k}(x_k)) of ∇_{x_k} log g⋆_k(x_k).”", "b2_justification": "Authors acknowledge the distinction in how distributions/potentials are defined between DCPS and SDA and state they tested the alternative (using m instead of k_l) and found it inferior, which implies agreement that DCPS uses k_l-based potentials (i.e., the reviewer’s characterization).", "b3_justification": "The paper defines the potentials used for backward twisting as conditional expectations of earlier potentials (i.e., g*_k(x_k) = E[g_0(X_0) | X_k = x_k]) and explicitly notes the recursion g*_{k+1}(x_{k+1}) = E[g*_k(X_k) | X_{k+1} = x_{k+1}]. It also contrasts this with DPS, which uses a point-mass approximation of p_{0|k} (a rough approximation to E[g_0|x_k]). Thus the paper supports the claim that DCPS uses intermediate (conditional expectation) potentials rather than the crude point-mass approximation used in DPS/SDA."}
{"claim": "Potentials defined as in Eq.(3.9)-(3.11) but using index m instead of k_l would likely perform nearly as well, suggesting the potential choice may not be the critical factor.", "claim_type": "experimental", "paper_id": "BOrut7M2X7", "paper_title": "Divide-and-Conquer Posterior Sampling for Denoising Diffusion priors", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "IgYyLGCtuC", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We have already experimented with the setting you suggest and found that it doesn’t compare favorably with DCPS.\" \"As stated in our rebuttal, we firmly believe that the main gains stem essentially from our choice of potentials and the KL minimization step.\"", "b3_evidence": "1) \"These distributions are induced by a sequence of increasingly complex potentials and converge to the target distribution.\" 2) \"The effectiveness of this technique depends heavily on the choice of intermediate potentials ( g_k )_{n k =1}, as discussed in [54, 59, 7, 16].\"", "b2_justification": "The authors state they tested the suggested alternative and found it performed worse, and emphasize that their choice of potentials is a primary source of their method's gains, thus directly opposing the reviewer's claim.", "b3_justification": "The paper repeatedly emphasizes that the choice of intermediate potentials is important and central to performance (Section 2 and Introduction). It proposes a sequence of increasingly complex potentials that converge to the target and argues that effectiveness depends heavily on the potential choice, which contradicts the reviewer's claim that a simple index change would not matter."}
{"claim": "The authors do not analyze which noise statistics improve performance nor identify conditions where added noise will deteriorate results.", "claim_type": "experimental", "paper_id": "0bMmZ3fkCk", "paper_title": "NEFTune: Noisy Embeddings Improve Instruction Finetuning", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "vmTbtNCVEl", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“Concerning the ablation of different noise levels, while we had originally run NEFTune with additional noise scales, i.e. values of alpha, we did not include those results in the initial submission copy. We have now re-run these experiments for the alpaca dataset...At low noise levels like $0.1$ and $1$ NEFTune does not meaningfully alter performance. On the other hand, slightly larger intermediate noise levels such $\\alpha=50$ lead to reduced performance compared to the optimal settings of $\\alpha=10$. For significantly larger noise values, such as $\\alpha=100$, performance _does_ noticeably degrade as the generations become repetitive and nonsensical.”; “In particular, through the combination of ablation across noise scales in the response above (Table 6) and the analysis section on token flip rates at different noise scales, the updated version of this work begins to establish a more mechanistic understanding of how NEFTune works.”; “For every value of alpha, it seems that uniform performs better.”", "b3_evidence": "Section 2: \"The noise is generated by sampling iid uniform entries, each in the range [ -1 , 1] , and then scaling the entire noise vector by a factor of α/ √ Ld...\"; Section 3.2: \"We set our hyperparameters through a coarse sweep on LLaMA-1 ( 7 B) trained on the Alpaca dataset, where we see 6% improvement over the standard Alpaca model. We use these as the defaults on all models.\"; Section 4: \"we note that some capabilities of this checkpoint model may be affected like its ability to refrain from outputting toxic behavior.\"", "b2_justification": "The authors report ablations over noise magnitude (alpha) and noise type (Gaussian vs Uniform), show a table of performance by alpha including clear degradation at very high noise, and attribute degradation to token flips—therefore addressing which noise statistics help and when added noise hurts.", "b3_justification": "The paper specifies a single noise scheme (iid uniform in [-1,1] scaled by α/√(Ld)) and only mentions a coarse hyperparameter sweep for α; it does not compare different noise statistics or systematically identify conditions where noise worsens performance (only an unquantified note that some capabilities 'may be affected')."}
{"claim": "The paper does not study the range of noise initializations and their impact on the robustness and reliability of the proposed method.", "claim_type": "experimental", "paper_id": "0bMmZ3fkCk", "paper_title": "NEFTune: Noisy Embeddings Improve Instruction Finetuning", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "vmTbtNCVEl", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Concerning the ablation of different noise levels, while we had originally run NEFTune with additional noise scales, i.e. values of alpha, we did not include those results in the initial submission copy. We have now re-run these experiments for the alpaca dataset, incorporated them into the updated manuscript, and we presented them in the table below for clarity. At low noise levels like $0.1$ and $1$ NEFTune does not meaningfully alter performance. On the other hand, slightly larger intermediate noise levels such $\\alpha=50$ lead to reduced performance compared to the optimal settings of $\\alpha=10$. For significantly larger noise values, such as $\\alpha=100$, performance _does_ noticeably degrade as the generations become repetitive and nonsensical. ... This result shows that there is a minimum amount of noise required before NEFTune becomes effective and when there is too much noise NEFTune becomes less effective.", "b3_evidence": "“The noise is generated by sampling iid uniform entries, each in the range [-1, 1], and then scaling the entire noise vector by a factor of α/√Ld, where L is the sequence length, d is the embedding dimension, and α is a tunable parameter.”\n\n“We set our hyperparameters through a coarse sweep on LLaMA-1 (7B) trained on the Alpaca dataset, where we see 6% improvement over the standard Alpaca model. We use these as the defaults on all models.”", "b2_justification": "The authors report new experiments across multiple noise scales (alpha values), provide a table of results showing performance variation (including degradation at very high alpha and minimal effect at very low alpha), and discuss mechanisms (token flips) and stability across seeds—directly addressing the reviewer's concern about the range of noise initializations and their impact.", "b3_justification": "The paper defines a single noise generation scheme (iid uniform in [-1,1] scaled by α/√(Ld)) and notes only a 'coarse sweep' to set hyperparameters; it does not present a systematic study or ablation over different noise initializations, distributions, or detailed robustness/reliability analyses in the provided content."}
{"claim": "The key frame sampling procedure for successful experiences is an important implementation detail that the paper does not explain.", "claim_type": "methodology", "paper_id": "OqTMUPuLuC", "paper_title": "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xN8k5wi0lW", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We indeed overlooked the details of keyframe sampling in our text. In our experiments, we uniformly sample frames in the sequence at equal intervals. However, this is merely a simple setup for our experiments. A more effective approach would be to cluster the scene descriptions of these frames and then select a frame from each cluster for storage.", "b3_evidence": "\"Initialization : The Initialization of memory module is akin to a human attending driving school before hitting the road. We select a few scenarios and manually outline the correct reasoning and decision-making processes for these situations to form the initial memory.\" \"Memory recall : At each decision frame, the agent receives a textual description of the driving scenario. Before making a decision, the current driving scenario is embedded into a vector, which serves as the memory key. This key is then clustered and searched to find the closest scenarios (Johnson et al., 2019) in the memory module and their corresponding reasoning processes, or memories.\" ", "b2_justification": "The authors acknowledge they overlooked the detail and provide the actual sampling procedure used (uniform sampling) and suggest a better alternative, directly addressing the reviewer's point.", "b3_justification": "The paper's Memory module (Section 3.2) describes initializing a small set of scenarios, embedding scene descriptions, clustering and retrieving nearest memories, and storing scene-description→reasoning pairs, but it does not describe any procedure for sampling key frames from successful experiences or how such key-frame selection is performed."}
{"claim": "The paper does not include a baseline implementing mixture-of-experts voting or winner-takes-all retrieval to compare against the proposed memory-based few-shot approach.", "claim_type": "baseline", "paper_id": "OqTMUPuLuC", "paper_title": "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xN8k5wi0lW", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"To address your concern To address your concern, we conducted additional tests using a winner-take-all baseline method with the following setup: ... We conducted ten repeated experiments, and here are the results: ... Winner takes all, with 160 memories | 60% | 22.5 | 30 ... DiLu, with 40 memories | **90%** | **27.7** | **30**\"", "b3_evidence": "\"Remarkably, with only 40 memory items, DiLu achieves comparable performance to the reinforcement learning (RL) based methods that have extensively trained over 600,000 episodes, but with a much stronger generalization ability to diverse scenarios.\"; \"Memory recall : At each decision frame, the agent receives a textual description of the driving scenario. Before making a decision, the current driving scenario is embedded into a vector, which serves as the memory key. This key is then clustered and searched to find the closest scenarios (Johnson et al., 2019) in the memory module and their corresponding reasoning processes, or memories.\"", "b2_justification": "The authors state they conducted an additional winner-take-all baseline (exactly the kind of baseline the reviewer requested) and report comparative results showing it underperformed DiLu, directly addressing the reviewer's concern.", "b3_justification": "The paper describes comparisons to reinforcement-learning baselines and details its memory recall (nearest/clustered retrieval) mechanism, but it does not mention or implement a baseline using mixture-of-experts voting or a winner-takes-all retrieval strategy for comparison."}
{"claim": "The authors do not impose Donsker conditions, raising concern about attaining root-n convergence of the proposed semiparametric estimator.", "claim_type": "methodology", "paper_id": "MqEQbvPvkE", "paper_title": "Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "kfNah4HeNr", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Regarding your question about Donsker classes, notice that we impose conditions on the Rademacher complexity and boundedness of the function classes in T2. These conditions suffice for a uniform law of large numbers, ensuring convergence. Note that our regularity assumptions in terms of Rademacher complexity are based on the targeted regularization literature we build upon, specifically, Nie et al. (ICLR 2021), who also do not use Donsker classes. Assumptions on Donsker classes are stronger; they ensure a limiting distribution and are required to prove asymptotic normality. As the reviewer pointed out, relying on weaker conditions strengthens the approach, considering our work is an application paper and asymptotic normality has yet to be established in the theory of targeted regularization that our paper builds upon.", "b3_evidence": "1) \"Given standard regularity conditions, these guarantees imply that the SRF is consistently estimated when either the outcome model or the density-ratio model for the exposure shift is correctly specified, and achieves the best possible efficiency rate when both models are correctly specified.\" 2) \"As we have suggested earlier, an estimator of ψ can be derived from estimators of the outcome and density ratio functions. Using TR, we will obtain an estimator ˆψ_tr with the guarantees that ∥ˆψ_tr - ψ∥_2 converges in probability at an 'efficient' rate according to the prevailing semiparametric efficiency theory surrounding robust causal effect estimation (Kennedy, 2022).\"", "b2_justification": "The authors acknowledge they do not impose Donsker conditions, state they instead impose Rademacher-complexity and boundedness assumptions that yield a uniform law of large numbers (but not asymptotic normality), and explicitly note that Donsker-type assumptions are stronger and required to prove root-n asymptotic normality—thus agreeing with the reviewer's concern.", "b3_justification": "Nowhere in the provided paper text do the authors state or impose Donsker (empirical process) conditions; they assert efficiency under \"standard regularity conditions\" and claim an estimator attains an 'efficient' rate, but do not list the empirical-process-type assumptions (e.g., Donsker) that are commonly required to guarantee root-n asymptotic linearity. Thus the reviewer's factual claim that Donsker conditions are not imposed is supported, and the concern about root-n convergence is reasonable given the lack of such stated conditions."}
{"claim": "It is unclear whether the paper's shift-response function is equivalent to the standard average treatment effect; the manuscript does not clarify this relationship.", "claim_type": "methodology", "paper_id": "MqEQbvPvkE", "paper_title": "Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "kfNah4HeNr", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"To clarify, we are not estimating a propensity score as in traditional treatment effect estimation... The SRF framework requires estimating the conditional density ratio between two generalized propensity scores (Diaz & Van der Laan, 2012; Diaz et al., 2021).\"; \"SRFs are different from traditional treatment effects, comprising the average treatment effect (ATE) for binary treatment and the exposure-response function (ERF) for continuous treatments, as explained in Section 2 and Appendix C.\"; \"The revision has improved and expanded Section 2, paragraph 3, to improve clarity.\"", "b3_evidence": "“This estimand cannot be expressed in terms of traditional causal effects such as the average treatment effect (ATE) or an exposure-response function (ERF) (Muñoz & Van Der Laan, 2012).”\n\n“Mathematically, the ERF ξ can be written as the mapping ξ(a) = E[µ(X,A) | A = a]. One can consider ERFs as a limiting case of SRFs when ˜p is a point mass distribution centered at a fixed treatment value assigned equally to all units.”", "b2_justification": "The authors explicitly state the shift-response (SRF) is not equivalent to standard ATE/ERF and clarify the relationship (including that the shift is a stochastic intervention marginally). They also note they revised Section 2 to improve clarity, thereby refuting the implication of equivalence while addressing the clarity concern.", "b3_justification": "The paper explicitly states that the SRF is not equivalent to standard causal effects and clarifies its relation to other estimands (ATE and ERF), so the reviewer's claim that the manuscript does not clarify the relationship is contradicted by the text."}
{"claim": "MGDL exhibits loss spikes during training, indicating potential instability in the method.", "claim_type": "experimental", "paper_id": "IoRT7EhFap", "paper_title": "Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "3b0MU64PcM", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"This result indicates that MGDL outperforms SGDL in terms of  PSNR value. Notably, MGDL demonstrates the ability to learn high-frequency details more effectively than SGDL.\"", "b3_evidence": "1) \"Our study reveals that MGDL excels at representing functions containing high-frequency information.\" (Abstract)\n2) \"When D is relatively small, for example, D < 5, we call N_D an SNN. It is well-recognized that training an SNN is notably easier than training a DNN.\" (Section 2: Proposed Approach and Multi-Grade Learning Model)", "b2_justification": "The authors provide additional numerical experiments showing improved performance (PSNR) and report training times, but they do not mention, show, or discuss training loss curves or the alleged loss spikes/instability—so the specific claim about loss spikes is not addressed.", "b3_justification": "The provided paper content does not report or discuss training loss spikes or any instability of MGDL. The paper describes MGDL's training procedure and claims empirical efficacy (Abstract, Introduction, Section 2) but contains no statements, training curves, or analysis mentioning loss spikes or instability."}
{"claim": "The authors did not clearly address the performance and stability concerns, nor provide additional numerical experiments to alleviate these doubts.", "claim_type": "experimental", "paper_id": "IoRT7EhFap", "paper_title": "Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "3b0MU64PcM", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We conducted two more numerical experiments.\" \"The PSNR value for the image generated by MGDL and SGDL is 24.07 db and 22.41 db, respectively.  This result indicates that MGDL outperforms SGDL in terms of  PSNR value. Notably, MGDL demonstrates the ability to learn high-frequency details more effectively than SGDL.\" \"The total training time for MGDL was 3109 seconds, with grade 1 taking 1310 seconds, grade 2 taking 906 seconds, and grade 3 taking 893 seconds. While in the same setting, the training time for SGDL is 3298 seconds.\"", "b3_evidence": "\"We apply MGDL to synthetic, manifold, colored images, and MNIST datasets, all characterized by presence of high-frequency features. Our study reveals that MGDL excels at representing functions containing high-frequency information.\" (Abstract)\n\n\"We demonstrate the efficacy of the proposed approach in four experiments with one-dimensional synthetic data, two-dimensional manifold data, two-dimensional colored images, and very high-dimensional modified National Institute of Standards and Technology (MNIST) data.\" (Introduction)\n\n\"Contributions of this paper include: (a) ... (b) ... (c) We successfully apply the proposed approach to synthetic data in 1 and 2 dimensions and real data in 2 and 784 dimensions, showing that it can effectively address the spectral bias issue.\" (Contributions)", "b2_justification": "The authors provided additional numerical experiments and quantitative results showing improved performance (PSNR) and reported training times and a computational-cost explanation, which address the reviewer's request for more experiments and performance evidence. They do not, however, explicitly address \"stability\" (e.g., variance, convergence behavior, or robustness metrics), so the concern is only partially resolved.", "b3_justification": "The paper does include multiple numerical experiments (1D, 2D manifold, colored images, and MNIST) demonstrating efficacy, so the reviewer's claim that no additional numerical experiments were provided is contradicted. However, the paper does not present an explicit analysis or discussion of stability (e.g., convergence, robustness, sensitivity, or runtime) or dedicated performance/stability experiments, so the portion of the claim about not clearly addressing performance/stability concerns is accurate."}
{"claim": "The paper's overall novelty is very limited because it largely reuses existing ideas from graph neural networks and prior graph transformer work.", "claim_type": "novelty", "paper_id": "ffNrpcBpi6", "paper_title": "Graph Convolutions Enrich the Self-Attention in Transformers!", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BnHhKrAJht", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"From the perspective of using learnable coefficients, this approach is similar to polynomial GNNs, such as GPR-GNN [1] and BernNet [3].\"; \"Our goal is not to create theoretically exact high-pass or low-pass filters. Instead, we aim to learn optimal graph filters based on coefficients, improving the original self-attention.\"; \"GFSA can be implemented with linear complexity and still provide performance improvements. This addresses the concern about the computational cost and shows that the gain-complexity trade-off can be more favorable than initially presented.\"", "b3_evidence": ["In general, a graph filter on a graph G is represented by a polynomial expression based on its adjacency or Laplacian matrix - in this regard, the existing self-attention mechanism can be understood as the simplest graph filter with ¯A only, where ¯A ∈ [0,1]^{n×n} means a learned attention matrix and n is the number of input tokens.", "In comparison with them, our proposed graph filter is distinctive in the following aspects: i) our proposed filter is more effective and shows better performance with comparable computational overheads, ii) our proposed filter is well-aligned with recent advancements in the GCN community - in other words, some graph filters used by recent advanced GCN methods are special cases of our proposed graph filter, which is not the case for prior works, and iii) other methods were typically studied for certain domains only whereas we test our method in 6 domains - for instance, DiversePatch [25] works only for Vision Transformers (ViTs).", "We propose a graph filter-based self-attention (GFSA) mechanism, integrating an identity term and two polynomial terms for general yet effective than the simple self-attention mechanism (Section 3)."], "b2_justification": "The authors acknowledge similarity to prior polynomial GNN/filter-learning work but argue their contribution is novel in applying learnable graph filters to self-attention (GFSA), extending theoretical analysis, and showing empirical/efficiency benefits. Thus they partially accept the reviewer’s point about reused ideas while defending novel aspects.", "b3_justification": "The paper explicitly builds on prior GSP/GNN ideas (it interprets self-attention as a graph filter and positions its filter as an extension of existing matrix-polynomial filters), which supports the reviewer's point that existing ideas are reused. However, the authors also propose a concrete new GFSA design (identity + two polynomial terms with a Taylor approximation), provide theoretical analysis (Theorem 3.1), and emphasize distinctiveness and broad empirical evaluation across multiple domains, which contradicts the claim that novelty is 'very limited.' Thus the reviewer's statement is only partially accurate."}
{"claim": "Adaptive high-pass and low-pass filters have already been well studied in the graph neural network literature and used to address oversmoothing.", "claim_type": "novelty", "paper_id": "ffNrpcBpi6", "paper_title": "Graph Convolutions Enrich the Self-Attention in Transformers!", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BnHhKrAJht", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"From the perspective of using learnable coefficients, this approach is similar to polynomial GNNs, such as GPR-GNN [1] and BernNet [3]. They can learn arbitrary filters instead of fixed filters by learning $w_k$.\" \n\n\"Our goal is not to create theoretically exact high-pass or low-pass filters. Instead, we aim to learn optimal graph filters based on coefficients, improving the original self-attention.\"", "b3_evidence": "1) \"There exist a couple of prior works to enrich the self-attention mechanism with high frequency information [80, 4].\" 2) \"our proposed filter is well-aligned with recent advancements in the GCN community - in other words, some graph filters used by recent advanced GCN methods are special cases of our proposed graph filter...\" 3) \"There are studies on utilizing high frequency information via frequency domain analyses [80, 4], but they are not designed on top of graph filtering perspectives.\"", "b2_justification": "The authors acknowledge prior related work on learnable graph filters (polynomial GNNs) and cite GPR-GNN and BernNet, but argue their contribution is distinct—applying adaptive filters to self-attention/Transformers, providing theory, visualizations, and empirical evidence rather than constructing exact classical low/high-pass filters.", "b3_justification": "The paper cites prior work that uses high-frequency information and discusses graph filters in GCNs and oversmoothing (supporting that related filters have been studied). However, it does not explicitly state that adaptive high-pass and low-pass filters have been \"well studied\" in the GNN literature nor that such adaptive filters are already widely used specifically to address oversmoothing; it only notes some prior studies and that some GCN filters are special cases of their proposal."}
{"claim": "Treating the attention module as a graph filter has already been proposed in many prior Graph Transformer models.", "claim_type": "novelty", "paper_id": "ffNrpcBpi6", "paper_title": "Graph Convolutions Enrich the Self-Attention in Transformers!", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "BnHhKrAJht", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"From the perspective of using learnable coefficients, this approach is similar to polynomial GNNs, such as GPR-GNN [1] and BernNet [3]. They can learn arbitrary filters instead of fixed filters by learning $w_k$.\" \n\n\"Our goal is not to create theoretically exact high-pass or low-pass filters. Instead, we aim to learn optimal graph filters based on coefficients, improving the original self-attention.\"", "b3_evidence": "\"Shi et al. [71] revealed an analogy between the self-attention and the residual graph convolutional network (GCN)...\"; \"The self-attention matrix used in Transformers has the form of symmetrically normalized adjacency matrix where each token become a node [71, 28] ... In other words, ¯A = D^{-1}A\"; \"There exist a couple of prior works to enrich the self-attention mechanism with high frequency information [80, 4].\"", "b2_justification": "The authors acknowledge similarity to prior graph-filter approaches (e.g., polynomial GNNs that learn filter coefficients) and emphasize that coefficients determine filter behavior, but they do not explicitly concede the reviewer's broader claim that many prior Graph Transformer models treated attention as a graph filter nor directly enumerate or compare to those Graph Transformer papers—thus only a partial acknowledgment.", "b3_justification": "The paper acknowledges prior work linking self-attention to graph adjacency/graph convolution (citing Shi et al. [71] and others) and notes prior methods to enrich attention with high-frequency information, but the authors still frame their specific graph-filter formulation and its novelty as a contribution. Thus the claim that this perspective has been proposed before is supported in part, but the paper also claims novelty in their particular graph-filter design."}
{"claim": "Figures 6 and 7 are squeezed and Figure 7 slightly occludes the caption of Figure 6, impairing visualization.", "claim_type": "presentation", "paper_id": "VzPGV19Bnp", "paper_title": "Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "DR2C8HbrUg", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "“We have updated some new results in the Appendix, including: 1. A quantitative comparison between baseline sampling and the proposed Fusion Sampling... 2. We provide comparison of using different $m$... 3. We provide qualitative results of using different $\\gamma$... 4. We also provide qualitative results...”", "b3_evidence": "\"Figure 1: Generated examples from the proposed framework. Given only single testing image from arbitrary downstream domain, ProFusion can perform customized generation in 5 to 25 seconds.\"; \"Figure 2: Illustration of the proposed framework. A PromptNet will be trained to output an embedding S ∗ based on input image. Then Fusion Sampling performs customized generation based on S ∗ and arbitrary text input.\"; \"Figure 3: The performance of customized generation is impacted by the level of regularization.\"", "b2_justification": "The authors' response discusses additional experiments, appendix updates, and technical clarifications, but does not address the reviewer's specific concern about figure layout (Figures 6 and 7 being squeezed/occluding captions).", "b3_justification": "The provided paper excerpt does not contain Figures 6 or 7, so the claim about their layout and occlusion cannot be verified from the supplied content."}
{"claim": "The paper lacks theoretical guarantees for the proposed CS-Fluctuation metric and its use in preventing overfitting.", "claim_type": "methodology", "paper_id": "TzWLecXH6I", "paper_title": "Towards Personalized AI: Early-stopping Low-Rank Adaptation of Foundation Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "QrZww2Zdjd", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We recognize that the current approach may lack a complete theoretical framework.\" \"Although our method may lack the traditional full theoretical framework, it has demonstrated significant results in a series of experiments.\"", "b3_evidence": "Abstract: \"Empirically, we leverage various types of personalized data to conduct customization experiments on both vision and language foundation models, which corroborates the effectiveness of CS-Fluctuation in early stopping the LoRA fine-tuning.\"; Section 3.2: \"We leverage CS-Fluctuation to early stop the fine-tuning process to return a well performing LoRA model. Over the fine-tuning iterations, we empirically observe that the CS-Fluctuations behave like transverse waves...\"", "b2_justification": "Authors explicitly acknowledge the lack of a complete/theoretical framework for CS-Fluctuation and offer empirical results instead, admitting the need for further normalization but providing no theoretical guarantees.", "b3_justification": "The paper describes CS-Fluctuation empirically and reports experiments that corroborate its effectiveness, but it contains no theoretical analysis, theorems, proofs, or formal guarantees about the metric or its ability to prevent overfitting."}
{"claim": "Figure 1 does not clarify the relationship between 'Epoch' and 'training steps', leaving the mapping and interpretation ambiguous.", "claim_type": "presentation", "paper_id": "TzWLecXH6I", "paper_title": "Towards Personalized AI: Early-stopping Low-Rank Adaptation of Foundation Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "QrZww2Zdjd", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Relationship Between Epoch and Training Steps:\nEpoch and training steps actually correspond to each other and represent different ways of controlling training process. The formula is: Training steps = Repeat * Train set size * Epochs / Batch Size. In Figure 1, the better-performing LoRA models are the results of Epoch 2 and Epoch 3. ... Our approach is based on training steps to decide on early stopping and returns the LoRA model of the epoch in which the selected training step is located.", "b3_evidence": "Figure 1 caption: 'The grey dashed line is the turning point that is located by our proposed algorithm, e.g., the Epoch 2 in red in Fig.1(a) is where the turning point is located.'; Section 3.2: 'where j is the index of iteration steps in fine-tuning process, and M is the size of moving window.'; Section 3.2: 'Note that in order to calculate the CS of the iteration j , we need to calculate M more iterations of fine-tuning.'", "b2_justification": "The authors explicitly explain the correspondence between epochs and training steps, provide a formula linking them, state which epochs correspond to the results in Figure 1, and describe how early stopping maps a selected training step back to an epoch.", "b3_justification": "The paper's Figure 1 refers to an 'Epoch' (e.g., 'Epoch 2') but the text defines CS measurements in terms of iteration/index j and batch-wise moving windows without specifying how iterations map to epochs or how many training steps constitute an epoch. Thus the figure does not clarify the relationship between 'Epoch' and 'training steps', making the mapping ambiguous."}
{"claim": "Figure 1 appears to suggest that the first two epochs are sufficient for fine-tuning, but the paper does not discuss or validate early stopping.", "claim_type": "experimental", "paper_id": "TzWLecXH6I", "paper_title": "Towards Personalized AI: Early-stopping Low-Rank Adaptation of Foundation Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "QrZww2Zdjd", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "In Figure 1, the better-performing LoRA models are the results of Epoch 2 and Epoch 3. ... Our approach is based on training steps to decide on early stopping and returns the LoRA model of the epoch in which the selected training step is located. ... Therefore, the \"overfitted LoRA\" results we show are exactly what you would expect after several valleys.", "b3_evidence": "Abstract: \"we introduce a new monitoring metric (CS-Fluctuation) to facilitate early stopping the fine-tuning process.\" | Figure 1 caption: \"The grey dashed line is the turning point that is located by our proposed algorithm, e.g., the Epoch 2 in red in Fig.1(a) is where the turning point is located.\" | Section 3.2: \"In this section, we propose a CS-Fluctuation metric to monitor the LoRA fine-tuning process. Once CS-Fluctuation becomes steady and small, we early stop the fine-tuning process to avoid overfitting.\"", "b2_justification": "The authors explicitly describe and justify their early-stopping strategy and link Figure 1 results to specific epochs (Epoch 2 and 3), thereby addressing and refuting the claim that the paper does not discuss or validate early stopping.", "b3_justification": "The paper explicitly proposes and discusses early stopping via the CS-Fluctuation metric, describes an algorithm for early stopping (Algorithm 1), and reports empirical validation that CS-Fluctuation identifies turning points to early-stop fine-tuning. Figure 1 does show an example turning point at 'Epoch 2', but contrary to the claim the paper does discuss and validate early stopping."}
{"claim": "Section 3 Lines 87-103 introduce background on normalization but fail to signal that topic in the opening sentence.", "claim_type": "presentation", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "The reviewer raises 2 additional concrete examples of what they perceive as poor writing: the openings of lines 87-103 and lines 104-117. We thank the reviewer for these examples but politely disagree and view these as subjective stylistic preferences instead of substantial criticisms that merit the review’s score. ... the claimed criticisms to writing quality need to be backed up with more evidence to be warranted.", "b3_evidence": "“Several works have highlighted the architectural choice of Layer Normalisation (LN) [44] as a cause of OFE [1, 7, 15]. LN belongs to a family of normalisation (Norm) layers commonly used in sequence models, which normalise a representation vector x ∈ R d across the width dimension independently”", "b2_justification": "The authors explicitly disagree with the reviewer about the opening sentences, treating the examples as subjective stylistic preferences and not substantive writing faults; they do not acknowledge the specific claim that the normalization topic is not signaled and refuse the critique.", "b3_justification": "Section 3's opening sentence explicitly introduces normalization: it names Layer Normalisation and states LN belongs to the family of normalisation layers used in sequence models, so the topic is clearly signalled."}
{"claim": "Lines 104-177 begin abruptly with 'In Figure 2' without a transition, leaving the reader unclear about the figure's context.", "claim_type": "presentation", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We have already significantly improved the manuscript, particularly with regards to a more extensive description of the OP block. The reviewer raises 2 additional concrete examples of what they perceive as poor writing: the openings of lines 87-103 and lines 104-117. We thank the reviewer for these examples but politely disagree and view these as subjective stylistic preferences instead of substantial criticisms that merit the review’s score.\"", "b3_evidence": "We compare these different Norms in Fig 2, where we see that independent of Norm choice, all Pre-Norm transformers incur OFE: the peak kurtosis during training across Norms is over 4 orders of magnitude larger than initialisation.\n\nFigure 2: Kurtosis becomes large (i.e. OFE) when training with different Norms at 130M scale. We plot the residual stream entering\n\n...the 2nd of 6 blocks. Other layers in Fig 14. Having established that removing trainable weights in Norms still results in OFE, the next question we ask is: how does removing standard Norms entirely influence Outlier Feature emergence ?", "b2_justification": "The authors explicitly disagree with the reviewer’s comment about those line openings, calling the examples subjective stylistic preferences and not substantive writing problems; they state they have improved the manuscript but refuse the specific criticism.", "b3_justification": "The paper introduces Figure 2 with a preceding sentence that explicitly references and contextualises the figure, and the figure caption further explains what is being plotted. The surrounding text continues after the figure, showing the figure is integrated into the discussion rather than presented abruptly or without transition."}
{"claim": "The paper does not prominently present substantial results supporting the proposed architecture, similar to how Tables 2 and 3 are presented in Reference [14].", "claim_type": "experimental", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "We have since run the experiments, reported in Table 1* in the attached one-page pdf (see details and discussion in the global repsonse). In summary, the proposed modifications do enhance low precision training, which nicely correlates with the observation of less OFs. ... In particular, with regards to the four axes mentioned in the initial review, we believe that (a), (b) and (c) are resolved in the original rebuttal and references to the appendix. Finally, see above for the quantization experiment, requested in (d). ... we politely disagree that there is not enough experimental evidence for the architectural modification. ... We have demonstrated the efficacy of the OP block at 7B scale in Figures 1* and 2* of the additional rebuttal pdf, and would appreciate it if the Reviewer acknowledges this.", "b3_evidence": "Abstract: \"As highlights, we introduce a novel unnormalised transformer block, the Outlier Protected block, and present a previously unknown benefit of non-diagonal preconditioning optimisers, finding both approaches to significantly reduce OFs and improve quantisation without compromising convergence speed, at scales of up to 7B parameters. Notably, our combination of OP block and non-diagonal preconditioner (SOAP) achieves 14.87 weight-and-activation int8 perplexity (from 14.71 in standard precision), compared to 63.4 int8 perplexity (from 16.00) with a default OF-prone combination of Pre-Norm model and Adam, when quantising OPT-125m models post-training.\"  Also: \"We proceed to show that removing normalisation through our Outlier Protected transformer block minimises OFs, without loss of convergence speed or training stability compared to standard transformer blocks.\"", "b2_justification": "The authors explicitly disagree with the reviewer's claim and report having added experiments and results (quantization experiments, Table 1*, and 7B-scale figures) to support the architectural contribution.", "b3_justification": "The paper does present prominent, quantitative results supporting the proposed Outlier Protected (OP) block and its combination with a non-diagonal preconditioner (SOAP). The Abstract reports concrete int8 quantisation perplexity numbers for OP/SOAP versus a baseline, Sec. 3 claims the OP block minimises OFs without loss of convergence speed, and Sec. 6 is cited as demonstrating performance up to 7B parameters—indicating substantive empirical support for the proposed architecture."}
{"claim": "The claimed relationship between Signal Propagation and Outlier Features is unsurprising because both Kurtosis and the Gram matrix are functions of the same variable X.", "claim_type": "novelty", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The reviewer has raised the “insignificance/noteworthiness” of the OF and Signal Prop link as a new concern in their most recent response. The original review (weakness 3) criticised the “surprisingness/novelty” of the finding, which we addressed in our rebuttal.\n\nThe significance/noteworthiness of the relation between OF and Signal Prop is that it: (i) establishes a connection between two previously unconnected sub-branches of the literature... and (ii) helps us motivate why choices from the Signal Prop literature that improve Signal Prop ... also help to reduce OFs, which we provide empirical evidence for in Figures 5 and 21.\"", "b3_evidence": "\"Consider an activation matrix X ∈ R n × d obtained from some neural network layer...\" (Sec. 2)\n\n\"Let Kurt ( X ) be the ratio of the fourth moment m4 to the squared second moment m2 over the empirical distribution of s...\" (Sec. 2)\n\n\"Variants of Kurt ( X ) have previously been proposed..., but our formulation in Eq (1) aggregates activations over inputs first, which allows us to link OFs and signal propagation in Sec 4.\" (Sec. 2)\n\n\"In Sec 4, we consolidate our findings by identifying signal propagation as an important object that can predict OFs during training, and that choices that improve signal propagation during training also minimise OFE.\" (Introduction / Contributions)", "b2_justification": "The authors rebut the claim's significance/novelty but do not directly address the specific critique that the relationship is unsurprising because Kurtosis and the Gram matrix are both functions of the same variable X. They defend novelty and provide empirical motivations, but never mention Kurtosis, Gram matrix, or the dependence-on-X argument.", "b3_justification": "The paper does link kurtosis (Kurt(X)) to the activation matrix X and states that this formulation allows linking OFs and signal propagation (Sec. 2 and Sec. 4). However the paper excerpt does not mention the Gram matrix or claim that the Gram matrix is used to explain the Signal Propagation–OF relationship. Thus the reviewer’s rationale (that the relationship is unsurprising because both Kurtosis and the Gram matrix are functions of the same X) is not supported or addressed by the paper as given."}
{"claim": "The authors responded with subjective opposing comments rather than directly engaging the core issue about the relationship between OF and Signal Propagation.", "claim_type": "subjective", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "The significance/noteworthiness of the relation between OF and Signal Prop is that it: (i) establishes a connection between two previously unconnected sub-branches of the literature which allows ideas from both to help drive progress in the other e.g. the identification that normalisation layers make Signal Prop worse during training (Figures 5 and 6), and (ii) helps us motivate why choices from the Signal Prop literature that improve Signal Prop (like downweighted residuals [22, 25] or shaped activations [63, 24, 23]) also help to reduce OFs, which we provide empirical evidence for in Figures 5 and 21.", "b3_evidence": "\"In Sec 4, we consolidate our findings by identifying signal propagation as an important object that can predict OFs during training, and that choices that improve signal propagation during training also minimise OFE.\"", "b2_justification": "The authors directly address and defend the significance of the OF–Signal Propagation connection, providing specific motivations and empirical references rather than only offering subjective opposition to the reviewer's point.", "b3_justification": "The paper explicitly states that it studies and links signal propagation to Outlier Feature Emergence and devotes a section to consolidating findings around signal propagation predicting OFs; it therefore directly engages the core issue rather than only offering subjective opposing comments."}
{"claim": "The paper lacks rigorous analytical approaches, such as neural tangent kernel or training-dynamics analyses, to uncover underlying causes of Outlier Features.", "claim_type": "methodology", "paper_id": "npJQ6qS4bg", "paper_title": "Understanding and Minimising Outlier Features in Transformer Training", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "YeBeK8zEL0", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "As we openly state in our limitations section, there are a lot of interesting future directions for mathematically rigorous studies that would build on the results of our paper, but are outside the scope of our work. ... The reviewer’s suggestion of the “NTK” or “training dynamics” as theoretical analysis techniques are insufficient for OFE because the NTK limit is incompatible with feature learning, which is necessary for OFs, as we state in lines 254-256 of the submission. We are unsure what is meant by “training dynamics” as an analysis technique here.", "b3_evidence": "1) \"we consolidate our findings by identifying signal propagation as an important object that can predict OFs during training\"; 2) \"Though progress has been made [1, 13, 14, 10, 15], the mechanisms behind OFE remain largely unknown.\"", "b2_justification": "Authors acknowledge the lack of mathematically rigorous analyses as future work (i.e., out of scope) while also arguing that suggested techniques like NTK are inappropriate for studying Outlier Features, so they neither provide the requested analyses nor fully reject the reviewer's concern.", "b3_justification": "The paper provides some analytical discussion of training dynamics (notably identifying signal propagation as an object that can predict OFs in Sec. 4) but does not present more formal analytical frameworks like Neural Tangent Kernel (NTK) analyses or detailed training-dynamics derivations. Thus the reviewer’s claim is partially correct: rigorous NTK-style analysis is absent, but the paper does include some training-dynamics-related analysis (signal propagation)."}
{"claim": "Scaling the proposed method to Objaverse-scale datasets may be computationally infeasible or practically meaningless.", "claim_type": "subjective", "paper_id": "6zROYoHlcp", "paper_title": "DiffGS: Functional Gaussian Splatting Diffusion", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "jMbtMURYue", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We estimate that training DiffGS on the large 3D dataset Objaverse, which contains 1 M shapes, will take approximately 5-7 days to converge under 64 A100-80G GPUs. I believe the time is acceptable since we only need to train DiffGS for once.\" \"DiffGS takes only less than 10 seconds for inference on a single 3090 GPU, which is several orders of magnitude faster than SDS-based methods.\"", "b3_evidence": "Abstract: \"DiffGS is a powerful and efficient 3D generative model which is capable of generating Gaussian primitives at arbitrary numbers for high-fidelity rendering with rasterization.\" Introduction (summary of contributions): \"4) Scalability, we scalably generate Gaussian primitives at arbitrary numbers.\" Section 3 (Method): \"We introduce DiffGS, a novel diffusion-based generative model for general 3D Gaussian Splatting, which is capable of efficiently generating high-quality Gaussian primitives at arbitrary numbers.\" Introduction (experiments): \"We conduct comprehensive experiments on both synthetic ShapeNet dataset and real-world DeepFashion3D dataset...\"", "b2_justification": "The authors explicitly disagree with the reviewer's concern by arguing that training at Objaverse scale is feasible and practically worthwhile, providing concrete time estimates and efficiency comparisons to support scalability.", "b3_justification": "The paper explicitly claims DiffGS is efficient and scalable and can generate Gaussian primitives at arbitrary numbers. It presents scalability and efficiency as core advantages and evaluates on ShapeNet and DeepFashion3D, and does not state or provide evidence that scaling to very large datasets (e.g., Objaverse-scale) is infeasible or meaningless."}
{"claim": "The method requires an efficient text-to-image diffusion model with a small number of inference steps, which may hinder applying the method to other base models.", "claim_type": "methodology", "paper_id": "E6ZodZu0HQ", "paper_title": "PuLID: Pure and Lightning ID Customization via Contrastive Alignment", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "hG6rPjvWXW", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We highly agree with your suggestion of open-sourcing... We plan to adapt PuLID to FLUX.1 in the coming months and make it open-source as well.\"", "b3_evidence": "Introduction: \"Specifically, we introduce a Lightning T2I branch alongside the standard diffusion-denoising training branch. Leveraging recent fast sampling methods [26, 38, 23], the lighting T2I branch can generate high-quality images from pure noise with a limited and manageable number of steps.\"; Related Work (Fast Sampling): \"The Lightning T2I training branch we introduce leverages the SDXL-Lightning [23] acceleration technology, thus enabling us to generate high-quality images from pure noise in just 4 steps.\"; Methods (3.2 Basic Settings): \"We build our model based on the pre-trained SDXL [30], which is a SOTA T2I latent diffusion model.\"", "b2_justification": "The authors do not directly address the requirement for a small number of inference steps or explicitly discuss compatibility limitations, but they indicate intent to adapt PuLID to another base model (FLUX.1) and to open-source the code, which partially responds to concerns about applicability to other models.", "b3_justification": "The paper explicitly requires a Lightning T2I branch that leverages fast sampling (SDXL-Lightning) to generate high-quality images from pure noise in a few steps (4 steps), so the first part of the claim is supported (see Introduction, Related Work, Methods). However, the paper does not state or discuss that this requirement will hinder applying the method to other base models — that limitation is not asserted or analyzed in the paper, so the second part is not supported by the paper."}
{"claim": "The paper does not use advanced, recent graph-to-text generation techniques such as graph transformers.", "claim_type": "methodology", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In this paper, we specifically studied the class of fixed text encoding functions...\"; \"For this particular reference [1], we searched for an existing model to try to use it “out of the box”, but could not find any available. Unfortunately we do not have time in the review cycle to appropriately train this as a baseline and collect its results (as running this experiment takes significant time already).\"; \"Our results show that your intuition is exactly right (fixed encodings have limitations), and investigating this area is very interesting follow up work!\"", "b3_evidence": "However, these methods require access to the internals of the model (its weights or gradients), which can limit their applicability in many settings. In this work, we are instead interested in the case where f ( . ) and its parameters are fixed, and the system is available only for use in a black box setup where the LLM only consumes and produces text ( i.e. , the LLM f : W ↦→ W ).", "b2_justification": "Authors acknowledge they did not use graph-transformer style graph-to-text models, explain they focused on fixed text encodings, and state they could not find an existing model to run and lacked time to train one, treating it as future work.", "b3_justification": "The paper specifically studies representing graphs as text for black-box LLM consumption and explicitly states it does not adopt methods that require modifying model internals (which would include graph-transformer style approaches). The experiments and methods focus on text encodings and prompting heuristics rather than advanced graph-to-text models."}
{"claim": "Using similar encoding templates primarily measures LLMs' ability to interpret names rather than their ability to understand underlying relations or exploit graph neighborhoods.", "claim_type": "experimental", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Our results show that your intuition is exactly right (fixed encodings have limitations), and investigating this area is very interesting follow up work!\" ... \"The results of this experiment also confirm the major findings in the paper. First, the LLM didn't do well on the node classification task either and only just beat the majority baseline by a small amount (51.2% to 58.4%). Second, the choice of the graph encoder has a significant impact on the LLM reasoning. As this task requires more reasoning (compared to some of the tasks that require more of memorization), some of the encoders with more textual information (e.g., friendship) proved to be more powerful.\" ... \"We posit that the success of incident encoding can be attributed to two key factors. Firstly, it leverages integer node encoding (e.g., *node 0* or *node 1*), as we previously emphasized the advantages of this approach in Section 3.1.1. Secondly, incident edge encoding effectively captures the one-hop neighbourhood around a graph, outperforming methods that simply list edges in a random order.\"", "b3_evidence": "“Integer node encoding improves arithmetic performance. Another finding here is that integer encoding of nodes ( e.g. , node 0 ) can improve the performance of LLMs on integer output tasks, such” ; “Graph encoding function has significant impact on LLM reasoning. ... For instance, for finding connected nodes to a node in a graph, adjacency achieves 19 . 8% accuracy and incident achieves 53 . 8% accuracy. For both node degree and connected nodes, incident encoding outperforms the rest of the encoding functions. This is likely because the incident encoding encodes the graph structure in a way that makes the relevant information more accessible, i.e. , in close proximity, to the LLM.”", "b2_justification": "The authors acknowledge limitations of fixed/similar encodings and show that encoder choice strongly affects performance (supporting the reviewer's concern), but they also present experiments and argue that certain encodings (e.g., incident/integer encodings or more textual encoders) can capture neighborhood or relational information—indicating the issue is not solely name-interpretation and that encoding design matters.", "b3_justification": "The paper shows that the choice of encoding (including node labels) strongly affects LLM performance — e.g., integer node encoding improves arithmetic-style outputs — which supports the reviewer's point that label interpretation matters. However, the paper also attributes performance differences to how encodings present relational structure (e.g., incident encoding puts relevant information in close proximity and improves connected-node accuracy), indicating encodings also measure ability to access/exploit neighborhood/relations. Thus the claim is only partially aligned with the paper."}
{"claim": "The encoding functions lack diversity and fail to evaluate models' ability to exploit neighborhood information in graphs.", "claim_type": "methodology", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "“This exercise aimed to assess the LLM's ability to exploit the homophily in a given graph.”; “While we initially intended to explore fixed text encoding functions, our goal was to introduce diversity in node and edge encodings. This involved employing a range of node encodings (integers, alphabet letters, popular character names) and edge encodings (friendship, co-authorship, parentheses). By combining these, we achieved a diverse set of graph encoding functions (see Appendix A.1 for more details).”; “Secondly, incident edge encoding effectively captures the one-hop neighbourhood around a graph, outperforming methods that simply list edges in a random order.”", "b3_evidence": "1) \"R3 : Incident graph encoding outperforms the rest in most of the setups ( § 3.1).\"  2) \"Graph encoding function has significant impact on LLM reasoning. As the results indicate, the choice of the graph encoding function has a significant impact on the performance of LLMs on graph-related tasks. ... For instance, for finding connected nodes to a node in a graph, adjacency achieves 19 . 8% accuracy and incident achieves 53 . 8% accuracy.\"", "b2_justification": "The authors explicitly counter the reviewer's claim by reporting a new node-classification (homophily) experiment and by describing a variety of node and edge encodings used in the paper; they further argue that certain encoders (e.g., incident) capture one-hop neighborhood information effectively. They do acknowledge fixed-encoding limitations as future work, but overall provide experimental evidence and methodological detail that contradict the claim.", "b3_justification": "The paper explicitly studies multiple distinct graph encoding functions (e.g., adjacency, incident, integer node encoding) and evaluates tasks that require neighborhood information (connected nodes, node degree). It reports large performance differences across encodings—showing that certain encodings (incident) better expose neighborhood information and improve LLM performance—so the claim that encodings lack diversity and fail to evaluate neighborhood exploitation is contradicted."}
{"claim": "Most proposed benchmark tasks (except edge existence) do not require reasoning.", "claim_type": "methodology", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"This task requires more reasoning (compared to some of the tasks that require more of memorization)\" \n\"The cycle check task needs to do multi-hop reasoning over the structure of the graph in order to determine the existence of a cycle.\" \n\"Upon your suggestion on adding more complex tasks, we conducted experiments on a new task for path existence which requires multi-hop reasoning.\"", "b3_evidence": "1) \"Simple prompts are best for simple tasks. We see that ZERO-COT prompting has worse model performance than ZERO-SHOT prompting on basic graph tasks. This is likely because ZERO-SHOT prompting is sufficient for these tasks, which do not require multi-hop reasoning.\" 2) \"In this experiment, we measure the performance of pre-trained LLMs on graph tasks: edge existence, node degree, node count, edge count, connected nodes, and cycle check.\" 3) \"LLMs perform poorly on basic graph tasks. ... This is especially interesting for edge existence and cycle check ... Therefore. LLMs perform worse than the majority baseline.\"", "b2_justification": "Authors do not fully accept the reviewer's blanket claim; they acknowledge some tasks are more like memorization but add and emphasize tasks that require multi-hop reasoning (node classification, path existence, cycle check), showing they partially rebut the claim while not claiming all original tasks require reasoning.", "b3_justification": "The paper states that the evaluated basic graph tasks do not require multi-hop reasoning (i.e., are 'simple tasks'), which supports the reviewer's general point that most benchmark tasks do not require reasoning. However, the paper does not single out edge existence as the sole exception; edge existence is listed among the basic tasks and is mentioned as a failure case, but the paper does not claim it uniquely requires reasoning. Thus the reviewer's exception for edge existence is not supported by the paper."}
{"claim": "The tasks can be solved by counting, simple arithmetic, or memorizing the graph structure instead of real reasoning.", "claim_type": "methodology", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "“As this task requires more reasoning (compared to some of the tasks that require more of memorization), some of the encoders with more textual information (e.g., friendship) proved to be more powerful.”; “Note that the node degree counting could be viewed as the simplest node regression task.”; “Integer node encoding enhances arithmetic performance for node degree, node count, and edge count tasks.”", "b3_evidence": "1) \"Simple prompts are best for simple tasks. We see that ZERO-COT prompting has worse model performance than ZERO-SHOT prompting on basic graph tasks. This is likely because ZERO-SHOT prompting is sufficient for these tasks, which do not require multi-hop reasoning.\" 2) \"Integer node encoding improves arithmetic performance.\"", "b2_justification": "The authors acknowledge that some tasks involve counting, simple arithmetic, or memorization (and that integer encoding aids arithmetic tasks), but they also distinguish these from harder multi-hop reasoning tasks and present experiments targeted at reasoning, so they do not fully accept the claim as applying to all tasks.", "b3_justification": "The paper explicitly states many evaluated graph tasks are \"basic\" and do not require multi-hop reasoning, and notes integer encoding helps arithmetic-like outputs, implying counting/simple arithmetic can suffice. However, the paper does not claim these tasks are solvable merely by \"memorizing the graph structure,\" nor does it assert that no reasoning is required beyond simple operations—so the reviewer claim overstates what the paper asserts."}
{"claim": "More challenging tasks, such as node classification, are missing from the experiments.", "claim_type": "experimental", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Your suggestion to explore a node classification task proved to be immensely valuable. Inspired by your suggestion, we used our stochastic block model graph generator to create two distinct blocks representing soccer and baseball enthusiasts. We then labeled a subset of nodes and asked the LLM to determine whether an unspecified node belonged to the soccer or baseball group. The results for various encoders were as follows: [table]. The results of this experiment also confirm the major findings in the paper. ... We can add this experiment to the main paper.", "b3_evidence": "In this experiment, we measure the performance of pre-trained LLMs on graph tasks: edge existence , node degree , node count , edge count , connected nodes , and cycle check .", "b2_justification": "The authors implemented a node classification experiment (stochastic block model), reported results for multiple encoders, and stated they can add this experiment to the main paper, directly addressing the reviewer's request.", "b3_justification": "The paper's experiments (GraphQA) evaluate basic graph tasks—edge existence, node degree, node count, edge count, connected nodes, and cycle check—and do not include node classification or other more challenging tasks."}
{"claim": "The distinction between \"question rephrasing\" and \"application rephrasing\" methods in Experiment 2 is unclear.", "claim_type": "methodology", "paper_id": "IuXR1CCrSi", "paper_title": "Talk like a Graph: Encoding Graphs for Large Language Models", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "xykE9kudcU", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "", "b3_evidence": "“we introduce the graph encoding function g ( G ) and question rephrasing function q ( Q ) , where g : G ↦→ W and q : W ↦→ W ...” (Section 2.1). The excerpt contains descriptions of prompting heuristics and Experiment 1, but no Experiment 2 or 'application rephrasing' discussion is present.", "b2_justification": "Error during labeling: Unterminated string starting at: line 1 column 269 (char 268)", "b3_justification": "The provided paper excerpt defines a question rephrasing function q(Q) (Section 2.1) but does not include Experiment 2 or any description of an 'application rephrasing' method. Therefore there is insufficient information in the supplied content to assess whether the distinction in Experiment 2 is unclear."}
{"claim": "The paper values complexity, lexicon size, and NID over actual task performance without adequately justifying that choice when systems differ in task success.", "claim_type": "methodology", "paper_id": "2wlNnIqCb7", "paper_title": "Bridging semantics and pragmatics in information-theoretic emergent communication", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ZUU7oKQGvi", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"High task performance (utility) can be trivially achieved with very non-human-like communication systems.\" | \"We value all metrics for evaluation, including task-performance, and when comparing them with human behavior they all consistently support our conclusions.\" | \"In comparison, our model achieves ~72%, which is well within the reasonable range of human performance.", "b3_evidence": "Abstract: \"we extend a recent information-theoretic framework for emergent communication in artificial agents, which integrates utility maximization, associated with pragmatics, with general communicative constraints...\" Introduction: \"we assess the pragmatic competence (i.e., utility) of the agents as well as the 'human-likeness' of the shared emergent lexicon that they converged on... Given the substantial empirical evidence that human semantic systems are pressured to optimize the IB tradeoff, we predict that a shared human-like lexicon will not emerge when agents are guided solely by utility maximization but rather when they are guided by a non-trivial tradeoff between optimizing utility, informativeness, and complexity.\" Also: \"Interestingly, pressure for communicative informativeness, rather than (non-communicative) task utility, appears as the main driver of emergent communication, but weaker pressures to minimize complexity and maximize utility are still crucial for achieving human-like properties of the lexicon.\"", "b2_justification": "The authors explicitly defend prioritizing lexical/complexity metrics over raw task accuracy, arguing task performance can be trivially maximized by non-human-like systems, providing human-performance bounds and showing their model's accuracy (~72%) lies within that range, and stating they consider all metrics together.", "b3_justification": "The paper explicitly integrates task utility with information-theoretic pressures (complexity/informativeness) and evaluates both pragmatic competence (utility) and lexical properties. It motivates this choice with prior IB theory and empirical work and reports that informativeness drives emergence while utility and complexity remain important. Thus it does not merely value lexicon size/complexity/NID over task performance without justification."}
{"claim": "The paper severely lacks discussion addressing the core methodological flaw of prioritizing human-likeness metrics over task performance differences.", "claim_type": "methodology", "paper_id": "2wlNnIqCb7", "paper_title": "Bridging semantics and pragmatics in information-theoretic emergent communication", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ZUU7oKQGvi", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "High task performance (utility) can be trivially achieved with very non-human-like communication systems. For example, by assigning a unique signal to each object in the dataset, or by using the same signal for entirely unrelated objects that never appear in the same context. Therefore, focusing only on task performance is unlikely to explain the emergence of human-like lexicons. Taken together with our previous point, that the English lexicon does not afford near-perfect task performance, we actually find it very encouraging that the emergent system that is most aligned with humans also achieves bounded task performance. In other words, we value all metrics for evaluation, including task-performance, and when comparing them with human behavior they all consistently support our conclusions.", "b3_evidence": "1) \"At test time, we assess the pragmatic competence (i.e., utility) of the agents as well as the 'human-likeness' of the shared emergent lexicon that they converged on...\" (Abstract/Introduction).\n2) \"we predict that a shared human-like lexicon will not emerge when agents are guided solely by utility maximization but rather when they are guided by a non-trivial tradeoff between optimizing utility, informativeness, and complexity.\" (Introduction).\n3) \"Interestingly, pressure for communicative informativeness, rather than (non-communicative) task utility, appears as the main driver of emergent communication, but weaker pressures to minimize complexity and maximize utility are still crucial for achieving human-like properties of the lexicon.\" (Introduction).", "b2_justification": "The authors directly rebut the reviewer's criticism: they argue they already focus on the lexical (not syntactic) comparison, justify prioritizing human-likeness metrics because task performance can be trivially high for non-human-like systems, provide empirical bounds showing their model's task accuracy lies within plausible human range, and state they will make limitations more explicit. Thus they do address and dispute the claim that the paper lacks discussion of this methodological issue.", "b3_justification": "The paper explicitly evaluates both task performance (pragmatic competence / utility) and human-likeness, and discusses their tradeoffs and relative roles (informativeness vs utility). Thus it does not \"severely lack discussion\" of prioritizing human-likeness over task performance; instead it analyzes the interaction and tradeoffs between these objectives."}
{"claim": "The manuscript provides no clear basis for the claim that utility and informativeness are only partially aligned.", "claim_type": "experimental", "paper_id": "2wlNnIqCb7", "paper_title": "Bridging semantics and pragmatics in information-theoretic emergent communication", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ZUU7oKQGvi", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "High task performance (utility) can be trivially achieved with very non-human-like communication systems. ... Therefore, focusing only on task performance is unlikely to explain the emergence of human-like lexicons. In comparison, our model achieves ~72%, which is well within the reasonable range of human performance.", "b3_evidence": "\"Interestingly, pressure for communicative informativeness, rather than (non-communicative) task utility, appears as the main driver of emergent communication, but weaker pressures to minimize complexity and maximize utility are still crucial for achieving human-like properties of the lexicon.\"", "b2_justification": "The authors directly defend the claim by arguing that utility alone can be misleading, providing empirical reasoning and human-performance bounds and showing their model's performance falls within the human range; they also emphasize other metrics (lexicon size, NID, complexity) are important for assessing alignment.", "b3_justification": "The paper asserts that informativeness, rather than task utility, is the main driver while utility plays a weaker role, but the provided manuscript excerpt states this conclusion without presenting accompanying empirical analyses, metrics, or detailed results in the shown sections to substantiate the partial alignment claim."}
{"claim": "The authors claim the listener under the utility-only condition does not learn robust, non-contextual semantics but do not explain how the model nonetheless generalizes well.", "claim_type": "experimental", "paper_id": "2wlNnIqCb7", "paper_title": "Bridging semantics and pragmatics in information-theoretic emergent communication", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "ZUU7oKQGvi", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We have verified that our results are robust across random seeds (see Table 1). The stopping criteria we used is convergence of the training objective, which is one of the most common, generic stopping criteria in the literature... We have not considered a stopping criteria that specifically targets better alignment with humans, but that presumably could only improve our results.\"; \"High task performance (utility) can be trivially achieved with very non-human-like communication systems.\"", "b3_evidence": [{"quote": "Given the substantial empirical evidence that human semantic systems are pressured to optimize the IB tradeoff, we predict that a shared human-like lexicon will not emerge when agents are guided solely by utility maximization but rather when they are guided by a non-trivial tradeoff between optimizing utility, informativeness, and complexity.", "section": "1 Introduction"}, {"quote": "In support of our prediction, we find that human-like properties of the lexicon (its size, complexity, and alignment with English speakers), together with high pragmatic competence, emerge when agents are guided by both context-specific utility and general communicative pressures as derived from the IB principle.", "section": "1 Introduction"}, {"quote": "Tucker et al. [4] showed how to directly integrate the IB objective function with utility maximization in emergent communication and demonstrated the advantages of this framework for faster convergence rates and better out-of-distribution generalization [31]. However, they did not study the co-emergence of semantics and pragmatics.", "section": "2 Related work"}], "b2_justification": "The authors partially address the reviewer's concern by providing evidence of robustness (across random seeds and a common convergence-based stopping criterion) and arguing that high utility can be achieved by non-human-like systems (hence task performance alone is not decisive). However, they do not directly explain the mechanism by which the utility-only listener generalizes well despite lacking robust, non-contextual semantics.", "b3_justification": "The paper explicitly states that a human-like (non-contextual) lexicon does not emerge when agents are guided solely by utility maximization (supporting the first part of the reviewer claim). However, the paper does not make or substantively discuss a claim that the model nevertheless \"generalizes well\" under the utility-only condition, nor does it provide an explanation for such a phenomenon; the only discussion of improved out-of-distribution generalization refers to prior work on the VQ-VIB method, not an explanation within this paper (so the second part of the reviewer claim is not supported by the paper)."}
{"claim": "The paper does not explain the specific differences between the proposed method and diffusionTS.", "claim_type": "baseline", "paper_id": "5HQhYiGnYb", "paper_title": "FIDE: Frequency-Inflated Conditional Diffusion Model for Extreme-Aware Time Series Generation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "0RMF9eYWmh", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"DiffusionTS struggles to effectively capture extreme values due to its primary focus on generating and reconstructing entire time series, rather than specifically preserving the distribution of extreme values. According to the objective function (Eq. 10) of DiffusinTS, it aims to minimize mean squared error in the time domain and frequency domain. This approach leads the model to prioritize the central tendency of the data, resulting in a strong focus on predicting the conditional expectation. However, this focus tends to underrepresent extreme values, which are often located in the tail of the distribution. Our proposed method addresses this limitation by incorporating both mean squared error and a Generalized Extreme Value (GEV) loss (see Eq. 11 in our paper). This combination allows our model to simultaneously maintain overall accuracy and accurately capture the distribution of extreme values, which is critical for applications that rely on modeling rare events.\" \"Our proposed method addresses this limitation by introducing a targeted strategy to inflate high-frequency components. This approach ensures that these components do not prematurely fade out during the diffusion model's noising process, allowing them to dissipate at a rate comparable to low frequency components, thus better preserving the characteristics of extreme values.\"", "b3_evidence": "\"To illustrate the difficulty of modeling the distribution of block maxima, Figure 1 shows the result of applying the Denoising Diffusion Probabilistic Model (DDPM) [12] to a synthetic AR(1) dataset.\"; \"While there has been growing research on applying diffusion models for time series [20, 2], their ability to preserve the distribution of extreme values remains largely underexplored.\"", "b2_justification": "The authors directly explain specific methodological differences: they describe how DiffusionTS's objectives lead it to prioritize mean behavior and underrepresent extremes, and contrast this with their method's inclusion of a GEV loss and a targeted high-frequency inflation strategy to preserve extreme values.", "b3_justification": "The paper discusses DDPM and diffusion models broadly (Introduction, Section 3) but contains no mention of 'DiffusionTS' or any comparison explaining specific differences to it, so the claim that it does not explain specific differences is accurate."}
{"claim": "The manuscript does not explain how fairness of the comparison between methods is ensured.", "claim_type": "baseline", "paper_id": "5HQhYiGnYb", "paper_title": "FIDE: Frequency-Inflated Conditional Diffusion Model for Extreme-Aware Time Series Generation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "0RMF9eYWmh", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We employed comparable experimental setups for DiffusionTS, Fourier-Flows, and RealNVP as we did for our proposed method and other baseline approaches. To ensure a fair comparison, we carefully tuned the general hyperparameters (number of epochs, learning rate, batch size) for all methods under evaluation. To account for variability and ensure fairness in our comparisons, we conducted 5 independent runs for each method. We then reported the mean and standard deviation of all performance metrics across these runs.", "b3_evidence": "\"Experimental results on real-world and synthetic data showcase the efficacy of FIDE over baseline methods, highlighting its potential in advancing Generative AI for time series analysis, specifically in accurately modeling extreme events.\"", "b2_justification": "The authors directly explain how they ensured fair comparisons by using comparable experimental setups, tuning general hyperparameters for all methods, running multiple independent runs, and reporting mean and standard deviation—addressing the reviewer's concern about fairness.", "b3_justification": "The provided manuscript text (Abstract, Introduction, and Sections 2–4) mentions experimental comparisons but does not include any description of how fairness between methods was ensured (no evaluation protocol, baseline selection criteria, hyperparameter tuning/selection procedures, or other controls are described in the supplied content)."}
{"claim": "Ablation experiments are placed in the supplementary materials, which reduces clarity and is inappropriate according to the reviewer.", "claim_type": "presentation", "paper_id": "5HQhYiGnYb", "paper_title": "FIDE: Frequency-Inflated Conditional Diffusion Model for Extreme-Aware Time Series Generation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "0RMF9eYWmh", "b2_label": "Not Determined", "b3_label": "Not Determined", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We thank the reviewer for suggesting the Wilcoxon-Holm test to further validate the performance improvement of our proposed method relative to DiffusionTS.\"; \"While this is indeed an interesting direction for further investigation, given the limited time remaining for authors' response, we were unable to conduct such an analysis at this time.\"", "b3_evidence": ["A more detailed analysis supporting this argument is given in Appendix B.", "see Appendix C for proof and details"], "b2_justification": "The authors' response discusses statistical tests, comparisons to baselines, experimental setup, and data scarcity, but does not address the reviewer's specific complaint about ablation experiments being placed in the supplementary materials or whether that reduces clarity.", "b3_justification": "The paper references appendices for additional analysis and proofs (Appendix B and C) but does not mention any ablation experiments or state that ablations are placed in supplementary materials. Therefore the specific claim about ablation experiments being placed in the supplementary materials cannot be confirmed from the provided text."}
{"claim": "The authors did not verify the proposed method's performance on small-scale datasets such as 10% of the stock dataset.", "claim_type": "experimental", "paper_id": "5HQhYiGnYb", "paper_title": "FIDE: Frequency-Inflated Conditional Diffusion Model for Extreme-Aware Time Series Generation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "0RMF9eYWmh", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "While this is indeed an interesting direction for further investigation, given the limited time remaining for authors' response, we were unable to conduct such an analysis at this time.", "b3_evidence": "Experimental results on real-world and synthetic data showcase the efficacy of FIDE over baseline methods, highlighting its potential in advancing Generative AI for time series analysis, specifically in accurately modeling extreme events.", "b2_justification": "The authors explicitly acknowledge the reviewer's suggestion to test on small-scale datasets and state they did not perform that analysis due to limited time, thus agreeing the verification was not done.", "b3_justification": "The provided paper text only states that experiments were run on \"real-world and synthetic data\" but gives no mention of a stock dataset or of experiments on small-scale subsets (e.g., 10% of a stock dataset). Therefore the claim that the authors did not verify performance on such a small-scale (10% stock) dataset is consistent with the paper content provided."}
{"claim": "The paper evaluates only one machine learning task, lacking broader benchmarks to demonstrate contributions for long-range sequence modeling.", "claim_type": "experimental", "paper_id": "vE1e1mLJ0U", "paper_title": "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "2c423ciTlo", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"The LRA benchmark contains 6 rather different tasks. Additionally, the Spoken Heidelberg Digits Task (SHD), and particularly SHD-addition, has a context length of 2000 for a bin size of 1, and therefore is twice as long as, e.g., the Image or Pathfinder task from LRA. Therefore, we provide results on a total of 8 long-range tasks.\"", "b3_evidence": "Abstract: \"we evaluate it on various tasks with demanding temporal structures, including the Long Range Arena (LRA) datasets, as well as a novel neuromorphic dataset based on the Spiking Heidelberg Digits dataset (SHD-Adding).\"; Introduction (Sec. 1): \"We subsequently evaluate the ELM neuron on the well-established long sequence modeling LRA benchmarks from the machine learning literature, including the notoriously challenging Pathfinder-X task, where it achieves over 70% accuracy...\"", "b2_justification": "The authors state they evaluated multiple long-range benchmarks (LRA's six tasks plus SHD and SHD-Adding), and report additional ablations and model-size comparisons on Pathfinder and LRA, directly addressing the reviewer's concern about limited tasks.", "b3_justification": "The paper evaluates multiple long-range sequence modeling benchmarks (Long Range Arena datasets, a neuromorphic SHD-Adding task, and Pathfinder-X), so the claim that it evaluates only one machine learning task is false."}
{"claim": "The paper's efficiency claims may be overstated because Table 1 shows ELM still requires roughly 100,000–200,000 parameters.", "claim_type": "quantitative", "paper_id": "vE1e1mLJ0U", "paper_title": "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "2c423ciTlo", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"we provide an ablation of the ELM neuron and S5 model on Pathfinder in terms of parameters in Tables S5 and S6 showing that an ELM with 3.5K parameters is outperforming a single layered S5 with ~170K parameters (62.95% ACC vs 58.19% ACC).\"; \"The number of trainable parameters might look deceptively large, but the input dimension is also very large (1278 on the NeuronIO). ... a Branch-ELM with 5329 parameters ... can achieve 0.9915 AUC.\"; \"We acknowledge the scaling limitation of individual ELM neurons, which we set out to explore using the LRA benchmark...\"", "b3_evidence": "Abstract: \"our ELM neuron can accurately match the aforementioned input-output relationship with under ten thousand trainable parameters.\" Introduction: \"Our experiments show that a variant of the ELM neuron is expressive enough to accurately match the spike level I/O of a detailed biophysical model ... with a few thousand parameters, in stark contrast to the millions of parameters required by temporal convolutional networks.\"", "b2_justification": "The authors do not accept that ELM inherently requires 100k–200k parameters; they provide additional ablations and results showing much smaller ELM/Branch-ELM models (3.5K–5.3K params) that outperform or fit data well, and explain parameter counts depend on input dimensionality. They acknowledge scaling limitations but counter the reviewer's assertion with empirical evidence and clarifications.", "b3_justification": "The paper explicitly claims the ELM neuron matches the biophysical I/O relationship with under ten thousand (and in places 'a few thousand') trainable parameters, so the reviewer's assertion that Table 1 shows ELM requires ~100k–200k parameters contradicts the paper's stated parameter counts. The provided content does not include a Table 1 that reports 100k–200k parameters."}
{"claim": "The paper does not evaluate training ELM with biologically plausible learning rules instead of BPTT, leaving biological learning compatibility untested.", "claim_type": "experimental", "paper_id": "vE1e1mLJ0U", "paper_title": "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.", "paper_venue": "iclr2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "2c423ciTlo", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We agree that it would be interesting to study the biologically plausible training, and it might happen that the training will converge to a different solution. However, for this manuscript, we aimed to establish how the model can perform with standard machine learning optimizers (that typically define the upper limit on the performance, seldomly achieved by the biologically plausible rules). Finding how to train this model with, for example, Eq.Prop or even more complicated bio-plausible plasticity rules would be an exciting direction. We added it to future work suggestions.\" \"We highlight the limitations of the dataset in the main part of the manuscript; namely that we don’t train the ELM neuron in a biologically plausible way (e.g. similar to your suggestion), and that only the SHD and SHD-Adding are bio-inspired tasks, and the NeuronIO task is not.\"", "b3_evidence": "\"While biologically inspired, low-level biological processes are abstracted away for computational efficiency, and consequently, individual parameters of the ELM neuron are not designed for direct biophysical interpretability.\" \n\n\"w_p always learnable\" (describing the MLP integration parameters) and other parameters are described as learnable.", "b2_justification": "The authors explicitly acknowledge they did not train the ELM with biologically plausible learning rules, state they used standard ML optimizers for this manuscript, and list biologically-plausible training as future work.", "b3_justification": "The paper does not describe or evaluate training the ELM with biologically plausible learning rules nor mention alternatives to standard gradient-based training (e.g., BPTT). It repeatedly states that parameters are ‘learnable’ and that low-level biological processes are abstracted away, implying no exploration of biologically plausible learning methods."}
{"claim": "Using clique- or star-based expansions as baselines is inappropriate because they are not representative of state-of-the-art hypergraph projection methods.", "claim_type": "baseline", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"What's more, clique expansion, and star expansion may not be the SOTA expansion methods, but they are very classic hypergraph expansion methods.\" \n\n\"we also compared AdE with some state-of-the-art hypergraph representation learning methods, such as AllSet [6], which employs star-based expansion methods during hypergraph expansion. Compared with these SOTA methods and classic expansion methods, we believe our model AdE is novel, effective, and generalized.\" \n\n\"To validate whether the node-degree preserving projection methods effectively convert hypergraphs into graphs, we then discuss one existing method, IRMM [1], and conduct experiments with IRMM over Cora, Cora-CA, and Citeseer datasets.\"", "b3_evidence": "1) \"most HyGNNs methods primarily leverage typical expansion methods, e.g., clique expansion (CE) (Sun et al., 2008), star expansion (SE) (Agarwal et al., 2006), and line expansion (LE) (Yang et al., 2022), to convert hypergraphs into graphs\". 2) \"For instance, HyperGCN (Yadati et al., 2019) utilizes a CE-based method to transfer the hypergraph structure into a weighted graph structure.\" 3) \"Most hypergraph neural networks (HyGNNs) first convert hypergraphs to (weighted) graphs via classic expansion methods, i.e., clique expansion (CE) (Sun et al., 2008), star expansion (SE) (Agarwal et al., 2006), line expansion (LE) (Yang et al., 2022) and its variants (Yadati et al., 2019; Feng et al., 2019; Zhou et al., 2006)\".", "b2_justification": "The authors explicitly defend using clique/star expansions as baseline choices (calling them classic) and state they additionally compared to state-of-the-art projection/expansion methods (e.g., AllSet, HyperGCN, Line expansion, and IRMM), arguing that these comparisons address the concern. Thus they reject the claim that using clique/star baselines is inappropriate.", "b3_justification": "The paper treats clique and star expansions as standard, widely-used methods in recent HyGNN work and cites state-of-the-art models that use them; it criticizes certain limitations but does not claim they are inappropriate or unrepresentative of SOTA projection methods."}
{"claim": "The authors do not justify why the projected graph will better capture homophily than the original hypergraph.", "claim_type": "methodology", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "To make it clear, we would like to provide an intuitive example showing that AdE enhances the ability to keep homophily when expanding hypergraphs into graphs. ... However, Nodes A and C do not share any interests, and they are supposed to be disconnected or connected with tiny edge weights. But our AdE can professionally handle real-world scenarios: 1. AdE first selects two representative nodes with the largest distance within the hyperedge. ... 3. With the edge set, we learn to assign the adaptive distance-aware weights to all edges in E_e. We believe that the edge weight between A and B is larger than the edge weight between A and D.\n\nFrom Table 3, we can conclude that AllSet outperforms all baseline methods over House (1.0) and House (0.6) datasets. Our method AdE outperforms AllSet over these two datasets, showing the effectiveness of handling the hypergraph datasets having larger hyperedge degrees and small homophily.", "b3_evidence": "\"we further design a distance-aware kernel function to dynamically adjust the edge weights to make sure that node pairs having similar attribute features within the corresponding hyperedge are more likely to be connected with large weights.\"", "b2_justification": "The authors directly rebut the reviewer by providing a design rationale (adaptive representative-node selection via GSi-Net and a distance-aware kernel for edge weights) and both an intuitive example and empirical results (datasets with low homophily) to argue the projected graph better preserves homophily than existing expansions.", "b3_justification": "The paper explicitly justifies that their projected (expanded) graph will better capture homophily by (1) noting that prior expansions use fixed/uniform weights and thus ignore attribute similarity, and (2) proposing a distance-aware kernel that increases edge weights between nodes with similar attributes—i.e., an explicit rationale for why the projected graph better reflects homophily."}
{"claim": "The paper does not justify using a representative pair of nodes per hyperedge; the rationale is missing.", "claim_type": "methodology", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "We design a novel module GSi-Net to adaptively learn the most representative two nodes for each hyperedge based on the specific downstream tasks. ... We believe that selecting two representative nodes to represent the information within the hyperedge is a common idea for hypergraph learning [1-4]. ... the reason why existing works [2,3,4] select two representative nodes based on the rule (v_{e^+}, v_{e^-})=argmax_{v_i,v_j in e}|S_i - S_j| is that finding the largest node and the smallest node in the feature space is an easy but effective way to represent the most essential information within the hyperedge.", "b3_evidence": "1) \"the classic CE method connects all node pairs within the same hyperedge and makes it a fully connected subgraph, which will bring the redundant information in the converted graph (Sun et al., 2008). HyperGCN, another classic CE-based method, proposes to pick two nodes to symbolize the corresponding hyperedge and further connect the rest of the nodes with the selected nodes (Yadati et al., 2019). However, the selected nodes are not representative enough of the corresponding hyperedge, which causes certain information loss.\" 2) \"To handle the first challenge, instead of connecting all nodes within the same hyperedge indiscriminately, we design a novel Global Simulation Network (GSi-Net) to select two nodes for symbolizing each hyperedge adaptively.\" 3) \"We first introduce a Global Simulation Network to pick two representative nodes for symbolizing each hyperedge in an adaptive manner.\"", "b2_justification": "The authors explicitly disagree with the reviewer's assertion that no rationale was given: they provide multiple justifications (method design, citations to prior work, theoretical/intuitive arguments) and empirical ablation evidence supporting the use of two representative nodes and their adaptive selection via GSi-Net.", "b3_justification": "The paper explicitly motivates selecting a representative node pair per hyperedge as a way to avoid the redundancy of clique expansion and to improve over prior work (HyperGCN) whose chosen pair is claimed to be insufficiently representative. It then proposes the Global Simulation Network (GSi-Net) to adaptively select two representative nodes per hyperedge."}
{"claim": "It is unclear how the approach handles hyperedges of varying sizes, including singleton or very large hyperedges.", "claim_type": "methodology", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "For Hyperedge with degree 1, it is a self-loop for the node with edge weight 1, AdE will add a self-loop of the node to the graph.\n\nFor hyperedge with degree 2, it is a pairwise edge, so this approach will generate an edge between two nodes, with edge weight computed by function \\mathcal{W} in Equation 3.\n\nFor hyperedge with degree 3, our method connects any pair of nodes within the hyperedge, which forms a triangle. AdE generates exactly the same subgraph structure with clique expansion for hyperedge with degree 3.\n\nFor general cases, i.e., hyperedge degree is larger than 3, AdE converts hypergraphs into a weighted graph as follows:\n1. For each hyperedge e in E, AdE selects two representative nodes (v_{e^+}, v_{e^-})=argmax_{v_i,v_j} |S_i - S_j| ...\n2. For each hyperedge e in E, we connect each mediator with two representative nodes v_{e^+} and v_{e^-}, respectively, and further obtain the edge set E_e = {...}\n3. We compute edge weight in each edge set E_e via our designed learnable kernel function W_{i,j} (Eq. 3), and normalize these edge weights with respect to hyperedges, \\bar{W}_{i,j}^{(e)} = W_{i,j} / \\sum_{...} W_{k,g}.\n\nBy the aforementioned steps, we obtain the weighted graph with the adaptive adjacency matrix A_a = \\sum_{e\\in E} I[\\{v_i,v_j\\}\\in E_e] \\bar{W}_{i,j}^{(e)}.", "b3_evidence": "Abstract: \"we first introduce a Global Simulation Network to pick two representative nodes for symbolizing each hyperedge in an adaptive manner.\"; Figure 2 caption: \"AdE scales the attribute feature X a with the learnable weight matrix W g and identifies a representative node pair ( v e -, v e + ) for each hyperedge e .\"; Section 4.1: \"we design a novel Global Simulation Network (GSi-Net) to select two nodes for symbolizing each hyperedge adaptively.\"", "b2_justification": "The authors explicitly explain how AdE handles hyperedges of different sizes: degree-1 hyperedges become self-loops, degree-2 become a pairwise edge, degree-3 yields a clique-equivalent triangle, and for degree>3 they give a clear 3-step procedure (select two representatives, connect mediators to them, compute/normalize adaptive weights).", "b3_justification": "The paper repeatedly states the method selects two representative nodes per hyperedge (e.g., Abstract, Section 4.1, Figure 2 description) but does not describe special handling for hyperedges of size one or discuss behavior/scaling for very large hyperedges. Thus it is unclear how varying hyperedge sizes, including singletons or extremely large hyperedges, are handled."}
{"claim": "The method's applicability when nodes lack attributes is not addressed, leaving performance on attribute-less hypergraphs unclear.", "claim_type": "methodology", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Our mechanisms, GSi-Net and the kernel function for edge weights, take the attribute features into account. Therefore, our proposed method can not be applied to hypergraphs without node attribute features directly.\n\nHowever, some techniques can be leveraged to generate node attribute features, such as identity features (one-hot encoded vector), constant features (constant value for each vector), and positional encoding (attribute based on the position of the node in the graph/hypergraph). With these generated attribute features, our proposed method still works. If there are some extreme scenarios in which attribute features are impossible to obtain, we think this could be our future work to expand the scalability of AdE.\"", "b3_evidence": "1) \"we design a distance-aware kernel function to dynamically adjust the edge weights to make sure that node pairs having similar attribute features within the corresponding hyperedge are more likely to be connected with large weights.\" 2) \"given a hypergraph H = ( V , E , X ) with attribute feature X , (i) AdE first feeds the attribute feature X into a global pooling layer, and leverages simulation network (Si-Net) to learn the importance of each feature dimension... Afterward, AdE scales the attribute feature X_a with the learnable weight matrix W_g and identifies a representative node pair (v_e-, v_e+) for each hyperedge e.\" 3) \"Definition 3.1. Hypergraph. ... and X is the attribute feature set.\"", "b2_justification": "The authors explicitly acknowledge that AdE requires node attributes and cannot be applied directly to attribute-less hypergraphs; they propose generating synthetic features as a workaround and treating true attribute-less cases as future work.", "b3_justification": "The paper consistently assumes node attribute features X and describes all AdE components (GSi-Net, distance-aware kernel) as operating on those attributes, but it does not discuss or present mechanisms or experiments for the case where nodes lack attributes. Thus the claim that applicability on attribute-less hypergraphs is not addressed is accurate."}
{"claim": "The paper omits dataset details such as size, average degree distribution, and average hyperedge size.", "claim_type": "experimental", "paper_id": "5M2MjyNR2w", "paper_title": "Adaptive Expansion for Hypergraph Learning", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "2eO0wOQPFu", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "A6: \"we already provided a detailed description of all statistics of five benchmark hypergraph datasets in Table 3 of the Appendix in our original manuscript. To make it clearer and more convenient, we also list the statistics of these datasets in the following Table 1 for your reference:\" (followed by a table listing # nodes, # hyperedges, avg. d(e), avg. d(v), etc.)\n\nAlso earlier: \"Table 2. Data statistics: $h_v$: node homophily; $h_e$: hyperedge homophily; $avg. d(v)$: mean node degree; $avg. d(e)$: mean hyperedge degree.\" (with table including avg d(v) and avg d(e) for datasets)", "b3_evidence": "“Extensive theoretical justifications and empirical experiments over five benchmark hypergraph datasets demonstrate that AdE has excellent rationality, generalization, and effectiveness compared to classic expansion models.”", "b2_justification": "The authors acknowledge the request and provide dataset statistics (number of nodes, number of hyperedges, average hyperedge degree, average node degree, etc.) in the rebuttal, referencing an Appendix table and reproducing a summary table in the response.", "b3_justification": "The paper mentions experiments on \"five benchmark hypergraph datasets\" but does not provide any dataset statistics or descriptions (e.g., dataset sizes, degree distributions, or average hyperedge sizes) in the provided content (Abstract, Introduction, Preliminaries, Methodology, Related Works)."}
{"claim": "Restricting to automorphisms of cycles and simple subgraphs may make computing the decomposition into irreducible representations computationally feasible.", "claim_type": "methodology", "paper_id": "HRnSVflpgt", "paper_title": "Schur Nets: exploiting local structure for equivariance in higher order graph neural networks", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "vD5C5zNY0Z", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "In summary, you are right, if all that we were interested in were cycles and first order message passing, then we could have developed an architecture specialized to just that and that would have been easier maybe.; For cycles the relevant group is not the cyclic group but the dihedral group, which is a little bit more complicated because it also has some two dimensional irreducible representations.; We wish it were just the eigenvectors that need to be cached. The main technical difficulty in GNNs is parallelizing the message passing step on the GPU, ... This is what can lead to memory issues.", "b3_evidence": "\"The Autobahn architecture described in [37] explicitly accounts for the automorpism group of two specific types of subgraphs, cycles and path. Defining bespoke convolution operations on these two types of subgraphs was shown to improve performance on molecular datasets like ZINC [26]. The drawback of the Autobahn approach is that it requires explicitly identifying the automorphism group of each type of subgraph, and crafting specialized equivariant operations based on its representation theory. For more flexible architectures leveraging not just cycles and paths but many other types of subgraphs this quickly becomes infeasible.\"", "b2_justification": "The authors acknowledge that focusing only on cycles/first-order message passing could allow a specialized (and therefore simpler/more feasible) solution, but they also point out complications (dihedral group irreps) and emphasize other practical computational bottlenecks (GPU message-passing, memory, caching). They therefore partly agree with the reviewer's suggestion but do not fully endorse it as a complete solution.", "b3_justification": "The paper states that the Autobahn approach explicitly handles automorphism groups for cycles and paths and implements bespoke equivariant operations for them (implying decomposition was carried out for these simple subgraphs). However, the paper also emphasizes that explicitly determining automorphism groups and crafting representations for many subgraph types quickly becomes infeasible, so it does not claim this is generally a scalable solution."}
{"claim": "The paper does not justify the benefit of enforcing the probability flow ODE in a PINN-inspired way instead of using operator learning methods such as Zheng et al.", "claim_type": "baseline", "paper_id": "a24gfxA7jD", "paper_title": "Physics Informed Distillation for Diffusion Models", "paper_venue": "iclr2024", "paper_decision": "Reject", "decision": "Reject", "review_id": "GvTxqBwc1Y", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"In DSNO[4], operator learning is defined as learning the mapping between functions. ... DSNO requires multiple functional evaluations of the different time steps in a parallel manner instead of the recursive one in diffusion models. As such, despite being able to perform single step inference to generate images, the parallel evaluations of the different time steps in DSNO causes it to be slower than standard single step inference ...\" \n\n\"operator learning as described in DSNO requires a trajectory dataset. This can be very memory consuming and expensive to produce ... In contrast, proposing it in a physics informed fashion is data-free as only noise samples are needed, alleviating this problems entirely.\"", "b3_evidence": "“Among the former, noteworthy methods such as Knowledge Distillation (Luhman & Luhman (2021)), DSNO (Zheng et al. (2022)), and Rectified Flow (Liu et al. (2022)). have recently exhibited their efficacy in distilling single-step student models. However, a notable drawback inherent in these approaches is the computationally costly nature of generating such synthetic data, which presents scalability challenges, particularly for larger models.”\n\n“Building upon these developments, we propose a novel distillation method for diffusion models called Physics Informed Distillation (PID), a method that takes a PINN-like approach to distill a single-step diffusion model.”", "b2_justification": "The authors explicitly justify why a PINN-inspired, probability-flow-ODE approach is preferable to operator-learning (DSNO/Zheng et al.) for their goals: they argue operator learning needs parallel/time-multiple evaluations, higher training cost, and trajectory datasets, whereas their PINN-style method is data-free, uses single-point evaluations, and is better suited for single-step, sampling-efficient distillation.", "b3_justification": "The paper introduces a PINN-inspired distillation and mentions Zheng et al. (DSNO) among synthetic-data-based distillation methods, noting their costly synthetic data generation. However, it does not provide an explicit theoretical or empirical justification comparing the benefit of enforcing the probability flow ODE in a PINN-like way versus operator-learning methods such as Zheng et al.; there is no direct comparison, analysis, or ablation that argues why the PINN-inspired enforcement is preferable to operator learning."}
{"claim": "The paper does not explain why the contrastive learning-based encoder is not used during downstream segmentation training.", "claim_type": "methodology", "paper_id": "uyqjpycMbU", "paper_title": "Integrating Deep Metric Learning with Coreset for Active Learning in 3D Segmentation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "H0XOuH3aDu", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"One of the main issues is architecture incompatibility: the contrastive encoder may not be readily used by, for example, our weakly-supervised segmentation architecture and we would have to adapt the architecture, which we felt would be out of the scope of our current work. Thus, in order to ensure a fair comparison between all methods, none of the downstream segmentation models used the contrastive learning-based encoder. However, especially for the fully-supervised networks, we can definitely generate some results with the contrastive learning-based encoder and include this in our camera-ready version.\" || \"First, we considered utilizing the contrastive learning-based encoder in the downstream segmentation task. We utilized the fully-supervised segmentation architecture that we referenced in the general rebuttal [6] and we compared the results with utilizing random weight initialization, pre-trained medical weights provided by [6], and our original U-Net trained from scratch. We generated the results on a fully-supervised segmentation task on the ACDC dataset and calculated the mean DICE scores over the 2%-5% annotation points (for fair comparison).\"", "b3_evidence": "“We do this by training a contrastive learning-based encoder with a unique Group-based Contrastive Learning (GCL) ... d_ϕ is then used by the Coreset algorithm to select the optimal set of slices. ... The annotations for the collected slices are then used to train a segmentation model.”", "b2_justification": "The authors acknowledge the reviewer's concern, explain why the contrastive encoder was not used (architecture incompatibility and fairness across comparisons), and report experiments that do use the contrastive encoder and promise to include these results/explanations in the camera-ready version.", "b3_justification": "The paper describes training a contrastive learning-based encoder to produce d_ϕ for Coreset selection (Section 3.2 / 3.2.1) and then states that the collected annotations are used to train a segmentation model, but it does not provide any explanation for why the contrastive encoder would not be reused during downstream segmentation training."}
{"claim": "Equation (5) appears to permit comparisons between different images, which would be problematic given inter-image anatomical misalignment.", "claim_type": "methodology", "paper_id": "uyqjpycMbU", "paper_title": "Integrating Deep Metric Learning with Coreset for Active Learning in 3D Segmentation", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "H0XOuH3aDu", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Yes, the images in equation 5 can be different in our method...\"; \"After registering the volumes and the scribble masks...we ultimately found that there was no improvement in using this approach.\"", "b3_evidence": "“The NT-Xent loss focuses on generating and comparing embeddings for image pairs and their augmentations.”; “In the same vein, in our group-based loss, we promote similar embeddings for slices from the same group and dissimilar embeddings for slices from different groups, enhancing group-level representation.”; “The denominator excludes patient slices for a particular data point that are not part of the same group. Excluding non-group patient slices ensures that the model does not promote dissimilarity between non-group slices from the same patient.”", "b2_justification": "The authors acknowledge that equation (5) can compare different images (agreeing with the reviewer) and they investigated alignment (group-wise registration). They report that registration did not improve results, arguing the issue is not empirically problematic, while also noting they can add registered experiments in the final version—thus they partially accept the concern but counter that it did not harm performance in their tests.", "b3_justification": "The paper’s contrastive formulation explicitly compares embeddings of different slices/images (supporting the reviewer’s observation that Equation (5) permits inter-image comparisons). However, the paper does not claim such comparisons are problematic due to anatomical misalignment and does not discuss inter-image anatomical misalignment as an issue; instead it mitigates unwanted comparisons via group definitions and exclusions, so the reviewer’s concern about misalignment is not supported by the text."}
{"claim": "The paper does not explain how segmentations were extracted from ViTs, making the ViT-S results shown in Figure 4 unclear.", "claim_type": "methodology", "paper_id": "IRcv4yFX6z", "paper_title": "Learning Hierarchical Image Segmentation For Recognition and By Recognition", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "GtHJBOtrXQ", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "We generate segments from ViT by applying K-Means clustering to the final output tokens. We bilinearly upscale the feature map and then apply K-Means to the pixel-level features to align the segments with the input image resolution. Similar to CAST, we cross-reference clustering assignments across different levels to achieve hierarchical image segmentation. To maintain a consistent cluster hierarchy, we iteratively run K-Means, reducing the number of clusters by grouping the clusters from the previous iteration into coarser clusters. We have clarified this procedure on page 5 and in Appendix A.4 of our revised manuscript.", "b3_evidence": "1) \"We use arbitrarily-shaped superpixels instead of square patches on a regular grid as the visual units for ViT tokens.\" 2) \"Due to their distinct architectural designs, recognition models cannot be directly used for segmentation tasks. Instead, architectural modifications and fine-tuning with segmentation labels are often required (Ahn & Kwak, 2018).\" 3) \"By looping hierarchical segmentation into recognition, CAST delivers four major results. 1) CAST derives a hierarchical segmentation...\"", "b2_justification": "The authors directly explain the procedure used to extract segmentations from ViTs, describing K-Means on upscaled token features and an iterative clustering hierarchy, and state they clarified this in the paper and appendix.", "b3_justification": "The paper describes how its own model (CAST) produces hierarchical segmentation (using superpixels and graph-pooling) but does not provide a description of how segmentations were extracted from baseline ViT models (e.g., ViT-S) for the comparisons in Figure 4. The Introduction and related discussion contrast ViT patch-based recognition with CAST's superpixel-based segmentation, but no method for deriving segmentation masks from ViT is given in the provided content."}
{"claim": "It is unclear whether positional embeddings are added to the CLS token, because the paper does not state this implementation detail.", "claim_type": "methodology", "paper_id": "IRcv4yFX6z", "paper_title": "Learning Hierarchical Image Segmentation For Recognition and By Recognition", "paper_venue": "iclr2024", "paper_decision": "Accept (spotlight)", "decision": "Spotlight", "review_id": "GtHJBOtrXQ", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"Following MoCo-v3, we used fixed sine-cosine positional embeddings for patches and an all-zero vector for the CLS token. The all-zero vector matches the length of positional embeddings with tokens but has no impact. We have clarified this in the equation on page 4 of our revised manuscript.\"; \"We added the positional encodings instead of concatenating them like standard ViTs. Please note that $E_{\\text{pos}}$ is added (+) to the tokens in the equation on page 4 of our paper.\"", "b3_evidence": "We implement our concept by innovating Vision Transformer (ViT) on two aspects. 1) We use arbitrarily-shaped superpixels instead of square patches on a regular grid as the visual units for ViT tokens. 2) We use graph-pooling to group these segment tokens successively towards recognition, forming a fine-to-coarse segmentation hierarchy that reflects partto-whole relationships. The entire model is learned solely from image recognition objectives, either unsupervised (Wu et al., 2018; He et al., 2020) or supervised (Touvron et al., 2021).", "b2_justification": "The authors explicitly clarify the implementation: positional embeddings for patches use fixed sine-cosine, and the CLS token uses an all-zero positional vector (i.e., no effective positional embedding). They also state that positional encodings are added to tokens in the equation on page 4, addressing the reviewer's uncertainty.", "b3_justification": "Nowhere in the provided paper text (Introduction, Related Works, or start of Section 3) does the paper specify implementation details about adding positional embeddings to a CLS token; the method description discusses using superpixels and graph-pooling but omits any mention of CLS tokens or positional embeddings."}
{"claim": "The authors only provide concrete trade-off comparisons against [18] without justifying why other relevant techniques are excluded from these comparisons.", "claim_type": "baseline", "paper_id": "CgGjT8EG8A", "paper_title": "Universal Exact Compression of Differentially Private Mechanisms", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "i340zWiLwc", "b2_label": "Supported", "b3_label": "Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "\"We chose to compare to CSGM [18] since [18] is asymptotically optimal and compares favorably to several previous algorithms, as demonstrated in the experiments in [18]. By showing that our proposed scheme compares favorably to [18], we show that our scheme compares favorably to those previous works as well.\"  \"Regarding Feldman and Talwar [30]: ... The main obstacle in comparing [30, Theorem 3.4] to our result is that [30] relies on a computational hardness assumption on the pseudorandom number generator, and it is unclear how many bits of random seed (communication) are necessary to guarantee computational indistinguishability. Also, [30] does not prove that their scheme has a communication cost close to the theoretical minimum.\"  \"Regarding Bassily and Smith [5]: [5] does not exactly preserves the distribution of the simulated mechanism (there is a 50% chance that the data is dropped). Additional (likely non-trivial) analyses are necessary to characterize its central-DP guarantee for mean estimation, to be compared to our scheme in Figure 1.\"", "b3_evidence": "Abstract: \"Experiment results on distributed mean estimation show that PPR consistently gives a better trade-off between communication, accuracy and central differential privacy compared to the coordinate subsampled Gaussian mechanism, while also providing local differential privacy.\"; Related Work: \"Subsequently, communication-efficient mechanisms introduced by Feldman and Talwar [31], Shah et al. [71], Isik et al. [51] aimed to construct communication-efficient versions of privUnit, either through distributed simulation or discretization. However, these approaches only approximate the privUnit distribution, while our proposed method ensures exact distribution recovery.\"", "b2_justification": "The authors directly justify why they compared mainly to [18] (it is asymptotically optimal and representative of prior work) and give concrete technical reasons for excluding other methods (computational assumptions for [30], non-exact simulation/unclear central-DP for [5] and [65]), thus addressing the reviewer's concern.", "b3_justification": "The paper's abstract and contributions explicitly state experimental comparisons only against the coordinate subsampled Gaussian mechanism, while the Related Work section discusses other relevant techniques (e.g., Feldman & Talwar [31], Shah et al. [71], privUnit variants) but the provided text contains no justification for excluding those methods from the concrete trade-off experiments."}
{"claim": "The manuscript does not explain why approximate simulation would necessarily lead to biased estimates despite claiming conceptual advantages for exact simulation.", "claim_type": "methodology", "paper_id": "CgGjT8EG8A", "paper_title": "Universal Exact Compression of Differentially Private Mechanisms", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "i340zWiLwc", "b2_label": "Contradicted", "b3_label": "Contradicted", "agreement": true, "agreement_type": "exact", "b2_evidence": "In sum, approximate method does not necessarily imply biasedness (e.g., [65]), but an approximate method without a proof of unbiasedness should not be considered to be unbiased. Therefore, unbiasedness is an advantage of our exact method over other approximate methods without proofs of unbiasedness.", "b3_evidence": "“Since the induced mechanism is different from the original mechanism, these statistical properties are not preserved.” / “In contrast, reconstruction distributions in prior simulation-based compression methods [31, 71] are often biased unless specific debiasing steps are performed (only possible for certain DP mechanisms [71]).”", "b2_justification": "The authors directly reject the claim that approximate simulation necessarily leads to biased estimates, clarifying that approximate methods do not inherently imply bias and that unbiasedness is a property requiring proof; they argue exact simulation offers a ready proof of unbiasedness but do not assert approximate methods are always biased.", "b3_justification": "The paper explicitly states that approximate simulation changes the output distribution and therefore can fail to preserve statistical properties such as unbiasedness, and it expressly notes prior simulation-based methods are often biased unless debiasing is applied."}
{"claim": "The proposed protocol appears to inflate the privacy budget, which raises concerns about the validity of the privacy guarantees and comparisons.", "claim_type": "methodology", "paper_id": "CgGjT8EG8A", "paper_title": "Universal Exact Compression of Differentially Private Mechanisms", "paper_venue": "neurips2024", "paper_decision": "Accept (poster)", "decision": "Poster", "review_id": "i340zWiLwc", "b2_label": "Partially Supported", "b3_label": "Partially Supported", "agreement": true, "agreement_type": "exact", "b2_evidence": "Indeed, if $(\\varepsilon, \\delta)$ is fixed, then we have to reduce the $\\varepsilon, \\delta$ of the simulated mechanism. However, this reduction can be small according to Theorem 4.8.", "b3_evidence": "“PPR can compress a central DP mechanism (e.g., the Gaussian mechanism [27]) and simultaneously achieve weaker local DP (i.e., with a larger ε_local) and stronger central DP (i.e., with a smaller ε_central), while maintaining exactly the same privacy-utility trade-offs as the uncompressed Gaussian mechanism.”; “Bun et al. [12] proposed another generic compression technique based on rejection sampling, which compresses a ε -DP mechanism into a 10 ε -DP mechanism.”; “To ensure local DP, we introduce a randomized encoder based on the Poisson functional representation, which stochastically maps a private local message to its representation. Hence, PPR achieves order-wise trade-offs between privacy, communication, and accuracy, while preserving the original distribution of local randomizers.”", "b2_justification": "The authors acknowledge the concern that the simulated mechanism's (ε,δ) may need to be reduced (which relates to 'inflating the privacy budget') but argue this reduction can be small (per Theorem 4.8) and that exact simulation preserves tractable noise and central-DP guarantees, thereby mitigating the reviewer's concern rather than fully accepting it.", "b3_justification": "The paper explicitly states that PPR can result in a weaker local DP (larger ε_local) while achieving stronger central DP, so the reviewer’s observation about inflating the local privacy budget is correct. However, the paper also provides constructions (a randomized encoder) and arguments that preserve exact output distributions and enable precise privacy accounting, arguing that privacy guarantees and comparisons remain valid. Thus the reviewer’s concern is only partially reflected in the paper."}
